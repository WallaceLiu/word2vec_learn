{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Word2Vec Model\n",
    "==============\n",
    "\n",
    "Introduces Gensim's Word2Vec model and demonstrates its use on the Lee Corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you missed the buzz, word2vec is a widely featured as a member of the\n",
    "“new wave” of machine learning algorithms based on neural networks, commonly\n",
    "referred to as \"deep learning\" (though word2vec itself is rather shallow).\n",
    "Using large amounts of unannotated plain text, word2vec learns relationships\n",
    "between words automatically. The output are vectors, one vector per word,\n",
    "with remarkable linear relationships that allow us to do things like:\n",
    "\n",
    "* vec(\"king\") - vec(\"man\") + vec(\"woman\") =~ vec(\"queen\")\n",
    "* vec(\"Montreal Canadiens\") – vec(\"Montreal\") + vec(\"Toronto\") =~ vec(\"Toronto Maple Leafs\").\n",
    "\n",
    "Word2vec is very useful in `automatic text tagging\n",
    "<https://github.com/RaRe-Technologies/movie-plots-by-genre>`_\\ , recommender\n",
    "systems and machine translation.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "#. Introduces ``Word2Vec`` as an improvement over traditional bag-of-words\n",
    "#. Shows off a demo of ``Word2Vec`` using a pre-trained model\n",
    "#. Demonstrates training a new model from your own data\n",
    "#. Demonstrates loading and saving models\n",
    "#. Introduces several training parameters and demonstrates their effect\n",
    "#. Discusses memory requirements\n",
    "#. Visualizes Word2Vec embeddings by applying dimensionality reduction\n",
    "\n",
    "Review: Bag-of-words\n",
    "--------------------\n",
    "\n",
    ".. Note:: Feel free to skip these review sections if you're already familiar with the models.\n",
    "\n",
    "You may be familiar with the `bag-of-words model\n",
    "<https://en.wikipedia.org/wiki/Bag-of-words_model>`_ from the\n",
    "`core_concepts_vector` section.\n",
    "This model transforms each document to a fixed-length vector of integers.\n",
    "For example, given the sentences:\n",
    "\n",
    "- ``John likes to watch movies. Mary likes movies too.``\n",
    "- ``John also likes to watch football games. Mary hates football.``\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "- ``[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]``\n",
    "- ``[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]``\n",
    "\n",
    "Each vector has 10 elements, where each element counts the number of times a\n",
    "particular word occurred in the document.\n",
    "The order of elements is arbitrary.\n",
    "In the example above, the order of the elements corresponds to the words:\n",
    "``[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]``.\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "First, they lose all information about word order: \"John likes Mary\" and\n",
    "\"Mary likes John\" correspond to identical vectors. There is a solution: bag\n",
    "of `n-grams <https://en.wikipedia.org/wiki/N-gram>`__\n",
    "models consider word phrases of length n to represent documents as\n",
    "fixed-length vectors to capture local word order but suffer from data\n",
    "sparsity and high dimensionality.\n",
    "\n",
    "Second, the model does not attempt to learn the meaning of the underlying\n",
    "words, and as a consequence, the distance between vectors doesn't always\n",
    "reflect the difference in meaning.  The ``Word2Vec`` model addresses this\n",
    "second problem.\n",
    "\n",
    "Introducing: the ``Word2Vec`` Model\n",
    "-----------------------------------\n",
    "\n",
    "``Word2Vec`` is a more recent model that embeds words in a lower-dimensional\n",
    "vector space using a shallow neural network. The result is a set of\n",
    "word-vectors where vectors close together in vector space have similar\n",
    "meanings based on context, and word-vectors distant to each other have\n",
    "differing meanings. For example, ``strong`` and ``powerful`` would be close\n",
    "together and ``strong`` and ``Paris`` would be relatively far.\n",
    "\n",
    "The are two versions of this model and :py:class:`~gensim.models.word2vec.Word2Vec`\n",
    "class implements them both:\n",
    "\n",
    "1. Skip-grams (SG)\n",
    "2. Continuous-bag-of-words (CBOW)\n",
    "\n",
    ".. Important::\n",
    "  Don't let the implementation details below scare you.\n",
    "  They're advanced material: if it's too much, then move on to the next section.\n",
    "\n",
    "The `Word2Vec Skip-gram <http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model>`__\n",
    "model, for example, takes in pairs (word1, word2) generated by moving a\n",
    "window across text data, and trains a 1-hidden-layer neural network based on\n",
    "the synthetic task of given an input word, giving us a predicted probability\n",
    "distribution of nearby words to the input. A virtual `one-hot\n",
    "<https://en.wikipedia.org/wiki/One-hot>`__ encoding of words\n",
    "goes through a 'projection layer' to the hidden layer; these projection\n",
    "weights are later interpreted as the word embeddings. So if the hidden layer\n",
    "has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It\n",
    "is also a 1-hidden-layer neural network. The synthetic training task now uses\n",
    "the average of multiple input context words, rather than a single word as in\n",
    "skip-gram, to predict the center word. Again, the projection weights that\n",
    "turn one-hot words into averageable vectors, of the same width as the hidden\n",
    "layer, are interpreted as the word embeddings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Demo\n",
    "-------------\n",
    "\n",
    "To see what ``Word2Vec`` can do, let's download a pre-trained model and play\n",
    "around with it. We will fetch the Word2Vec model trained on part of the\n",
    "Google News dataset, covering approximately 3 million words and phrases. Such\n",
    "a model can take hours to train, but since it's already available,\n",
    "downloading and loading it with Gensim takes minutes.\n",
    "\n",
    ".. Important::\n",
    "  The model is approximately 2GB, so you'll need a decent network connection\n",
    "  to proceed.  Otherwise, skip ahead to the \"Training Your Own Model\" section\n",
    "  below.\n",
    "\n",
    "You may also check out an `online word2vec demo\n",
    "<http://radimrehurek.com/2014/02/word2vec-tutorial/#app>`_ where you can try\n",
    "this vector algebra for yourself. That demo runs ``word2vec`` on the\n",
    "**entire** Google News dataset, of **about 100 billion words**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:11:00,017 : INFO : loading projection weights from ../data/GoogleNews-vectors-negative300.bin.gz\n",
      "2020-02-03 23:13:32,331 : INFO : loaded (3000000, 300) matrix from ../data/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "wv=gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to retrieve the vocabulary of a model.  That is trivial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "in\n",
      "for\n",
      "that\n",
      "is\n",
      "on\n",
      "##\n",
      "The\n",
      "with\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily obtain vectors for terms the model is familiar with:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可惜，这个model不能推断它不知道的词。这是Word2Vec其中一个限制：如果你很在意这个限制，请使用 FastText 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, ``Word2Vec`` supports several word similarity tasks out of the\n",
    "box.  You can see how the similarity intuitively decreases as the words get\n",
    "less and less similar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 5 most similar words to \"car\" or \"minivan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:46:02,729 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532191514968872), ('vehicle', 0.8175784349441528), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the below does not belong in the sequence?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuning11/.conda/envs/myfaiss/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Your Own Model\n",
    "-----------------------\n",
    "\n",
    "To start, you'll need some data for training the model.  For the following\n",
    "examples, we'll use the `Lee Corpus\n",
    "<https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/lee_background.cor>`_\n",
    "(which you already have if you've installed gensim).\n",
    "\n",
    "该语料很小，能完全放在内存中，但我们仍然实现一个针对内存友好的迭代器，按行读取，以便处理大规模语料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:49:22,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-02-03 22:49:22,020 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "corpus_path='../data/lee_background.cor'\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to do any custom preprocessing, e.g. decode a non-standard\n",
    "encoding, lowercase, remove numbers, extract named entities... All of this can\n",
    "be done inside the ``MyCorpus`` iterator and ``word2vec`` doesn’t need to\n",
    "know. All that is required is that the input yields one sentence (list of\n",
    "utf8 words) after another.\n",
    "\n",
    "Let's go ahead and train a model on our corpus.  Don't worry about the\n",
    "training parameters much for now, we'll revisit them later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:49:28,784 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:49:28,790 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:49:28,885 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-02-03 22:49:28,886 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:49:28,918 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)\n",
      "2020-02-03 22:49:28,919 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)\n",
      "2020-02-03 22:49:28,925 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-02-03 22:49:28,928 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-02-03 22:49:28,930 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)\n",
      "2020-02-03 22:49:28,936 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-02-03 22:49:28,937 : INFO : resetting layer weights\n",
      "2020-02-03 22:49:29,265 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:49:29,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:49:29,382 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:49:29,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:49:29,385 : INFO : EPOCH - 1 : training on 58152 raw words (35994 effective words) took 0.1s, 347217 effective words/s\n",
      "2020-02-03 22:49:29,487 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:49:29,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:49:29,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:49:29,494 : INFO : EPOCH - 2 : training on 58152 raw words (35961 effective words) took 0.1s, 333119 effective words/s\n",
      "2020-02-03 22:49:29,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:49:29,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:49:29,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:49:29,604 : INFO : EPOCH - 3 : training on 58152 raw words (35894 effective words) took 0.1s, 330731 effective words/s\n",
      "2020-02-03 22:49:29,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:49:29,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:49:29,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:49:29,717 : INFO : EPOCH - 4 : training on 58152 raw words (35944 effective words) took 0.1s, 323789 effective words/s\n",
      "2020-02-03 22:49:29,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:49:29,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:49:29,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:49:29,833 : INFO : EPOCH - 5 : training on 58152 raw words (35949 effective words) took 0.1s, 316929 effective words/s\n",
      "2020-02-03 22:49:29,833 : INFO : training on a 290760 raw words (179742 effective words) took 0.6s, 316588 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model, we can use it in the same way as in the demo above.\n",
    "\n",
    "The main part of the model is ``model.wv``\\ , where \"wv\" stands for \"word vectors\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = model.wv['king'] # dim=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the vocabulary works the same way:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds\n",
      "of\n",
      "people\n",
      "have\n",
      "been\n",
      "forced\n",
      "to\n",
      "their\n",
      "homes\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading models\n",
    "--------------------------\n",
    "\n",
    "You'll notice that training non-trivial models can take time.  Once you've\n",
    "trained your model and it works as expected, you can save it to disk.  That\n",
    "way, you don't have to spend time training it all over again later.\n",
    "\n",
    "You can store/load models using the standard gensim methods:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:50:01,465 : INFO : saving Word2Vec object under /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx, separately None\n",
      "2020-02-03 22:50:01,466 : INFO : not storing attribute vectors_norm\n",
      "2020-02-03 22:50:01,467 : INFO : not storing attribute cum_table\n",
      "2020-02-03 22:50:01,491 : INFO : saved /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx\n",
      "2020-02-03 22:50:01,492 : INFO : loading Word2Vec object from /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx\n",
      "2020-02-03 22:50:01,509 : INFO : loading wv recursively from /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx.wv.* with mmap=None\n",
      "2020-02-03 22:50:01,510 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-02-03 22:50:01,511 : INFO : loading vocabulary recursively from /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx.vocabulary.* with mmap=None\n",
      "2020-02-03 22:50:01,511 : INFO : loading trainables recursively from /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx.trainables.* with mmap=None\n",
      "2020-02-03 22:50:01,513 : INFO : setting ignored attribute cum_table to None\n",
      "2020-02-03 22:50:01,513 : INFO : loaded /var/folders/fb/jcf536t9265fc_nlmqdcwd9jsf5jrm/T/gensim-model-wiazqwrx\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which uses pickle internally, optionally ``mmap``\\ ‘ing the model’s internal\n",
    "large NumPy matrices into virtual memory directly from disk files, for\n",
    "inter-process memory sharing.\n",
    "\n",
    "In addition, you can load models created by the original C tool, both using\n",
    "its text and binary formats::\n",
    "\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.txt', binary=False)\n",
    "  # using gzipped/bz2 input works too, no need to unzip\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.bin.gz', binary=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters\n",
    "-------------------\n",
    "\n",
    "``Word2Vec`` accepts several parameters that affect both training speed and quality.\n",
    "\n",
    "min_count\n",
    "---------\n",
    "\n",
    "``min_count`` is for pruning the internal dictionary. Words that appear only\n",
    "once or twice in a billion-word corpus are probably uninteresting typos and\n",
    "garbage. In addition, there’s not enough data to make any meaningful training\n",
    "on those words, so it’s best to ignore them:\n",
    "\n",
    "default value of min_count=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size\n",
    "----\n",
    "\n",
    "``size`` is the number of dimensions (N) of the N-dimensional space that\n",
    "gensim Word2Vec maps the words onto.\n",
    "\n",
    "Bigger size values require more training data, but can lead to better (more\n",
    "accurate) models. Reasonable values are in the tens to hundreds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default value of size=100\n",
    "model = gensim.models.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers\n",
    "-------\n",
    "\n",
    "``workers`` , the last of the major parameters (full list `here\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec>`_)\n",
    "is for training parallelization, to speed up training:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default value of workers=3 (tutorial says 1...)\n",
    "model = gensim.models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``workers`` parameter only has an effect if you have `Cython\n",
    "<http://cython.org/>`_ installed. Without Cython, you’ll only be able to use\n",
    "one core because of the `GIL\n",
    "<https://wiki.python.org/moin/GlobalInterpreterLock>`_ (and ``word2vec``\n",
    "training will be `miserably slow\n",
    "<http://rare-technologies.com/word2vec-in-python-part-two-optimizing/>`_\\ ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory\n",
    "------\n",
    "\n",
    "At its core, ``word2vec`` model parameters are stored as matrices (NumPy\n",
    "arrays). Each array is **#vocabulary** (controlled by min_count parameter)\n",
    "times **#size** (size parameter) of floats (single precision aka 4 bytes).\n",
    "\n",
    "Three such matrices are held in RAM (work is underway to reduce that number\n",
    "to two, or even one). So if your input contains 100,000 unique words, and you\n",
    "asked for layer ``size=200``\\ , the model will require approx.\n",
    "``100,000*200*4*3 bytes = ~229MB``.\n",
    "\n",
    "There’s a little extra memory needed for storing the vocabulary tree (100,000 words would take a few megabytes), but unless your words are extremely loooong strings, memory footprint will be dominated by the three matrices above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating\n",
    "----------\n",
    "\n",
    "``Word2Vec`` training is an unsupervised task, there’s no good way to\n",
    "objectively evaluate the result. Evaluation depends on your end application.\n",
    "\n",
    "Google has released their testing set of about 20,000 syntactic and semantic\n",
    "test examples, following the “A is to B as C is to D” task. It is provided in\n",
    "the 'datasets' folder.\n",
    "\n",
    "For example a syntactic analogy of comparative type is bad:worse;good:?.\n",
    "There are total of 9 types of syntactic comparisons in the dataset like\n",
    "plural nouns and nouns of opposite meaning.\n",
    "\n",
    "The semantic questions contain five types of semantic analogies, such as\n",
    "capital cities (Paris:France;Tokyo:?) or family members\n",
    "(brother:sister;dad:?).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim supports the same evaluation set, in exactly the same format:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accuracy('../data/questions-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ``accuracy`` takes an `optional parameter\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec.accuracy>`_\n",
    "``restrict_vocab`` which limits which test examples are to be considered.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.\n",
    "\n",
    "By default it uses an academic dataset WS-353 but one can create a dataset\n",
    "specific to your business based on it. It contains word pairs together with\n",
    "human-assigned similarity judgments. It measures the relatedness or\n",
    "co-occurrence of two words. For example, 'coast' and 'shore' are very similar\n",
    "as they appear in the same context. At the same time 'clothes' and 'closet'\n",
    "are less similar because they are related but not interchangeable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_word_pairs('../data/wordsim353.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Important::\n",
    "  Good performance on Google's or WS-353 test set doesn’t mean word2vec will\n",
    "  work well in your application, or vice versa. It’s always best to evaluate\n",
    "  directly on your intended task. For an example of how to use word2vec in a\n",
    "  classifier pipeline, see this `tutorial\n",
    "  <https://github.com/RaRe-Technologies/movie-plots-by-genre>`_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online training / Resuming training\n",
    "-----------------------------------\n",
    "\n",
    "Advanced users can load a model and continue training it with more sentences\n",
    "and `new vocabulary words <online_w2v_tutorial.ipynb>`_:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences']\n",
    "]\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to tweak the ``total_words`` parameter to ``train()``,\n",
    "depending on what learning rate decay you want to simulate.\n",
    "\n",
    "Note that it’s not possible to resume training with models generated by the C\n",
    "tool, ``KeyedVectors.load_word2vec_format()``. You can still use them for\n",
    "querying/similarity, but information vital for training (the vocab tree) is\n",
    "missing there.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loss Computation\n",
    "-------------------------\n",
    "\n",
    "The parameter ``compute_loss`` can be used to toggle computation of loss\n",
    "while training the Word2Vec model. The computed loss is stored in the model\n",
    "attribute ``running_training_loss`` and can be retrieved using the function\n",
    "``get_latest_training_loss`` as follows :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "----------\n",
    "\n",
    "Let's run some benchmarks to see effect of the training loss computation code\n",
    "on training time.\n",
    "\n",
    "We'll use the following data for the benchmarks:\n",
    "\n",
    "#. Lee Background corpus: included in gensim's test data\n",
    "#. Text8 corpus.  To demonstrate the effect of corpus size, we'll look at the\n",
    "   first 1MB, 10MB, 50MB of the corpus, as well as the entire thing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "import logging\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = '../data/lee_background.cor'\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = '../data/text8'\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the training time taken for different combinations of input\n",
    "data and model training parameters like ``hs`` and ``sg``.\n",
    "\n",
    "For each combination, we repeat the test several times to obtain the mean and\n",
    "standard deviation of the test duration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:28,575 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:28,577 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:28,598 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:28,599 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:28,606 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:28,606 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:28,613 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:28,614 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:28,614 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:28,620 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:28,621 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:28,974 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:29,006 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,009 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,015 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,022 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.0s, 709922 effective words/s\n",
      "2020-02-03 22:54:29,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,067 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.0s, 764805 effective words/s\n",
      "2020-02-03 22:54:29,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,116 : INFO : EPOCH - 3 : training on 59890 raw words (32568 effective words) took 0.0s, 698906 effective words/s\n",
      "2020-02-03 22:54:29,150 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,160 : INFO : EPOCH - 4 : training on 59890 raw words (32585 effective words) took 0.0s, 766270 effective words/s\n",
      "2020-02-03 22:54:29,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,207 : INFO : EPOCH - 5 : training on 59890 raw words (32638 effective words) took 0.0s, 742911 effective words/s\n",
      "2020-02-03 22:54:29,207 : INFO : training on a 299450 raw words (163111 effective words) took 0.2s, 702915 effective words/s\n",
      "2020-02-03 22:54:29,209 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:29,210 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:29,233 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:29,233 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:29,242 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:29,242 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:29,250 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:29,251 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:29,251 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:29,256 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:29,257 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:29,607 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:29,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,637 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,641 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.0s, 1005534 effective words/s\n",
      "2020-02-03 22:54:29,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,681 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.0s, 853414 effective words/s\n",
      "2020-02-03 22:54:29,717 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,720 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,727 : INFO : EPOCH - 3 : training on 59890 raw words (32568 effective words) took 0.0s, 748664 effective words/s\n",
      "2020-02-03 22:54:29,764 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,774 : INFO : EPOCH - 4 : training on 59890 raw words (32585 effective words) took 0.0s, 726456 effective words/s\n",
      "2020-02-03 22:54:29,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:29,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:29,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:29,819 : INFO : EPOCH - 5 : training on 59890 raw words (32720 effective words) took 0.0s, 794407 effective words/s\n",
      "2020-02-03 22:54:29,820 : INFO : training on a 299450 raw words (163193 effective words) took 0.2s, 769564 effective words/s\n",
      "2020-02-03 22:54:29,824 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:29,825 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:29,849 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:29,850 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:29,858 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:29,859 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:29,866 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:29,867 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:29,868 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:29,874 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:29,875 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:30,253 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:30,279 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,283 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,284 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1103714 effective words/s\n",
      "2020-02-03 22:54:30,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:30,317 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,321 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 945396 effective words/s\n",
      "2020-02-03 22:54:30,351 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,359 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.0s, 909672 effective words/s\n",
      "2020-02-03 22:54:30,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,398 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,399 : INFO : EPOCH - 4 : training on 59890 raw words (32654 effective words) took 0.0s, 849420 effective words/s\n",
      "2020-02-03 22:54:30,432 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,440 : INFO : EPOCH - 5 : training on 59890 raw words (32715 effective words) took 0.0s, 855416 effective words/s\n",
      "2020-02-03 22:54:30,441 : INFO : training on a 299450 raw words (162981 effective words) took 0.2s, 870223 effective words/s\n",
      "2020-02-03 22:54:30,446 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:30,448 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:30,470 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:30,471 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:30,481 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:30,482 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:30,491 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:30,492 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:30,493 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:30,498 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:30,499 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.6225600242614746, 'train_time_std': 0.008212428504875411}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:30,882 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:30,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,921 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 868729 effective words/s\n",
      "2020-02-03 22:54:30,957 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:30,964 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:30,964 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 798707 effective words/s\n",
      "2020-02-03 22:54:30,996 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:30,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,002 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,003 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 902488 effective words/s\n",
      "2020-02-03 22:54:31,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,041 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 881031 effective words/s\n",
      "2020-02-03 22:54:31,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,083 : INFO : EPOCH - 5 : training on 59890 raw words (32693 effective words) took 0.0s, 831667 effective words/s\n",
      "2020-02-03 22:54:31,084 : INFO : training on a 299450 raw words (162978 effective words) took 0.2s, 811650 effective words/s\n",
      "2020-02-03 22:54:31,086 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:31,087 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:31,108 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:31,109 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:31,116 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:31,117 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:31,124 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:31,125 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:31,126 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:31,131 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:31,131 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:31,527 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:31,554 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,562 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 987637 effective words/s\n",
      "2020-02-03 22:54:31,592 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,599 : INFO : EPOCH - 2 : training on 59890 raw words (32616 effective words) took 0.0s, 900358 effective words/s\n",
      "2020-02-03 22:54:31,628 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,634 : INFO : EPOCH - 3 : training on 59890 raw words (32670 effective words) took 0.0s, 979682 effective words/s\n",
      "2020-02-03 22:54:31,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,683 : INFO : EPOCH - 4 : training on 59890 raw words (32605 effective words) took 0.0s, 698228 effective words/s\n",
      "2020-02-03 22:54:31,717 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:31,718 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:31,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:31,726 : INFO : EPOCH - 5 : training on 59890 raw words (32567 effective words) took 0.0s, 788805 effective words/s\n",
      "2020-02-03 22:54:31,727 : INFO : training on a 299450 raw words (163001 effective words) took 0.2s, 816934 effective words/s\n",
      "2020-02-03 22:54:31,730 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:31,731 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:31,757 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:31,758 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:31,765 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:31,766 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:31,775 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:31,776 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:31,778 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:31,783 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:31,783 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:32,127 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:32,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,163 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 956920 effective words/s\n",
      "2020-02-03 22:54:32,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,199 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 929234 effective words/s\n",
      "2020-02-03 22:54:32,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,230 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,234 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.0s, 973720 effective words/s\n",
      "2020-02-03 22:54:32,260 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,264 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:32,268 : INFO : EPOCH - 4 : training on 59890 raw words (32769 effective words) took 0.0s, 1001040 effective words/s\n",
      "2020-02-03 22:54:32,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,308 : INFO : EPOCH - 5 : training on 59890 raw words (32723 effective words) took 0.0s, 878691 effective words/s\n",
      "2020-02-03 22:54:32,309 : INFO : training on a 299450 raw words (163104 effective words) took 0.2s, 900933 effective words/s\n",
      "2020-02-03 22:54:32,312 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:32,313 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:32,337 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:32,339 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:32,348 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:32,348 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:32,357 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:32,358 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:32,359 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:32,362 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:32,408 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:32,411 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:32,412 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.621660312016805, 'train_time_std': 0.028677800827210085}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:32,764 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:32,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,821 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 595016 effective words/s\n",
      "2020-02-03 22:54:32,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,888 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,895 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 458342 effective words/s\n",
      "2020-02-03 22:54:32,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:32,951 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:32,955 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:32,956 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.1s, 547961 effective words/s\n",
      "2020-02-03 22:54:33,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,012 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,015 : INFO : EPOCH - 4 : training on 59890 raw words (32654 effective words) took 0.1s, 570689 effective words/s\n",
      "2020-02-03 22:54:33,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,066 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,073 : INFO : EPOCH - 5 : training on 59890 raw words (32640 effective words) took 0.1s, 581854 effective words/s\n",
      "2020-02-03 22:54:33,073 : INFO : training on a 299450 raw words (162906 effective words) took 0.3s, 527942 effective words/s\n",
      "2020-02-03 22:54:33,076 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:33,078 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:33,103 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:33,105 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:33,115 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:33,116 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:33,125 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:33,127 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:33,128 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:33,132 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:33,180 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:33,183 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:33,184 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:33,534 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:33,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,604 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 475849 effective words/s\n",
      "2020-02-03 22:54:33,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,670 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 516679 effective words/s\n",
      "2020-02-03 22:54:33,724 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,738 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.1s, 491938 effective words/s\n",
      "2020-02-03 22:54:33,795 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,809 : INFO : EPOCH - 4 : training on 59890 raw words (32654 effective words) took 0.1s, 470304 effective words/s\n",
      "2020-02-03 22:54:33,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:33,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:33,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:33,892 : INFO : EPOCH - 5 : training on 59890 raw words (32715 effective words) took 0.1s, 405293 effective words/s\n",
      "2020-02-03 22:54:33,893 : INFO : training on a 299450 raw words (162981 effective words) took 0.4s, 454963 effective words/s\n",
      "2020-02-03 22:54:33,896 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:33,898 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:33,923 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:33,924 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:33,933 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:33,934 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:33,945 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:33,946 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:33,947 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:33,950 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:33,998 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:34,002 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:34,002 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:34,337 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:34,394 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:34,396 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:34,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:34,403 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 507901 effective words/s\n",
      "2020-02-03 22:54:34,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:34,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:34,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:34,466 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 527327 effective words/s\n",
      "2020-02-03 22:54:34,512 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:34,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:34,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:34,526 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.1s, 553050 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:34,577 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:34,580 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:34,588 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:34,589 : INFO : EPOCH - 4 : training on 59890 raw words (32769 effective words) took 0.1s, 534934 effective words/s\n",
      "2020-02-03 22:54:34,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:34,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:34,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:34,668 : INFO : EPOCH - 5 : training on 59890 raw words (32723 effective words) took 0.1s, 430194 effective words/s\n",
      "2020-02-03 22:54:34,668 : INFO : training on a 299450 raw words (163104 effective words) took 0.3s, 492454 effective words/s\n",
      "2020-02-03 22:54:34,673 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:34,675 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:34,698 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:34,699 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:34,707 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:34,708 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:34,714 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:34,715 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:34,717 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:34,720 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:34,765 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:34,769 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:34,770 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.7871049245198568, 'train_time_std': 0.02387725786025585}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:35,127 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:35,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,185 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,193 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,194 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 505026 effective words/s\n",
      "2020-02-03 22:54:35,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,253 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 565358 effective words/s\n",
      "2020-02-03 22:54:35,309 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,320 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,321 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 503158 effective words/s\n",
      "2020-02-03 22:54:35,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,382 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,383 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 541072 effective words/s\n",
      "2020-02-03 22:54:35,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,444 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 541911 effective words/s\n",
      "2020-02-03 22:54:35,445 : INFO : training on a 299450 raw words (162877 effective words) took 0.3s, 514428 effective words/s\n",
      "2020-02-03 22:54:35,448 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:35,449 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:35,472 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:35,473 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:35,481 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:35,482 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:35,489 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:35,490 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:35,491 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:35,493 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:35,538 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:35,541 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:35,542 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:35,885 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:35,934 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:35,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:35,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:35,948 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.1s, 535066 effective words/s\n",
      "2020-02-03 22:54:35,998 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,009 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.1s, 553310 effective words/s\n",
      "2020-02-03 22:54:36,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,085 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,086 : INFO : EPOCH - 3 : training on 59890 raw words (32584 effective words) took 0.1s, 434704 effective words/s\n",
      "2020-02-03 22:54:36,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,160 : INFO : EPOCH - 4 : training on 59890 raw words (32629 effective words) took 0.1s, 460920 effective words/s\n",
      "2020-02-03 22:54:36,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,223 : INFO : EPOCH - 5 : training on 59890 raw words (32579 effective words) took 0.1s, 537275 effective words/s\n",
      "2020-02-03 22:54:36,224 : INFO : training on a 299450 raw words (163112 effective words) took 0.3s, 483642 effective words/s\n",
      "2020-02-03 22:54:36,227 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:36,228 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:36,249 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:36,249 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:36,257 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:36,258 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:36,265 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:36,266 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:36,266 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:36,269 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:36,317 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:36,321 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:36,322 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:36,671 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:36,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,726 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,730 : INFO : EPOCH - 1 : training on 59890 raw words (32596 effective words) took 0.1s, 567593 effective words/s\n",
      "2020-02-03 22:54:36,782 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,798 : INFO : EPOCH - 2 : training on 59890 raw words (32601 effective words) took 0.1s, 498293 effective words/s\n",
      "2020-02-03 22:54:36,850 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,859 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,864 : INFO : EPOCH - 3 : training on 59890 raw words (32618 effective words) took 0.1s, 511380 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:36,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,926 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,927 : INFO : EPOCH - 4 : training on 59890 raw words (32624 effective words) took 0.1s, 528869 effective words/s\n",
      "2020-02-03 22:54:36,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:36,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:36,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:36,987 : INFO : EPOCH - 5 : training on 59890 raw words (32543 effective words) took 0.1s, 559008 effective words/s\n",
      "2020-02-03 22:54:36,988 : INFO : training on a 299450 raw words (162982 effective words) took 0.3s, 515390 effective words/s\n",
      "2020-02-03 22:54:36,992 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:36,994 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:37,016 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:37,017 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:37,024 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:37,024 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:37,031 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:37,032 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:37,033 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:37,042 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:37,043 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.7731149196624756, 'train_time_std': 0.0057283864786662475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:37,437 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:37,510 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:37,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:37,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:37,521 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.1s, 403550 effective words/s\n",
      "2020-02-03 22:54:37,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:37,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:37,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:37,616 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.1s, 349560 effective words/s\n",
      "2020-02-03 22:54:37,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:37,691 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:37,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:37,695 : INFO : EPOCH - 3 : training on 59890 raw words (32568 effective words) took 0.1s, 425375 effective words/s\n",
      "2020-02-03 22:54:37,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:37,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:37,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:37,780 : INFO : EPOCH - 4 : training on 59890 raw words (32585 effective words) took 0.1s, 393569 effective words/s\n",
      "2020-02-03 22:54:37,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:37,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:37,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:37,869 : INFO : EPOCH - 5 : training on 59890 raw words (32638 effective words) took 0.1s, 370762 effective words/s\n",
      "2020-02-03 22:54:37,870 : INFO : training on a 299450 raw words (163111 effective words) took 0.4s, 376619 effective words/s\n",
      "2020-02-03 22:54:37,875 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:37,877 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:37,900 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:37,901 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:37,909 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:37,910 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:37,916 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:37,917 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:37,918 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:37,924 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:37,925 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:38,357 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:38,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:38,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:38,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:38,437 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 415408 effective words/s\n",
      "2020-02-03 22:54:38,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:38,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:38,514 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:38,515 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 429803 effective words/s\n",
      "2020-02-03 22:54:38,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:38,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:38,609 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:38,610 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 350177 effective words/s\n",
      "2020-02-03 22:54:38,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:38,695 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:38,698 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:38,699 : INFO : EPOCH - 4 : training on 59890 raw words (32649 effective words) took 0.1s, 377269 effective words/s\n",
      "2020-02-03 22:54:38,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:38,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:38,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:38,778 : INFO : EPOCH - 5 : training on 59890 raw words (32494 effective words) took 0.1s, 415728 effective words/s\n",
      "2020-02-03 22:54:38,778 : INFO : training on a 299450 raw words (162841 effective words) took 0.4s, 387172 effective words/s\n",
      "2020-02-03 22:54:38,780 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:38,781 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:38,798 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:38,799 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:38,805 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:38,806 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:38,811 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:38,811 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:38,812 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:38,816 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:38,817 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:39,151 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:39,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:39,225 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 446818 effective words/s\n",
      "2020-02-03 22:54:39,290 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:39,299 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 449991 effective words/s\n",
      "2020-02-03 22:54:39,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:39,376 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 435174 effective words/s\n",
      "2020-02-03 22:54:39,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,451 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:39,452 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 436150 effective words/s\n",
      "2020-02-03 22:54:39,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:39,532 : INFO : EPOCH - 5 : training on 59890 raw words (32693 effective words) took 0.1s, 419158 effective words/s\n",
      "2020-02-03 22:54:39,533 : INFO : training on a 299450 raw words (162978 effective words) took 0.4s, 427615 effective words/s\n",
      "2020-02-03 22:54:39,534 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:39,536 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:39,553 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:39,554 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:39,561 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:39,561 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:39,566 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:39,567 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:39,568 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:39,572 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:39,573 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 0.8472832838694254, 'train_time_std': 0.0664275760725608}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:39,908 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:39,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:39,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:39,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:39,985 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.1s, 439556 effective words/s\n",
      "2020-02-03 22:54:40,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,060 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,061 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.1s, 440707 effective words/s\n",
      "2020-02-03 22:54:40,130 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,133 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,138 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,138 : INFO : EPOCH - 3 : training on 59890 raw words (32568 effective words) took 0.1s, 430554 effective words/s\n",
      "2020-02-03 22:54:40,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,205 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,212 : INFO : EPOCH - 4 : training on 59890 raw words (32610 effective words) took 0.1s, 456582 effective words/s\n",
      "2020-02-03 22:54:40,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,282 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,289 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,289 : INFO : EPOCH - 5 : training on 59890 raw words (32647 effective words) took 0.1s, 432107 effective words/s\n",
      "2020-02-03 22:54:40,290 : INFO : training on a 299450 raw words (163145 effective words) took 0.4s, 428904 effective words/s\n",
      "2020-02-03 22:54:40,292 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:40,293 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:40,311 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:40,312 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:40,318 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:40,319 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:40,324 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:40,325 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:40,326 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:40,330 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:40,331 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:40,674 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:40,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,750 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.1s, 459341 effective words/s\n",
      "2020-02-03 22:54:40,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,826 : INFO : EPOCH - 2 : training on 59890 raw words (32676 effective words) took 0.1s, 436636 effective words/s\n",
      "2020-02-03 22:54:40,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,902 : INFO : EPOCH - 3 : training on 59890 raw words (32590 effective words) took 0.1s, 437747 effective words/s\n",
      "2020-02-03 22:54:40,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:40,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:40,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:40,979 : INFO : EPOCH - 4 : training on 59890 raw words (32579 effective words) took 0.1s, 434186 effective words/s\n",
      "2020-02-03 22:54:41,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,059 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:41,060 : INFO : EPOCH - 5 : training on 59890 raw words (32524 effective words) took 0.1s, 416918 effective words/s\n",
      "2020-02-03 22:54:41,061 : INFO : training on a 299450 raw words (163037 effective words) took 0.4s, 421725 effective words/s\n",
      "2020-02-03 22:54:41,063 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:41,064 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:41,081 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:41,082 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:41,088 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:41,089 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:41,095 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:41,095 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:41,096 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:41,099 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-02-03 22:54:41,100 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:41,437 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:41,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,507 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:41,513 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 442014 effective words/s\n",
      "2020-02-03 22:54:41,584 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,596 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:41,596 : INFO : EPOCH - 2 : training on 59890 raw words (32616 effective words) took 0.1s, 397942 effective words/s\n",
      "2020-02-03 22:54:41,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:41,677 : INFO : EPOCH - 3 : training on 59890 raw words (32670 effective words) took 0.1s, 417416 effective words/s\n",
      "2020-02-03 22:54:41,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:41,752 : INFO : EPOCH - 4 : training on 59890 raw words (32580 effective words) took 0.1s, 442623 effective words/s\n",
      "2020-02-03 22:54:41,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:41,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:41,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:41,827 : INFO : EPOCH - 5 : training on 59890 raw words (32528 effective words) took 0.1s, 445564 effective words/s\n",
      "2020-02-03 22:54:41,828 : INFO : training on a 299450 raw words (162937 effective words) took 0.4s, 417093 effective words/s\n",
      "2020-02-03 22:54:41,830 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:41,832 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:41,849 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:41,850 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:41,856 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:41,856 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:41,862 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:41,862 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:41,863 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:41,865 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:41,900 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:41,903 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:41,904 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 0.7651705741882324, 'train_time_std': 0.0057429612127855275}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:42,270 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:42,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:42,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:42,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:42,445 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 187902 effective words/s\n",
      "2020-02-03 22:54:42,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:42,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:42,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:42,628 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.2s, 178734 effective words/s\n",
      "2020-02-03 22:54:42,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:42,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:42,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:42,829 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.2s, 171488 effective words/s\n",
      "2020-02-03 22:54:42,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:42,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:42,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:42,985 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.2s, 212206 effective words/s\n",
      "2020-02-03 22:54:43,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:43,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:43,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:43,145 : INFO : EPOCH - 5 : training on 59890 raw words (32693 effective words) took 0.2s, 206007 effective words/s\n",
      "2020-02-03 22:54:43,146 : INFO : training on a 299450 raw words (162978 effective words) took 0.9s, 186186 effective words/s\n",
      "2020-02-03 22:54:43,147 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:43,148 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:43,166 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:43,167 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:43,173 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:43,174 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:43,179 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:43,181 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:43,182 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:43,183 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:43,221 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:43,224 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:43,225 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:43,566 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:43,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:43,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:43,733 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:43,734 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 196464 effective words/s\n",
      "2020-02-03 22:54:43,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:43,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:43,903 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:43,904 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.2s, 193658 effective words/s\n",
      "2020-02-03 22:54:44,061 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:44,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:44,077 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:44,078 : INFO : EPOCH - 3 : training on 59890 raw words (32517 effective words) took 0.2s, 188420 effective words/s\n",
      "2020-02-03 22:54:44,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:44,264 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:44,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:44,271 : INFO : EPOCH - 4 : training on 59890 raw words (32654 effective words) took 0.2s, 171122 effective words/s\n",
      "2020-02-03 22:54:44,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:44,484 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:44,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:44,494 : INFO : EPOCH - 5 : training on 59890 raw words (32640 effective words) took 0.2s, 150264 effective words/s\n",
      "2020-02-03 22:54:44,495 : INFO : training on a 299450 raw words (162906 effective words) took 0.9s, 175584 effective words/s\n",
      "2020-02-03 22:54:44,497 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:44,498 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:44,520 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:44,521 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:44,529 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:44,529 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:44,535 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:44,536 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:44,539 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:44,544 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:44,594 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:44,597 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:44,597 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:44,977 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:45,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:45,135 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:45,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:45,142 : INFO : EPOCH - 1 : training on 59890 raw words (32668 effective words) took 0.2s, 200348 effective words/s\n",
      "2020-02-03 22:54:45,395 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:45,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:45,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:45,426 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.3s, 116055 effective words/s\n",
      "2020-02-03 22:54:45,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:45,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:45,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:45,733 : INFO : EPOCH - 3 : training on 59890 raw words (32568 effective words) took 0.3s, 116655 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:45,989 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:45,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:46,005 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:46,006 : INFO : EPOCH - 4 : training on 59890 raw words (32585 effective words) took 0.3s, 121382 effective words/s\n",
      "2020-02-03 22:54:46,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:46,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:46,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:46,257 : INFO : EPOCH - 5 : training on 59890 raw words (32720 effective words) took 0.2s, 131995 effective words/s\n",
      "2020-02-03 22:54:46,258 : INFO : training on a 299450 raw words (163193 effective words) took 1.3s, 127548 effective words/s\n",
      "2020-02-03 22:54:46,267 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:46,269 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:46,314 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:46,315 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:46,327 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:46,328 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:46,334 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:46,335 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:46,336 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:46,341 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:46,416 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:46,423 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:46,425 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 1.4782519340515137, 'train_time_std': 0.20497679517315912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:46,940 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:47,238 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:47,247 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:47,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:47,263 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.3s, 101384 effective words/s\n",
      "2020-02-03 22:54:47,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:47,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:47,750 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:47,753 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.5s, 69674 effective words/s\n",
      "2020-02-03 22:54:48,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:48,321 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:48,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:48,354 : INFO : EPOCH - 3 : training on 59890 raw words (32685 effective words) took 0.6s, 55251 effective words/s\n",
      "2020-02-03 22:54:49,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:49,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:49,160 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:49,161 : INFO : EPOCH - 4 : training on 59890 raw words (32526 effective words) took 0.4s, 86053 effective words/s\n",
      "2020-02-03 22:54:49,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:49,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:49,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:49,539 : INFO : EPOCH - 5 : training on 59890 raw words (32549 effective words) took 0.4s, 87115 effective words/s\n",
      "2020-02-03 22:54:49,540 : INFO : training on a 299450 raw words (162855 effective words) took 2.6s, 62653 effective words/s\n",
      "2020-02-03 22:54:49,544 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:49,545 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:49,566 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:49,567 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:49,573 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:49,573 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:49,579 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:49,580 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:49,580 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:49,583 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:49,617 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:49,620 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:49,621 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:49,962 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:50,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:50,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:50,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:50,123 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 204318 effective words/s\n",
      "2020-02-03 22:54:50,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:50,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:50,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:50,415 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.3s, 112300 effective words/s\n",
      "2020-02-03 22:54:50,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:50,760 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:50,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:50,763 : INFO : EPOCH - 3 : training on 59890 raw words (32582 effective words) took 0.3s, 95595 effective words/s\n",
      "2020-02-03 22:54:51,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:51,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:51,105 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:51,106 : INFO : EPOCH - 4 : training on 59890 raw words (32473 effective words) took 0.3s, 96375 effective words/s\n",
      "2020-02-03 22:54:51,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:51,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:51,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:51,309 : INFO : EPOCH - 5 : training on 59890 raw words (32604 effective words) took 0.2s, 164170 effective words/s\n",
      "2020-02-03 22:54:51,309 : INFO : training on a 299450 raw words (162754 effective words) took 1.3s, 120906 effective words/s\n",
      "2020-02-03 22:54:51,312 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:51,314 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:51,333 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-02-03 22:54:51,334 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:51,342 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-02-03 22:54:51,343 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-02-03 22:54:51,350 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-02-03 22:54:51,352 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-03 22:54:51,353 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-02-03 22:54:51,359 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-02-03 22:54:51,405 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-02-03 22:54:51,408 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-02-03 22:54:51,409 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:51,778 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:51,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:51,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:51,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:51,935 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.2s, 209991 effective words/s\n",
      "2020-02-03 22:54:52,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:52,080 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:52,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:52,084 : INFO : EPOCH - 2 : training on 59890 raw words (32616 effective words) took 0.1s, 221522 effective words/s\n",
      "2020-02-03 22:54:52,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:52,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:52,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:52,232 : INFO : EPOCH - 3 : training on 59890 raw words (32670 effective words) took 0.1s, 223549 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:52,373 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:52,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:52,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:52,386 : INFO : EPOCH - 4 : training on 59890 raw words (32605 effective words) took 0.2s, 214117 effective words/s\n",
      "2020-02-03 22:54:52,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:52,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:52,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:52,537 : INFO : EPOCH - 5 : training on 59890 raw words (32567 effective words) took 0.1s, 219721 effective words/s\n",
      "2020-02-03 22:54:52,538 : INFO : training on a 299450 raw words (163001 effective words) took 0.8s, 214614 effective words/s\n",
      "2020-02-03 22:54:52,543 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:52,569 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:52,601 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:54:52,602 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:52,613 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:54:52,614 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:54:52,624 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:54:52,626 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:54:52,627 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:54:52,634 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:54:52,635 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 2.0920166969299316, 'train_time_std': 0.8674240515297896}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:53,518 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:53,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:53,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:53,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:53,611 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1415013 effective words/s\n",
      "2020-02-03 22:54:53,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:53,735 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:53,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:53,738 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.1s, 1011600 effective words/s\n",
      "2020-02-03 22:54:53,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:53,863 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:53,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:53,864 : INFO : EPOCH - 3 : training on 175599 raw words (110219 effective words) took 0.1s, 1063192 effective words/s\n",
      "2020-02-03 22:54:53,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:53,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:53,967 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:53,967 : INFO : EPOCH - 4 : training on 175599 raw words (110060 effective words) took 0.1s, 1246265 effective words/s\n",
      "2020-02-03 22:54:54,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:54,095 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:54,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:54,097 : INFO : EPOCH - 5 : training on 175599 raw words (110266 effective words) took 0.1s, 986140 effective words/s\n",
      "2020-02-03 22:54:54,098 : INFO : training on a 877995 raw words (551103 effective words) took 0.6s, 951874 effective words/s\n",
      "2020-02-03 22:54:54,102 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:54,121 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:54,158 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:54:54,159 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:54,175 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:54:54,176 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:54:54,212 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:54:54,216 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:54:54,218 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:54:54,255 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:54:54,258 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:55,777 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:55,900 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:55,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:55,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:55,910 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 982582 effective words/s\n",
      "2020-02-03 22:54:56,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:56,026 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:56,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:56,029 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 1069865 effective words/s\n",
      "2020-02-03 22:54:56,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:56,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:56,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:56,202 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.2s, 707634 effective words/s\n",
      "2020-02-03 22:54:56,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:56,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:56,320 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:56,321 : INFO : EPOCH - 4 : training on 175599 raw words (110337 effective words) took 0.1s, 1053721 effective words/s\n",
      "2020-02-03 22:54:56,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:56,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:56,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:56,425 : INFO : EPOCH - 5 : training on 175599 raw words (110462 effective words) took 0.1s, 1295923 effective words/s\n",
      "2020-02-03 22:54:56,426 : INFO : training on a 877995 raw words (551562 effective words) took 0.6s, 851098 effective words/s\n",
      "2020-02-03 22:54:56,428 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:56,442 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:56,477 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:54:56,478 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:56,490 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:54:56,491 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:54:56,502 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:54:56,503 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:54:56,504 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:54:56,511 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:54:56,513 : INFO : resetting layer weights\n",
      "2020-02-03 22:54:57,268 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:57,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:57,381 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:57,382 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:57,383 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1152322 effective words/s\n",
      "2020-02-03 22:54:57,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:57,493 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:57,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:57,496 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 1142789 effective words/s\n",
      "2020-02-03 22:54:57,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:57,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:57,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:57,614 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 1076876 effective words/s\n",
      "2020-02-03 22:54:57,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:57,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:57,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:57,715 : INFO : EPOCH - 4 : training on 175599 raw words (110337 effective words) took 0.1s, 1289892 effective words/s\n",
      "2020-02-03 22:54:57,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:57,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:57,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:57,814 : INFO : EPOCH - 5 : training on 175599 raw words (110226 effective words) took 0.1s, 1314573 effective words/s\n",
      "2020-02-03 22:54:57,815 : INFO : training on a 877995 raw words (551326 effective words) took 0.5s, 1009492 effective words/s\n",
      "2020-02-03 22:54:57,818 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:57,831 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:57,865 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:54:57,866 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:57,880 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:54:57,881 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:54:57,895 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:54:57,896 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:54:57,896 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:54:57,907 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:54:57,907 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 1.7585968971252441, 'train_time_std': 0.40717185435063274}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:54:58,738 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:54:58,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:58,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:58,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:58,848 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1211352 effective words/s\n",
      "2020-02-03 22:54:58,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:58,952 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:58,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:58,954 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.1s, 1203785 effective words/s\n",
      "2020-02-03 22:54:59,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:59,053 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:59,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:59,055 : INFO : EPOCH - 3 : training on 175599 raw words (110076 effective words) took 0.1s, 1278824 effective words/s\n",
      "2020-02-03 22:54:59,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:59,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:59,161 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:59,162 : INFO : EPOCH - 4 : training on 175599 raw words (110309 effective words) took 0.1s, 1194886 effective words/s\n",
      "2020-02-03 22:54:59,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:54:59,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:54:59,276 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:54:59,277 : INFO : EPOCH - 5 : training on 175599 raw words (110396 effective words) took 0.1s, 1105115 effective words/s\n",
      "2020-02-03 22:54:59,277 : INFO : training on a 877995 raw words (551240 effective words) took 0.5s, 1023837 effective words/s\n",
      "2020-02-03 22:54:59,280 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:54:59,293 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:54:59,326 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:54:59,327 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:54:59,339 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:54:59,340 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:54:59,351 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:54:59,352 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:54:59,353 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:54:59,363 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:54:59,363 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:00,152 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:00,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:00,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:00,254 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:00,255 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.1s, 1293790 effective words/s\n",
      "2020-02-03 22:55:00,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:00,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:00,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:00,361 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.1s, 1216949 effective words/s\n",
      "2020-02-03 22:55:00,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:00,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:00,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:00,462 : INFO : EPOCH - 3 : training on 175599 raw words (110137 effective words) took 0.1s, 1351294 effective words/s\n",
      "2020-02-03 22:55:00,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:00,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:00,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:00,558 : INFO : EPOCH - 4 : training on 175599 raw words (110112 effective words) took 0.1s, 1332105 effective words/s\n",
      "2020-02-03 22:55:00,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:00,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:00,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:00,661 : INFO : EPOCH - 5 : training on 175599 raw words (110207 effective words) took 0.1s, 1271037 effective words/s\n",
      "2020-02-03 22:55:00,662 : INFO : training on a 877995 raw words (550954 effective words) took 0.5s, 1083030 effective words/s\n",
      "2020-02-03 22:55:00,665 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:00,678 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:00,716 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:00,716 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:00,729 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:00,729 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:00,742 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:00,743 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:00,744 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:00,754 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:00,755 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:01,538 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:01,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:01,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:01,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:01,658 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1067930 effective words/s\n",
      "2020-02-03 22:55:01,756 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:01,758 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:01,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:01,760 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 1268860 effective words/s\n",
      "2020-02-03 22:55:01,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:01,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:01,855 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:01,855 : INFO : EPOCH - 3 : training on 175599 raw words (110099 effective words) took 0.1s, 1367152 effective words/s\n",
      "2020-02-03 22:55:01,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:01,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:01,947 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:01,947 : INFO : EPOCH - 4 : training on 175599 raw words (110132 effective words) took 0.1s, 1401890 effective words/s\n",
      "2020-02-03 22:55:02,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:02,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:02,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:02,035 : INFO : EPOCH - 5 : training on 175599 raw words (110161 effective words) took 0.1s, 1475328 effective words/s\n",
      "2020-02-03 22:55:02,036 : INFO : training on a 877995 raw words (550803 effective words) took 0.5s, 1108736 effective words/s\n",
      "2020-02-03 22:55:02,040 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:02,054 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:02,089 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:02,089 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:02,101 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:02,101 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:02,113 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:02,114 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:02,115 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:02,119 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:02,203 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:02,212 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:02,213 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 1.407256046930949, 'train_time_std': 0.03917851311917621}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:03,023 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:03,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:03,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:03,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:03,241 : INFO : EPOCH - 1 : training on 175599 raw words (110285 effective words) took 0.2s, 546413 effective words/s\n",
      "2020-02-03 22:55:03,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:03,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:03,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:03,432 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.2s, 639918 effective words/s\n",
      "2020-02-03 22:55:03,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:03,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:03,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:03,633 : INFO : EPOCH - 3 : training on 175599 raw words (110317 effective words) took 0.2s, 595843 effective words/s\n",
      "2020-02-03 22:55:03,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:03,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:03,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:03,847 : INFO : EPOCH - 4 : training on 175599 raw words (109893 effective words) took 0.2s, 556238 effective words/s\n",
      "2020-02-03 22:55:04,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:04,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:04,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:04,085 : INFO : EPOCH - 5 : training on 175599 raw words (110157 effective words) took 0.2s, 500210 effective words/s\n",
      "2020-02-03 22:55:04,086 : INFO : training on a 877995 raw words (550866 effective words) took 1.1s, 518932 effective words/s\n",
      "2020-02-03 22:55:04,088 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:04,103 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:04,141 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:04,142 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:04,154 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:04,154 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:04,167 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:04,168 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:04,169 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:04,173 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:04,272 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:04,279 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:04,280 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:05,061 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:05,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:05,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:05,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:05,237 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 692603 effective words/s\n",
      "2020-02-03 22:55:05,412 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:05,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:05,422 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:05,422 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 0.2s, 659458 effective words/s\n",
      "2020-02-03 22:55:05,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:05,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:05,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:05,601 : INFO : EPOCH - 3 : training on 175599 raw words (110068 effective words) took 0.2s, 673333 effective words/s\n",
      "2020-02-03 22:55:05,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:05,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:05,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:05,782 : INFO : EPOCH - 4 : training on 175599 raw words (110128 effective words) took 0.2s, 673211 effective words/s\n",
      "2020-02-03 22:55:05,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:05,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:05,967 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:05,968 : INFO : EPOCH - 5 : training on 175599 raw words (109982 effective words) took 0.2s, 641703 effective words/s\n",
      "2020-02-03 22:55:05,969 : INFO : training on a 877995 raw words (550349 effective words) took 0.9s, 606987 effective words/s\n",
      "2020-02-03 22:55:05,974 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:05,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:06,029 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:06,029 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:06,042 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:06,043 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:06,055 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:06,056 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:06,057 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:06,061 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:06,145 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:06,151 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:06,152 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:06,973 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:07,133 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:07,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:07,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:07,148 : INFO : EPOCH - 1 : training on 175599 raw words (110202 effective words) took 0.2s, 688099 effective words/s\n",
      "2020-02-03 22:55:07,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:07,332 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:07,338 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:07,339 : INFO : EPOCH - 2 : training on 175599 raw words (110209 effective words) took 0.2s, 634291 effective words/s\n",
      "2020-02-03 22:55:07,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:07,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:07,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:07,524 : INFO : EPOCH - 3 : training on 175599 raw words (110217 effective words) took 0.2s, 651422 effective words/s\n",
      "2020-02-03 22:55:07,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:07,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:07,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:07,798 : INFO : EPOCH - 4 : training on 175599 raw words (110193 effective words) took 0.3s, 427209 effective words/s\n",
      "2020-02-03 22:55:07,985 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:07,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:07,998 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:07,999 : INFO : EPOCH - 5 : training on 175599 raw words (110258 effective words) took 0.2s, 595028 effective words/s\n",
      "2020-02-03 22:55:08,000 : INFO : training on a 877995 raw words (551079 effective words) took 1.0s, 537199 effective words/s\n",
      "2020-02-03 22:55:08,006 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:08,021 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:08,058 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:08,059 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:08,071 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:08,072 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:08,085 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:08,087 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:08,087 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:08,092 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:08,188 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:08,195 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:08,196 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 1.988530953725179, 'train_time_std': 0.07284101358439658}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:09,044 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:09,270 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:09,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:09,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:09,278 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.2s, 505477 effective words/s\n",
      "2020-02-03 22:55:09,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:09,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:09,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:09,496 : INFO : EPOCH - 2 : training on 175599 raw words (110137 effective words) took 0.2s, 543612 effective words/s\n",
      "2020-02-03 22:55:09,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:09,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:09,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:09,677 : INFO : EPOCH - 3 : training on 175599 raw words (110210 effective words) took 0.2s, 658202 effective words/s\n",
      "2020-02-03 22:55:09,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:09,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:09,870 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:09,871 : INFO : EPOCH - 4 : training on 175599 raw words (110106 effective words) took 0.2s, 632617 effective words/s\n",
      "2020-02-03 22:55:10,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:10,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:10,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:10,075 : INFO : EPOCH - 5 : training on 175599 raw words (110377 effective words) took 0.2s, 579898 effective words/s\n",
      "2020-02-03 22:55:10,076 : INFO : training on a 877995 raw words (551114 effective words) took 1.0s, 534334 effective words/s\n",
      "2020-02-03 22:55:10,082 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:10,095 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:10,133 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:10,133 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:10,146 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:10,147 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:10,160 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:10,161 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:10,162 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:10,166 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:10,252 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:10,258 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:10,259 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:11,077 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:11,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:11,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:11,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:11,259 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 674500 effective words/s\n",
      "2020-02-03 22:55:11,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:11,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:11,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:11,484 : INFO : EPOCH - 2 : training on 175599 raw words (110193 effective words) took 0.2s, 526011 effective words/s\n",
      "2020-02-03 22:55:11,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:11,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:11,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:11,683 : INFO : EPOCH - 3 : training on 175599 raw words (110172 effective words) took 0.2s, 601064 effective words/s\n",
      "2020-02-03 22:55:11,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:11,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:11,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:11,861 : INFO : EPOCH - 4 : training on 175599 raw words (110155 effective words) took 0.2s, 683213 effective words/s\n",
      "2020-02-03 22:55:12,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:12,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:12,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:12,039 : INFO : EPOCH - 5 : training on 175599 raw words (110257 effective words) took 0.2s, 674205 effective words/s\n",
      "2020-02-03 22:55:12,039 : INFO : training on a 877995 raw words (551121 effective words) took 1.0s, 573562 effective words/s\n",
      "2020-02-03 22:55:12,045 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:12,059 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:12,092 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:12,093 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:12,104 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:12,105 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:12,116 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:12,117 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:12,118 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:12,122 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:12,212 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:12,219 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:12,219 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:13,025 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:13,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:13,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:13,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:13,191 : INFO : EPOCH - 1 : training on 175599 raw words (110202 effective words) took 0.2s, 727926 effective words/s\n",
      "2020-02-03 22:55:13,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:13,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:13,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:13,353 : INFO : EPOCH - 2 : training on 175599 raw words (110006 effective words) took 0.1s, 739817 effective words/s\n",
      "2020-02-03 22:55:13,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:13,519 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:13,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:13,525 : INFO : EPOCH - 3 : training on 175599 raw words (110339 effective words) took 0.2s, 693839 effective words/s\n",
      "2020-02-03 22:55:13,700 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:13,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:13,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:13,706 : INFO : EPOCH - 4 : training on 175599 raw words (110332 effective words) took 0.2s, 666317 effective words/s\n",
      "2020-02-03 22:55:13,881 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:13,883 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:13,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:13,891 : INFO : EPOCH - 5 : training on 175599 raw words (110258 effective words) took 0.2s, 643391 effective words/s\n",
      "2020-02-03 22:55:13,892 : INFO : training on a 877995 raw words (551137 effective words) took 0.9s, 636350 effective words/s\n",
      "2020-02-03 22:55:13,898 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:13,912 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:13,951 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:13,952 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:13,965 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:13,966 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:13,980 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:13,981 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:13,982 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:13,990 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:13,992 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 1.9638365109761555, 'train_time_std': 0.09133045537800726}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:14,816 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:15,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:15,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:15,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:15,082 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.3s, 439515 effective words/s\n",
      "2020-02-03 22:55:15,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:15,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:15,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:15,352 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 0.3s, 430340 effective words/s\n",
      "2020-02-03 22:55:15,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:15,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:15,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:15,623 : INFO : EPOCH - 3 : training on 175599 raw words (110068 effective words) took 0.3s, 429063 effective words/s\n",
      "2020-02-03 22:55:15,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:15,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:15,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:15,887 : INFO : EPOCH - 4 : training on 175599 raw words (110173 effective words) took 0.3s, 438305 effective words/s\n",
      "2020-02-03 22:55:16,130 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:16,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:16,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:16,143 : INFO : EPOCH - 5 : training on 175599 raw words (110246 effective words) took 0.2s, 455056 effective words/s\n",
      "2020-02-03 22:55:16,144 : INFO : training on a 877995 raw words (550658 effective words) took 1.3s, 414926 effective words/s\n",
      "2020-02-03 22:55:16,149 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:16,163 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:16,199 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:16,200 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:16,213 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:16,213 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:16,225 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:16,227 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:16,227 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:16,236 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:16,236 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:17,068 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:17,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:17,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:17,383 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:17,384 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 369372 effective words/s\n",
      "2020-02-03 22:55:17,649 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:17,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:17,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:17,664 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.3s, 414423 effective words/s\n",
      "2020-02-03 22:55:17,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:17,923 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:17,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:17,933 : INFO : EPOCH - 3 : training on 175599 raw words (110334 effective words) took 0.3s, 433287 effective words/s\n",
      "2020-02-03 22:55:18,187 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:18,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:18,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:18,199 : INFO : EPOCH - 4 : training on 175599 raw words (110122 effective words) took 0.3s, 436645 effective words/s\n",
      "2020-02-03 22:55:18,458 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:18,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:18,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:18,471 : INFO : EPOCH - 5 : training on 175599 raw words (110093 effective words) took 0.3s, 425900 effective words/s\n",
      "2020-02-03 22:55:18,472 : INFO : training on a 877995 raw words (551107 effective words) took 1.4s, 392666 effective words/s\n",
      "2020-02-03 22:55:18,475 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:18,489 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:18,525 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:18,526 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:18,539 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:18,539 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:18,553 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:18,555 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:18,556 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:18,564 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:18,565 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:19,930 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:20,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:20,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:20,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:20,241 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 375518 effective words/s\n",
      "2020-02-03 22:55:20,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:20,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:20,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:20,538 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.3s, 390158 effective words/s\n",
      "2020-02-03 22:55:20,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:20,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:20,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:20,799 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.2s, 446448 effective words/s\n",
      "2020-02-03 22:55:21,045 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:21,048 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:21,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:21,057 : INFO : EPOCH - 4 : training on 175599 raw words (110224 effective words) took 0.2s, 450915 effective words/s\n",
      "2020-02-03 22:55:21,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:21,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:21,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:21,320 : INFO : EPOCH - 5 : training on 175599 raw words (110027 effective words) took 0.3s, 440053 effective words/s\n",
      "2020-02-03 22:55:21,321 : INFO : training on a 877995 raw words (551014 effective words) took 1.4s, 396424 effective words/s\n",
      "2020-02-03 22:55:21,324 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:21,338 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:21,374 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:21,375 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:21,386 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:21,387 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:21,398 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:21,399 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:21,399 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:21,408 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:21,409 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 2.4752933979034424, 'train_time_std': 0.26572930944761375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:22,175 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:22,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:22,417 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:22,429 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:22,429 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 460800 effective words/s\n",
      "2020-02-03 22:55:22,700 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:22,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:22,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:22,713 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.3s, 410299 effective words/s\n",
      "2020-02-03 22:55:22,960 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:22,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:22,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:22,972 : INFO : EPOCH - 3 : training on 175599 raw words (110080 effective words) took 0.2s, 449450 effective words/s\n",
      "2020-02-03 22:55:23,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:23,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:23,225 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:23,226 : INFO : EPOCH - 4 : training on 175599 raw words (110320 effective words) took 0.2s, 459956 effective words/s\n",
      "2020-02-03 22:55:23,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:23,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:23,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:23,475 : INFO : EPOCH - 5 : training on 175599 raw words (110064 effective words) took 0.2s, 465548 effective words/s\n",
      "2020-02-03 22:55:23,476 : INFO : training on a 877995 raw words (550495 effective words) took 1.3s, 423344 effective words/s\n",
      "2020-02-03 22:55:23,479 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:23,492 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:23,526 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:23,527 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:23,540 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:23,540 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:23,556 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:23,557 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:23,558 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:23,568 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:23,569 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:24,356 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:24,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:24,614 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:24,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:24,626 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.3s, 433494 effective words/s\n",
      "2020-02-03 22:55:24,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:24,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:24,880 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:24,882 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.2s, 456825 effective words/s\n",
      "2020-02-03 22:55:25,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:25,162 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:25,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:25,174 : INFO : EPOCH - 3 : training on 175599 raw words (110315 effective words) took 0.3s, 397113 effective words/s\n",
      "2020-02-03 22:55:25,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:25,438 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:25,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:25,442 : INFO : EPOCH - 4 : training on 175599 raw words (110241 effective words) took 0.3s, 434182 effective words/s\n",
      "2020-02-03 22:55:25,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:25,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:25,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:25,720 : INFO : EPOCH - 5 : training on 175599 raw words (110344 effective words) took 0.3s, 417479 effective words/s\n",
      "2020-02-03 22:55:25,721 : INFO : training on a 877995 raw words (551458 effective words) took 1.4s, 404531 effective words/s\n",
      "2020-02-03 22:55:25,724 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:25,737 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:25,774 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:25,775 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:25,787 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:25,788 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:25,800 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:25,801 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:25,802 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:25,814 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-02-03 22:55:25,814 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:26,633 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:26,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:26,882 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:26,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:26,887 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.2s, 463654 effective words/s\n",
      "2020-02-03 22:55:27,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:27,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:27,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:27,143 : INFO : EPOCH - 2 : training on 175599 raw words (110198 effective words) took 0.2s, 455624 effective words/s\n",
      "2020-02-03 22:55:27,417 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:27,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:27,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:27,436 : INFO : EPOCH - 3 : training on 175599 raw words (110258 effective words) took 0.3s, 394625 effective words/s\n",
      "2020-02-03 22:55:27,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:27,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:27,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:27,723 : INFO : EPOCH - 4 : training on 175599 raw words (110278 effective words) took 0.3s, 408633 effective words/s\n",
      "2020-02-03 22:55:27,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:27,973 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:27,982 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:27,982 : INFO : EPOCH - 5 : training on 175599 raw words (110216 effective words) took 0.2s, 449902 effective words/s\n",
      "2020-02-03 22:55:27,983 : INFO : training on a 877995 raw words (551234 effective words) took 1.3s, 408368 effective words/s\n",
      "2020-02-03 22:55:27,986 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:27,999 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:28,033 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:28,034 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:28,045 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:28,046 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:28,057 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:28,058 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:28,059 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:28,063 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:28,151 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:28,159 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:28,160 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 2.220606009165446, 'train_time_std': 0.04694651771730856}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:28,957 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:29,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:29,509 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:29,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:29,519 : INFO : EPOCH - 1 : training on 175599 raw words (110226 effective words) took 0.5s, 202015 effective words/s\n",
      "2020-02-03 22:55:30,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:30,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:30,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:30,479 : INFO : EPOCH - 2 : training on 175599 raw words (110041 effective words) took 0.9s, 117027 effective words/s\n",
      "2020-02-03 22:55:31,085 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:31,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:31,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:31,114 : INFO : EPOCH - 3 : training on 175599 raw words (110103 effective words) took 0.6s, 178854 effective words/s\n",
      "2020-02-03 22:55:31,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:31,717 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:31,723 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:31,724 : INFO : EPOCH - 4 : training on 175599 raw words (110279 effective words) took 0.6s, 185699 effective words/s\n",
      "2020-02-03 22:55:32,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:32,283 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:32,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:32,289 : INFO : EPOCH - 5 : training on 175599 raw words (110352 effective words) took 0.5s, 201356 effective words/s\n",
      "2020-02-03 22:55:32,290 : INFO : training on a 877995 raw words (551001 effective words) took 3.3s, 165353 effective words/s\n",
      "2020-02-03 22:55:32,292 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:32,305 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:32,342 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:32,343 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:32,355 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:32,355 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:32,368 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:32,369 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:32,370 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:32,374 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:32,464 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:32,470 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:32,471 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:33,264 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:33,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:33,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:33,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:33,855 : INFO : EPOCH - 1 : training on 175599 raw words (110146 effective words) took 0.6s, 191271 effective words/s\n",
      "2020-02-03 22:55:34,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:34,414 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:34,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:34,421 : INFO : EPOCH - 2 : training on 175599 raw words (110087 effective words) took 0.5s, 200823 effective words/s\n",
      "2020-02-03 22:55:34,956 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:34,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:34,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:34,985 : INFO : EPOCH - 3 : training on 175599 raw words (110174 effective words) took 0.5s, 201224 effective words/s\n",
      "2020-02-03 22:55:35,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:35,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:35,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:35,552 : INFO : EPOCH - 4 : training on 175599 raw words (110244 effective words) took 0.6s, 200035 effective words/s\n",
      "2020-02-03 22:55:36,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:36,114 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:36,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:36,122 : INFO : EPOCH - 5 : training on 175599 raw words (110214 effective words) took 0.6s, 198939 effective words/s\n",
      "2020-02-03 22:55:36,123 : INFO : training on a 877995 raw words (550865 effective words) took 2.9s, 192746 effective words/s\n",
      "2020-02-03 22:55:36,128 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:36,141 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:36,177 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:36,178 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:36,190 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:36,190 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:36,202 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:36,203 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:36,204 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:36,208 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:36,295 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:36,301 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:36,302 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:37,069 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:37,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:37,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:37,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:37,618 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.5s, 206475 effective words/s\n",
      "2020-02-03 22:55:38,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:38,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:38,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:38,155 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.5s, 210889 effective words/s\n",
      "2020-02-03 22:55:38,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:38,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:38,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:38,748 : INFO : EPOCH - 3 : training on 175599 raw words (110080 effective words) took 0.6s, 190861 effective words/s\n",
      "2020-02-03 22:55:39,333 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:39,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:39,364 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:39,365 : INFO : EPOCH - 4 : training on 175599 raw words (110224 effective words) took 0.6s, 183500 effective words/s\n",
      "2020-02-03 22:55:39,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:39,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:39,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:39,967 : INFO : EPOCH - 5 : training on 175599 raw words (110239 effective words) took 0.6s, 188255 effective words/s\n",
      "2020-02-03 22:55:39,968 : INFO : training on a 877995 raw words (550574 effective words) took 2.9s, 189971 effective words/s\n",
      "2020-02-03 22:55:39,974 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:39,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:40,030 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:40,031 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:40,046 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:40,047 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:40,061 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:40,063 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:40,064 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:40,069 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:40,163 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:40,171 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:40,171 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 3.9957686265309653, 'train_time_std': 0.2193048492510622}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:40,996 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:41,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:41,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:41,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:41,560 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.5s, 201082 effective words/s\n",
      "2020-02-03 22:55:42,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:42,119 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:42,129 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:42,130 : INFO : EPOCH - 2 : training on 175599 raw words (110124 effective words) took 0.6s, 199558 effective words/s\n",
      "2020-02-03 22:55:42,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:42,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:42,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:42,677 : INFO : EPOCH - 3 : training on 175599 raw words (110278 effective words) took 0.5s, 207164 effective words/s\n",
      "2020-02-03 22:55:43,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:43,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:43,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:43,224 : INFO : EPOCH - 4 : training on 175599 raw words (110278 effective words) took 0.5s, 207712 effective words/s\n",
      "2020-02-03 22:55:43,741 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:43,762 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:43,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:43,768 : INFO : EPOCH - 5 : training on 175599 raw words (110216 effective words) took 0.5s, 208245 effective words/s\n",
      "2020-02-03 22:55:43,768 : INFO : training on a 877995 raw words (551240 effective words) took 2.8s, 198853 effective words/s\n",
      "2020-02-03 22:55:43,773 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:43,786 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:43,819 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:43,820 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:43,832 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:43,832 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:43,844 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:43,845 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:43,846 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:43,849 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:43,933 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:43,939 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:43,940 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:44,723 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:45,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:45,263 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:45,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:45,273 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.5s, 206512 effective words/s\n",
      "2020-02-03 22:55:45,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:45,835 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:45,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:45,845 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.6s, 197942 effective words/s\n",
      "2020-02-03 22:55:46,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:46,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:46,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:46,434 : INFO : EPOCH - 3 : training on 175599 raw words (110271 effective words) took 0.6s, 192273 effective words/s\n",
      "2020-02-03 22:55:46,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:47,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:47,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:47,014 : INFO : EPOCH - 4 : training on 175599 raw words (110091 effective words) took 0.6s, 195347 effective words/s\n",
      "2020-02-03 22:55:47,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:47,549 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:47,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:47,563 : INFO : EPOCH - 5 : training on 175599 raw words (110341 effective words) took 0.5s, 206499 effective words/s\n",
      "2020-02-03 22:55:47,564 : INFO : training on a 877995 raw words (551201 effective words) took 2.8s, 194090 effective words/s\n",
      "2020-02-03 22:55:47,569 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:55:47,583 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:47,622 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-02-03 22:55:47,623 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:47,637 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-02-03 22:55:47,638 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-02-03 22:55:47,652 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-02-03 22:55:47,654 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-02-03 22:55:47,654 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-02-03 22:55:47,658 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-02-03 22:55:47,762 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-02-03 22:55:47,772 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-02-03 22:55:47,773 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:49,023 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:49,606 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:49,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:49,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:49,638 : INFO : EPOCH - 1 : training on 175599 raw words (110382 effective words) took 0.6s, 184518 effective words/s\n",
      "2020-02-03 22:55:50,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:50,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:50,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:50,231 : INFO : EPOCH - 2 : training on 175599 raw words (110231 effective words) took 0.6s, 190869 effective words/s\n",
      "2020-02-03 22:55:50,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:50,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:50,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:50,773 : INFO : EPOCH - 3 : training on 175599 raw words (110030 effective words) took 0.5s, 208634 effective words/s\n",
      "2020-02-03 22:55:51,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:51,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:51,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:51,343 : INFO : EPOCH - 4 : training on 175599 raw words (110323 effective words) took 0.6s, 198451 effective words/s\n",
      "2020-02-03 22:55:51,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:51,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:51,911 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:51,912 : INFO : EPOCH - 5 : training on 175599 raw words (110162 effective words) took 0.6s, 198707 effective words/s\n",
      "2020-02-03 22:55:51,913 : INFO : training on a 877995 raw words (551128 effective words) took 2.9s, 190723 effective words/s\n",
      "2020-02-03 22:55:51,918 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 3.9813363552093506, 'train_time_std': 0.2596908837737627}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:55:52,124 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:55:52,482 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:55:52,482 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:55:52,530 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:55:52,531 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:55:52,589 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:55:52,594 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:55:52,595 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:55:52,651 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:55:52,652 : INFO : resetting layer weights\n",
      "2020-02-03 22:55:56,460 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:55:57,481 : INFO : EPOCH 1 - PROGRESS: at 64.25% examples, 796027 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:55:57,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:57,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:57,999 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:58,000 : INFO : EPOCH - 1 : training on 1788017 raw words (1242171 effective words) took 1.5s, 816291 effective words/s\n",
      "2020-02-03 22:55:59,022 : INFO : EPOCH 2 - PROGRESS: at 58.10% examples, 723914 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:55:59,864 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:55:59,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:55:59,874 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:55:59,875 : INFO : EPOCH - 2 : training on 1788017 raw words (1242485 effective words) took 1.9s, 670569 effective words/s\n",
      "2020-02-03 22:56:00,907 : INFO : EPOCH 3 - PROGRESS: at 69.27% examples, 849232 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:01,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:01,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:01,314 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:01,314 : INFO : EPOCH - 3 : training on 1788017 raw words (1241612 effective words) took 1.4s, 874048 effective words/s\n",
      "2020-02-03 22:56:02,341 : INFO : EPOCH 4 - PROGRESS: at 75.98% examples, 944234 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:02,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:02,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:02,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:02,675 : INFO : EPOCH - 4 : training on 1788017 raw words (1243104 effective words) took 1.3s, 931122 effective words/s\n",
      "2020-02-03 22:56:03,707 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 898935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:04,033 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:04,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:04,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:04,043 : INFO : EPOCH - 5 : training on 1788017 raw words (1242160 effective words) took 1.3s, 920995 effective words/s\n",
      "2020-02-03 22:56:04,044 : INFO : training on a 8940085 raw words (6211532 effective words) took 7.6s, 819174 effective words/s\n",
      "2020-02-03 22:56:04,050 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:56:04,176 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:56:04,564 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:56:04,565 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:56:04,636 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:56:04,636 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:56:04,708 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:56:04,713 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:56:04,713 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:56:04,779 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:56:04,780 : INFO : resetting layer weights\n",
      "2020-02-03 22:56:08,745 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:56:09,763 : INFO : EPOCH 1 - PROGRESS: at 63.13% examples, 783984 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:10,222 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:10,230 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:10,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:10,233 : INFO : EPOCH - 1 : training on 1788017 raw words (1241961 effective words) took 1.5s, 845210 effective words/s\n",
      "2020-02-03 22:56:11,256 : INFO : EPOCH 2 - PROGRESS: at 69.27% examples, 859519 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:11,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:11,624 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:11,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:11,629 : INFO : EPOCH - 2 : training on 1788017 raw words (1242801 effective words) took 1.4s, 904032 effective words/s\n",
      "2020-02-03 22:56:12,652 : INFO : EPOCH 3 - PROGRESS: at 73.18% examples, 908821 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:13,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:13,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:13,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:13,080 : INFO : EPOCH - 3 : training on 1788017 raw words (1242702 effective words) took 1.4s, 869988 effective words/s\n",
      "2020-02-03 22:56:14,108 : INFO : EPOCH 4 - PROGRESS: at 66.48% examples, 821691 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:14,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:14,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:14,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:14,619 : INFO : EPOCH - 4 : training on 1788017 raw words (1242161 effective words) took 1.5s, 819310 effective words/s\n",
      "2020-02-03 22:56:15,691 : INFO : EPOCH 5 - PROGRESS: at 80.45% examples, 995737 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:15,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:15,980 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:15,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:15,987 : INFO : EPOCH - 5 : training on 1788017 raw words (1242690 effective words) took 1.3s, 954656 effective words/s\n",
      "2020-02-03 22:56:15,988 : INFO : training on a 8940085 raw words (6212315 effective words) took 7.2s, 857722 effective words/s\n",
      "2020-02-03 22:56:16,000 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:56:16,145 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:56:16,562 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:56:16,563 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:56:16,618 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:56:16,619 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:56:16,681 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:56:16,686 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:56:16,688 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:56:16,763 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:56:16,763 : INFO : resetting layer weights\n",
      "2020-02-03 22:56:20,955 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:56:21,982 : INFO : EPOCH 1 - PROGRESS: at 70.39% examples, 868730 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:22,337 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:22,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:22,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:22,348 : INFO : EPOCH - 1 : training on 1788017 raw words (1242443 effective words) took 1.4s, 904943 effective words/s\n",
      "2020-02-03 22:56:23,376 : INFO : EPOCH 2 - PROGRESS: at 69.27% examples, 858443 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:56:23,806 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:23,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:23,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:23,819 : INFO : EPOCH - 2 : training on 1788017 raw words (1242581 effective words) took 1.4s, 859170 effective words/s\n",
      "2020-02-03 22:56:24,845 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 871511 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:25,200 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:25,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:25,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:25,212 : INFO : EPOCH - 3 : training on 1788017 raw words (1242192 effective words) took 1.4s, 906373 effective words/s\n",
      "2020-02-03 22:56:26,242 : INFO : EPOCH 4 - PROGRESS: at 69.27% examples, 853866 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:56:26,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:26,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:26,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:26,667 : INFO : EPOCH - 4 : training on 1788017 raw words (1242167 effective words) took 1.4s, 867193 effective words/s\n",
      "2020-02-03 22:56:27,693 : INFO : EPOCH 5 - PROGRESS: at 62.01% examples, 767977 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:28,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:28,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:28,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:28,207 : INFO : EPOCH - 5 : training on 1788017 raw words (1241825 effective words) took 1.5s, 818361 effective words/s\n",
      "2020-02-03 22:56:28,208 : INFO : training on a 8940085 raw words (6211208 effective words) took 7.3s, 856470 effective words/s\n",
      "2020-02-03 22:56:28,215 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:56:28,342 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 12.098690430323282, 'train_time_std': 0.11005429577102101}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:56:28,817 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:56:28,818 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:56:28,875 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:56:28,876 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:56:28,935 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:56:28,940 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:56:28,940 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:56:29,004 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:56:29,004 : INFO : resetting layer weights\n",
      "2020-02-03 22:56:33,086 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:56:34,112 : INFO : EPOCH 1 - PROGRESS: at 63.69% examples, 787654 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:34,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:34,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:34,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:34,586 : INFO : EPOCH - 1 : training on 1788017 raw words (1242418 effective words) took 1.5s, 840151 effective words/s\n",
      "2020-02-03 22:56:35,610 : INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 899990 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:35,947 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:35,955 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:35,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:35,958 : INFO : EPOCH - 2 : training on 1788017 raw words (1242081 effective words) took 1.4s, 919467 effective words/s\n",
      "2020-02-03 22:56:36,987 : INFO : EPOCH 3 - PROGRESS: at 65.36% examples, 808163 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:37,486 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:37,494 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:37,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:37,496 : INFO : EPOCH - 3 : training on 1788017 raw words (1242494 effective words) took 1.5s, 820259 effective words/s\n",
      "2020-02-03 22:56:38,522 : INFO : EPOCH 4 - PROGRESS: at 82.12% examples, 1015863 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:38,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:38,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:38,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:38,756 : INFO : EPOCH - 4 : training on 1788017 raw words (1241983 effective words) took 1.2s, 1002729 effective words/s\n",
      "2020-02-03 22:56:39,789 : INFO : EPOCH 5 - PROGRESS: at 74.86% examples, 920453 words/s, in_qsize 3, out_qsize 2\n",
      "2020-02-03 22:56:40,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:40,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:40,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:40,073 : INFO : EPOCH - 5 : training on 1788017 raw words (1242608 effective words) took 1.3s, 959422 effective words/s\n",
      "2020-02-03 22:56:40,074 : INFO : training on a 8940085 raw words (6211584 effective words) took 7.0s, 889035 effective words/s\n",
      "2020-02-03 22:56:40,083 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:56:40,228 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:56:40,649 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:56:40,650 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:56:40,701 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:56:40,702 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:56:40,757 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:56:40,761 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:56:40,762 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:56:40,815 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:56:40,815 : INFO : resetting layer weights\n",
      "2020-02-03 22:56:44,690 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:56:45,711 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 1111086 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:45,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:45,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:45,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:45,833 : INFO : EPOCH - 1 : training on 1788017 raw words (1241496 effective words) took 1.1s, 1106710 effective words/s\n",
      "2020-02-03 22:56:46,863 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 1081615 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:46,992 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:47,000 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:47,002 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:47,003 : INFO : EPOCH - 2 : training on 1788017 raw words (1242384 effective words) took 1.1s, 1081761 effective words/s\n",
      "2020-02-03 22:56:48,028 : INFO : EPOCH 3 - PROGRESS: at 91.06% examples, 1127199 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:48,132 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:48,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:48,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:48,141 : INFO : EPOCH - 3 : training on 1788017 raw words (1241834 effective words) took 1.1s, 1110674 effective words/s\n",
      "2020-02-03 22:56:49,161 : INFO : EPOCH 4 - PROGRESS: at 79.33% examples, 985967 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:49,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:49,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:49,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:49,387 : INFO : EPOCH - 4 : training on 1788017 raw words (1241886 effective words) took 1.2s, 1012634 effective words/s\n",
      "2020-02-03 22:56:50,413 : INFO : EPOCH 5 - PROGRESS: at 82.12% examples, 1015537 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:50,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:50,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:50,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:50,634 : INFO : EPOCH - 5 : training on 1788017 raw words (1242190 effective words) took 1.2s, 1012564 effective words/s\n",
      "2020-02-03 22:56:50,636 : INFO : training on a 8940085 raw words (6209790 effective words) took 5.9s, 1044483 effective words/s\n",
      "2020-02-03 22:56:50,646 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:56:50,782 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:56:51,197 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:56:51,198 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:56:51,252 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:56:51,253 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:56:51,318 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:56:51,322 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:56:51,322 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:56:51,386 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:56:51,387 : INFO : resetting layer weights\n",
      "2020-02-03 22:56:55,275 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:56:56,302 : INFO : EPOCH 1 - PROGRESS: at 73.74% examples, 911231 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:56,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:56,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:56,659 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:56,659 : INFO : EPOCH - 1 : training on 1788017 raw words (1242614 effective words) took 1.4s, 911226 effective words/s\n",
      "2020-02-03 22:56:57,687 : INFO : EPOCH 2 - PROGRESS: at 73.18% examples, 906237 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:56:58,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:58,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:58,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:58,032 : INFO : EPOCH - 2 : training on 1788017 raw words (1242993 effective words) took 1.3s, 921205 effective words/s\n",
      "2020-02-03 22:56:59,063 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 838992 words/s, in_qsize 3, out_qsize 2\n",
      "2020-02-03 22:56:59,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:56:59,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:56:59,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:56:59,548 : INFO : EPOCH - 3 : training on 1788017 raw words (1242704 effective words) took 1.5s, 831864 effective words/s\n",
      "2020-02-03 22:57:00,570 : INFO : EPOCH 4 - PROGRESS: at 79.33% examples, 984129 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:00,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:00,817 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:00,828 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:00,829 : INFO : EPOCH - 4 : training on 1788017 raw words (1241737 effective words) took 1.3s, 984279 effective words/s\n",
      "2020-02-03 22:57:01,859 : INFO : EPOCH 5 - PROGRESS: at 65.36% examples, 809793 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:02,266 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:02,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:02,280 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:02,281 : INFO : EPOCH - 5 : training on 1788017 raw words (1242364 effective words) took 1.4s, 872105 effective words/s\n",
      "2020-02-03 22:57:02,282 : INFO : training on a 8940085 raw words (6212412 effective words) took 7.0s, 886773 effective words/s\n",
      "2020-02-03 22:57:02,290 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:57:02,423 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 11.358401457468668, 'train_time_std': 0.5699301892493713}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:57:02,848 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:57:02,849 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:57:02,909 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:57:02,910 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:57:02,974 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:57:02,978 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:57:02,979 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:57:03,001 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:57:03,536 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:57:03,577 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:57:03,578 : INFO : resetting layer weights\n",
      "2020-02-03 22:57:07,502 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:57:08,530 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 425978 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:09,551 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 479491 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:10,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:10,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:10,061 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:10,061 : INFO : EPOCH - 1 : training on 1788017 raw words (1242374 effective words) took 2.5s, 489167 effective words/s\n",
      "2020-02-03 22:57:11,098 : INFO : EPOCH 2 - PROGRESS: at 36.87% examples, 457510 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:12,113 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 523812 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:12,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:12,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:12,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:12,490 : INFO : EPOCH - 2 : training on 1788017 raw words (1241871 effective words) took 2.4s, 516320 effective words/s\n",
      "2020-02-03 22:57:13,535 : INFO : EPOCH 3 - PROGRESS: at 35.20% examples, 432753 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:14,546 : INFO : EPOCH 3 - PROGRESS: at 78.77% examples, 481843 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:15,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:15,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:15,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:15,081 : INFO : EPOCH - 3 : training on 1788017 raw words (1242445 effective words) took 2.6s, 483508 effective words/s\n",
      "2020-02-03 22:57:16,137 : INFO : EPOCH 4 - PROGRESS: at 36.87% examples, 448991 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:57:17,143 : INFO : EPOCH 4 - PROGRESS: at 79.33% examples, 483986 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:17,624 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:17,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:17,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:17,659 : INFO : EPOCH - 4 : training on 1788017 raw words (1242577 effective words) took 2.6s, 486218 effective words/s\n",
      "2020-02-03 22:57:18,696 : INFO : EPOCH 5 - PROGRESS: at 33.52% examples, 416526 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:19,712 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 469273 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:20,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:20,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:20,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:20,271 : INFO : EPOCH - 5 : training on 1788017 raw words (1241737 effective words) took 2.6s, 479714 effective words/s\n",
      "2020-02-03 22:57:20,272 : INFO : training on a 8940085 raw words (6211004 effective words) took 12.8s, 486395 effective words/s\n",
      "2020-02-03 22:57:20,280 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:57:20,424 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:57:20,878 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:57:20,878 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:57:20,936 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:57:20,937 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:57:20,996 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:57:20,999 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:57:21,000 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:57:21,024 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:57:21,553 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:57:21,602 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:57:21,602 : INFO : resetting layer weights\n",
      "2020-02-03 22:57:25,459 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:57:26,485 : INFO : EPOCH 1 - PROGRESS: at 36.31% examples, 453528 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:27,515 : INFO : EPOCH 1 - PROGRESS: at 74.30% examples, 453569 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:28,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:28,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:28,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:28,378 : INFO : EPOCH - 1 : training on 1788017 raw words (1242100 effective words) took 2.9s, 428270 effective words/s\n",
      "2020-02-03 22:57:29,477 : INFO : EPOCH 2 - PROGRESS: at 25.14% examples, 296340 words/s, in_qsize 5, out_qsize 2\n",
      "2020-02-03 22:57:30,485 : INFO : EPOCH 2 - PROGRESS: at 56.98% examples, 341050 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:31,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:31,509 : INFO : EPOCH 2 - PROGRESS: at 99.44% examples, 397342 words/s, in_qsize 1, out_qsize 1\n",
      "2020-02-03 22:57:31,510 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:31,511 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:31,512 : INFO : EPOCH - 2 : training on 1788017 raw words (1241760 effective words) took 3.1s, 399223 effective words/s\n",
      "2020-02-03 22:57:32,534 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 462826 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:33,543 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 552735 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:57:33,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:33,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:33,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:33,807 : INFO : EPOCH - 3 : training on 1788017 raw words (1242130 effective words) took 2.3s, 545870 effective words/s\n",
      "2020-02-03 22:57:34,847 : INFO : EPOCH 4 - PROGRESS: at 31.84% examples, 393568 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-03 22:57:35,868 : INFO : EPOCH 4 - PROGRESS: at 68.72% examples, 418263 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-03 22:57:36,889 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 397298 words/s, in_qsize 2, out_qsize 3\n",
      "2020-02-03 22:57:36,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:57:36,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:36,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:36,921 : INFO : EPOCH - 4 : training on 1788017 raw words (1242682 effective words) took 3.1s, 401671 effective words/s\n",
      "2020-02-03 22:57:37,958 : INFO : EPOCH 5 - PROGRESS: at 35.20% examples, 436171 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:38,976 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 533041 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:39,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:39,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:39,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:39,231 : INFO : EPOCH - 5 : training on 1788017 raw words (1242037 effective words) took 2.3s, 542492 effective words/s\n",
      "2020-02-03 22:57:39,232 : INFO : training on a 8940085 raw words (6210709 effective words) took 13.8s, 450926 effective words/s\n",
      "2020-02-03 22:57:39,256 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:57:39,376 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:57:39,738 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:57:39,739 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:57:39,788 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:57:39,788 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:57:39,840 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:57:39,844 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:57:39,845 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:57:39,865 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:57:40,345 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:57:40,382 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:57:40,383 : INFO : resetting layer weights\n",
      "2020-02-03 22:57:43,985 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:57:45,011 : INFO : EPOCH 1 - PROGRESS: at 41.34% examples, 515633 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:46,013 : INFO : EPOCH 1 - PROGRESS: at 90.50% examples, 560153 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:46,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:46,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:46,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:46,230 : INFO : EPOCH - 1 : training on 1788017 raw words (1241487 effective words) took 2.2s, 557599 effective words/s\n",
      "2020-02-03 22:57:47,249 : INFO : EPOCH 2 - PROGRESS: at 41.34% examples, 519432 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:48,260 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 559796 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:48,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:48,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:48,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:48,490 : INFO : EPOCH - 2 : training on 1788017 raw words (1242129 effective words) took 2.2s, 554089 effective words/s\n",
      "2020-02-03 22:57:49,518 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 522796 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:50,519 : INFO : EPOCH 3 - PROGRESS: at 90.50% examples, 560752 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:50,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:50,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:50,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:50,747 : INFO : EPOCH - 3 : training on 1788017 raw words (1242321 effective words) took 2.2s, 555460 effective words/s\n",
      "2020-02-03 22:57:51,893 : INFO : EPOCH 4 - PROGRESS: at 46.93% examples, 579926 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:52,895 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 585540 words/s, in_qsize 6, out_qsize 2\n",
      "2020-02-03 22:57:52,978 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:52,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:52,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:52,987 : INFO : EPOCH - 4 : training on 1788017 raw words (1242409 effective words) took 2.1s, 588890 effective words/s\n",
      "2020-02-03 22:57:54,016 : INFO : EPOCH 5 - PROGRESS: at 40.78% examples, 508204 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:55,022 : INFO : EPOCH 5 - PROGRESS: at 89.39% examples, 551561 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:57:55,233 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:57:55,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:57:55,255 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:57:55,256 : INFO : EPOCH - 5 : training on 1788017 raw words (1241919 effective words) took 2.2s, 551992 effective words/s\n",
      "2020-02-03 22:57:55,256 : INFO : training on a 8940085 raw words (6210265 effective words) took 11.3s, 551063 effective words/s\n",
      "2020-02-03 22:57:55,286 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:57:55,408 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 17.665089686711628, 'train_time_std': 1.224967270064921}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:57:55,781 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:57:55,781 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:57:55,833 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:57:55,834 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:57:55,887 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:57:55,892 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:57:55,892 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:57:55,912 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:57:56,388 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:57:56,425 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:57:56,426 : INFO : resetting layer weights\n",
      "2020-02-03 22:58:00,015 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:58:01,048 : INFO : EPOCH 1 - PROGRESS: at 41.34% examples, 512140 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:02,053 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 560826 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:02,226 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:02,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:02,246 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:02,247 : INFO : EPOCH - 1 : training on 1788017 raw words (1242476 effective words) took 2.2s, 560973 effective words/s\n",
      "2020-02-03 22:58:03,273 : INFO : EPOCH 2 - PROGRESS: at 41.34% examples, 515711 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:58:04,277 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 549454 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:04,506 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:04,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:04,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:04,529 : INFO : EPOCH - 2 : training on 1788017 raw words (1242809 effective words) took 2.3s, 548867 effective words/s\n",
      "2020-02-03 22:58:05,550 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 525793 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:06,566 : INFO : EPOCH 3 - PROGRESS: at 91.06% examples, 561195 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:06,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:06,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:06,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:06,768 : INFO : EPOCH - 3 : training on 1788017 raw words (1241652 effective words) took 2.2s, 559240 effective words/s\n",
      "2020-02-03 22:58:07,794 : INFO : EPOCH 4 - PROGRESS: at 41.90% examples, 523073 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:08,796 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 560428 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:09,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:09,019 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:09,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:09,023 : INFO : EPOCH - 4 : training on 1788017 raw words (1242221 effective words) took 2.2s, 555387 effective words/s\n",
      "2020-02-03 22:58:10,050 : INFO : EPOCH 5 - PROGRESS: at 41.90% examples, 522790 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:11,053 : INFO : EPOCH 5 - PROGRESS: at 89.39% examples, 553005 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:11,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:11,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:11,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:11,279 : INFO : EPOCH - 5 : training on 1788017 raw words (1242680 effective words) took 2.2s, 555479 effective words/s\n",
      "2020-02-03 22:58:11,279 : INFO : training on a 8940085 raw words (6211838 effective words) took 11.3s, 551501 effective words/s\n",
      "2020-02-03 22:58:11,307 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:58:11,427 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:58:11,797 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:58:11,798 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:58:11,849 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:58:11,850 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:58:11,906 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:58:11,910 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:58:11,911 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:58:11,930 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:58:16,465 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:58:16,508 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:58:16,509 : INFO : resetting layer weights\n",
      "2020-02-03 22:58:20,477 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:58:21,556 : INFO : EPOCH 1 - PROGRESS: at 41.34% examples, 516527 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:22,562 : INFO : EPOCH 1 - PROGRESS: at 89.94% examples, 556055 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:22,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:22,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:22,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:22,833 : INFO : EPOCH - 1 : training on 1788017 raw words (1242416 effective words) took 2.3s, 543960 effective words/s\n",
      "2020-02-03 22:58:23,860 : INFO : EPOCH 2 - PROGRESS: at 39.11% examples, 488478 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:58:24,879 : INFO : EPOCH 2 - PROGRESS: at 87.71% examples, 538099 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:25,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:25,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:25,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:25,191 : INFO : EPOCH - 2 : training on 1788017 raw words (1241982 effective words) took 2.3s, 530976 effective words/s\n",
      "2020-02-03 22:58:26,219 : INFO : EPOCH 3 - PROGRESS: at 35.20% examples, 440686 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:58:27,229 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 506790 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:27,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:27,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:27,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:27,652 : INFO : EPOCH - 3 : training on 1788017 raw words (1242311 effective words) took 2.4s, 509561 effective words/s\n",
      "2020-02-03 22:58:28,675 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 441707 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:58:29,705 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 461699 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:30,328 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:30,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:30,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:58:30,352 : INFO : EPOCH - 4 : training on 1788017 raw words (1242861 effective words) took 2.7s, 463804 effective words/s\n",
      "2020-02-03 22:58:31,378 : INFO : EPOCH 5 - PROGRESS: at 35.20% examples, 439994 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:32,393 : INFO : EPOCH 5 - PROGRESS: at 83.80% examples, 515415 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:32,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:32,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:32,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:32,775 : INFO : EPOCH - 5 : training on 1788017 raw words (1242278 effective words) took 2.4s, 516652 effective words/s\n",
      "2020-02-03 22:58:32,776 : INFO : training on a 8940085 raw words (6211848 effective words) took 12.3s, 505131 effective words/s\n",
      "2020-02-03 22:58:32,803 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:58:32,925 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:58:33,353 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:58:33,354 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:58:33,412 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:58:33,412 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:58:33,475 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:58:33,479 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:58:33,480 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:58:33,506 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 22:58:34,300 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 22:58:34,339 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 22:58:34,341 : INFO : resetting layer weights\n",
      "2020-02-03 22:58:38,172 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:58:39,194 : INFO : EPOCH 1 - PROGRESS: at 39.66% examples, 497883 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:40,203 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 532043 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-03 22:58:40,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:40,546 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:40,549 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:40,549 : INFO : EPOCH - 1 : training on 1788017 raw words (1242354 effective words) took 2.4s, 526760 effective words/s\n",
      "2020-02-03 22:58:41,574 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 433805 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:42,585 : INFO : EPOCH 2 - PROGRESS: at 80.45% examples, 496580 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:43,000 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:43,020 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:43,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:43,023 : INFO : EPOCH - 2 : training on 1788017 raw words (1242428 effective words) took 2.5s, 506225 effective words/s\n",
      "2020-02-03 22:58:44,045 : INFO : EPOCH 3 - PROGRESS: at 36.87% examples, 462228 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:45,051 : INFO : EPOCH 3 - PROGRESS: at 80.45% examples, 498263 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:45,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:45,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:45,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:45,564 : INFO : EPOCH - 3 : training on 1788017 raw words (1242361 effective words) took 2.5s, 492508 effective words/s\n",
      "2020-02-03 22:58:46,587 : INFO : EPOCH 4 - PROGRESS: at 40.22% examples, 506030 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:47,587 : INFO : EPOCH 4 - PROGRESS: at 85.47% examples, 531257 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:47,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:47,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:47,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:47,971 : INFO : EPOCH - 4 : training on 1788017 raw words (1242571 effective words) took 2.4s, 521033 effective words/s\n",
      "2020-02-03 22:58:49,000 : INFO : EPOCH 5 - PROGRESS: at 34.64% examples, 432501 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:50,010 : INFO : EPOCH 5 - PROGRESS: at 77.09% examples, 475572 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-03 22:58:50,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:50,587 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:50,592 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:50,593 : INFO : EPOCH - 5 : training on 1788017 raw words (1242289 effective words) took 2.6s, 477574 effective words/s\n",
      "2020-02-03 22:58:50,594 : INFO : training on a 8940085 raw words (6212003 effective words) took 12.4s, 500101 effective words/s\n",
      "2020-02-03 22:58:50,625 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:58:50,781 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 18.446553071339924, 'train_time_std': 2.277916091152619}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:58:51,174 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:58:51,175 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:58:51,233 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:58:51,234 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:58:51,290 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:58:51,294 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:58:51,295 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:58:51,352 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:58:51,353 : INFO : resetting layer weights\n",
      "2020-02-03 22:58:55,053 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:58:56,099 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 296849 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:57,104 : INFO : EPOCH 1 - PROGRESS: at 54.75% examples, 336928 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:58,121 : INFO : EPOCH 1 - PROGRESS: at 86.03% examples, 351342 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:58:58,530 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:58:58,567 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:58:58,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:58:58,574 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 3.5s, 354959 effective words/s\n",
      "2020-02-03 22:58:59,621 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 337311 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:00,646 : INFO : EPOCH 2 - PROGRESS: at 59.22% examples, 359052 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:59:01,665 : INFO : EPOCH 2 - PROGRESS: at 91.06% examples, 368706 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:01,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:01,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:01,961 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:01,962 : INFO : EPOCH - 2 : training on 1788017 raw words (1242344 effective words) took 3.4s, 368635 effective words/s\n",
      "2020-02-03 22:59:02,996 : INFO : EPOCH 3 - PROGRESS: at 21.23% examples, 265335 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:04,019 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 302796 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:05,019 : INFO : EPOCH 3 - PROGRESS: at 79.33% examples, 325049 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:05,755 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:05,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:05,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:05,810 : INFO : EPOCH - 3 : training on 1788017 raw words (1242531 effective words) took 3.8s, 324500 effective words/s\n",
      "2020-02-03 22:59:06,838 : INFO : EPOCH 4 - PROGRESS: at 24.58% examples, 309191 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:07,873 : INFO : EPOCH 4 - PROGRESS: at 55.87% examples, 341233 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:08,891 : INFO : EPOCH 4 - PROGRESS: at 85.47% examples, 347157 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:09,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:09,417 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:09,425 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:09,426 : INFO : EPOCH - 4 : training on 1788017 raw words (1241796 effective words) took 3.6s, 345383 effective words/s\n",
      "2020-02-03 22:59:10,485 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 313486 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:11,485 : INFO : EPOCH 5 - PROGRESS: at 51.40% examples, 315960 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:12,492 : INFO : EPOCH 5 - PROGRESS: at 79.89% examples, 326178 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:13,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:13,135 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:13,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:13,143 : INFO : EPOCH - 5 : training on 1788017 raw words (1241953 effective words) took 3.7s, 335978 effective words/s\n",
      "2020-02-03 22:59:13,144 : INFO : training on a 8940085 raw words (6211572 effective words) took 18.1s, 343377 effective words/s\n",
      "2020-02-03 22:59:13,176 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:59:13,305 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:59:13,760 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:59:13,761 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:59:13,823 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:59:13,823 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:59:13,886 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:59:13,891 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:59:13,892 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:59:13,953 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:59:13,954 : INFO : resetting layer weights\n",
      "2020-02-03 22:59:17,762 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:59:18,814 : INFO : EPOCH 1 - PROGRESS: at 20.67% examples, 256544 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:19,818 : INFO : EPOCH 1 - PROGRESS: at 50.84% examples, 314695 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:20,822 : INFO : EPOCH 1 - PROGRESS: at 82.12% examples, 336933 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:21,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:21,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:21,411 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:21,412 : INFO : EPOCH - 1 : training on 1788017 raw words (1242346 effective words) took 3.6s, 343033 effective words/s\n",
      "2020-02-03 22:59:22,434 : INFO : EPOCH 2 - PROGRESS: at 26.26% examples, 331534 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:23,450 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 355079 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:24,453 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 365534 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:24,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:24,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:24,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:24,838 : INFO : EPOCH - 2 : training on 1788017 raw words (1241793 effective words) took 3.4s, 364449 effective words/s\n",
      "2020-02-03 22:59:25,865 : INFO : EPOCH 3 - PROGRESS: at 26.26% examples, 330188 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:26,868 : INFO : EPOCH 3 - PROGRESS: at 54.19% examples, 336766 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:27,874 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 338534 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:28,509 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:28,552 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:28,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:28,562 : INFO : EPOCH - 3 : training on 1788017 raw words (1242453 effective words) took 3.7s, 335334 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:59:29,583 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 283140 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:30,593 : INFO : EPOCH 4 - PROGRESS: at 49.16% examples, 306857 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:31,609 : INFO : EPOCH 4 - PROGRESS: at 78.21% examples, 321646 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:32,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:32,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:32,314 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:32,315 : INFO : EPOCH - 4 : training on 1788017 raw words (1242708 effective words) took 3.7s, 332898 effective words/s\n",
      "2020-02-03 22:59:33,338 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 324053 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:34,342 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 327146 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:59:35,349 : INFO : EPOCH 5 - PROGRESS: at 82.12% examples, 338559 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 22:59:35,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:35,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:35,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:35,975 : INFO : EPOCH - 5 : training on 1788017 raw words (1242118 effective words) took 3.6s, 341168 effective words/s\n",
      "2020-02-03 22:59:35,975 : INFO : training on a 8940085 raw words (6211418 effective words) took 18.2s, 341063 effective words/s\n",
      "2020-02-03 22:59:35,982 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:59:36,106 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 22:59:36,488 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:59:36,489 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:59:36,545 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:59:36,546 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:59:36,621 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:59:36,626 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:59:36,628 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:59:36,695 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:59:36,696 : INFO : resetting layer weights\n",
      "2020-02-03 22:59:40,403 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 22:59:41,450 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 296446 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:42,466 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 331271 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:43,473 : INFO : EPOCH 1 - PROGRESS: at 83.80% examples, 341786 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:44,017 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:44,054 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:44,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:44,063 : INFO : EPOCH - 1 : training on 1788017 raw words (1242630 effective words) took 3.6s, 341363 effective words/s\n",
      "2020-02-03 22:59:45,091 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 266961 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:46,100 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 315873 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:47,125 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 326484 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:47,770 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:47,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:47,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:47,809 : INFO : EPOCH - 2 : training on 1788017 raw words (1241953 effective words) took 3.7s, 333202 effective words/s\n",
      "2020-02-03 22:59:48,847 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 319510 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:49,882 : INFO : EPOCH 3 - PROGRESS: at 54.19% examples, 329546 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:50,902 : INFO : EPOCH 3 - PROGRESS: at 86.03% examples, 348170 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:51,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:51,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:51,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:51,354 : INFO : EPOCH - 3 : training on 1788017 raw words (1242024 effective words) took 3.5s, 352250 effective words/s\n",
      "2020-02-03 22:59:52,385 : INFO : EPOCH 4 - PROGRESS: at 22.91% examples, 286981 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:53,394 : INFO : EPOCH 4 - PROGRESS: at 48.04% examples, 298333 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:54,399 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 300539 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:55,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:55,412 : INFO : EPOCH 4 - PROGRESS: at 99.44% examples, 305744 words/s, in_qsize 1, out_qsize 1\n",
      "2020-02-03 22:59:55,413 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:55,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:55,421 : INFO : EPOCH - 4 : training on 1788017 raw words (1241732 effective words) took 4.0s, 306802 effective words/s\n",
      "2020-02-03 22:59:56,450 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 322495 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:57,464 : INFO : EPOCH 5 - PROGRESS: at 57.54% examples, 354463 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:58,468 : INFO : EPOCH 5 - PROGRESS: at 88.27% examples, 362882 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 22:59:58,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 22:59:58,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 22:59:58,888 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 22:59:58,889 : INFO : EPOCH - 5 : training on 1788017 raw words (1242445 effective words) took 3.4s, 360297 effective words/s\n",
      "2020-02-03 22:59:58,890 : INFO : training on a 8940085 raw words (6210784 effective words) took 18.5s, 335975 effective words/s\n",
      "2020-02-03 22:59:58,897 : INFO : collecting all words and their counts\n",
      "2020-02-03 22:59:59,024 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 22.757126569747925, 'train_time_std': 0.152659750088263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 22:59:59,462 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 22:59:59,462 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 22:59:59,516 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 22:59:59,517 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 22:59:59,574 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 22:59:59,577 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 22:59:59,578 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 22:59:59,638 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 22:59:59,638 : INFO : resetting layer weights\n",
      "2020-02-03 23:00:03,452 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:00:04,509 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 313247 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:05,542 : INFO : EPOCH 1 - PROGRESS: at 57.54% examples, 346093 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:06,562 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 359774 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:06,888 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:06,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:06,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:06,935 : INFO : EPOCH - 1 : training on 1788017 raw words (1242435 effective words) took 3.5s, 358587 effective words/s\n",
      "2020-02-03 23:00:07,950 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 325099 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:08,962 : INFO : EPOCH 2 - PROGRESS: at 57.54% examples, 356234 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:09,983 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 366403 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:10,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:10,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:10,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:10,329 : INFO : EPOCH - 2 : training on 1788017 raw words (1242240 effective words) took 3.4s, 367443 effective words/s\n",
      "2020-02-03 23:00:11,365 : INFO : EPOCH 3 - PROGRESS: at 26.26% examples, 327724 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:12,366 : INFO : EPOCH 3 - PROGRESS: at 58.10% examples, 358958 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:13,376 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 367540 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:13,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:13,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:13,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:13,735 : INFO : EPOCH - 3 : training on 1788017 raw words (1242064 effective words) took 3.4s, 366891 effective words/s\n",
      "2020-02-03 23:00:14,756 : INFO : EPOCH 4 - PROGRESS: at 26.26% examples, 330721 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:15,760 : INFO : EPOCH 4 - PROGRESS: at 57.54% examples, 356654 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:16,772 : INFO : EPOCH 4 - PROGRESS: at 85.47% examples, 351658 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:17,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:17,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:17,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:17,267 : INFO : EPOCH - 4 : training on 1788017 raw words (1242315 effective words) took 3.5s, 353147 effective words/s\n",
      "2020-02-03 23:00:18,288 : INFO : EPOCH 5 - PROGRESS: at 22.35% examples, 283127 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:19,320 : INFO : EPOCH 5 - PROGRESS: at 44.13% examples, 272621 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:00:20,336 : INFO : EPOCH 5 - PROGRESS: at 64.25% examples, 261813 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:21,337 : INFO : EPOCH 5 - PROGRESS: at 84.92% examples, 260797 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:21,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:21,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:22,001 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:22,002 : INFO : EPOCH - 5 : training on 1788017 raw words (1242662 effective words) took 4.7s, 263555 effective words/s\n",
      "2020-02-03 23:00:22,004 : INFO : training on a 8940085 raw words (6211716 effective words) took 18.6s, 334842 effective words/s\n",
      "2020-02-03 23:00:22,013 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:00:22,163 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:00:22,650 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:00:22,651 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:00:22,710 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:00:22,711 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:00:22,769 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:00:22,773 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:00:22,774 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:00:22,835 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 23:00:22,836 : INFO : resetting layer weights\n",
      "2020-02-03 23:00:27,424 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:00:28,480 : INFO : EPOCH 1 - PROGRESS: at 22.35% examples, 274065 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:29,491 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 301602 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:30,502 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 306969 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:31,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:31,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:31,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:31,479 : INFO : EPOCH - 1 : training on 1788017 raw words (1242196 effective words) took 4.0s, 308029 effective words/s\n",
      "2020-02-03 23:00:32,511 : INFO : EPOCH 2 - PROGRESS: at 20.67% examples, 259930 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:33,538 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 272207 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:34,555 : INFO : EPOCH 2 - PROGRESS: at 69.27% examples, 281908 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:35,560 : INFO : EPOCH 2 - PROGRESS: at 94.97% examples, 291080 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:00:35,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:35,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:35,840 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:35,841 : INFO : EPOCH - 2 : training on 1788017 raw words (1242578 effective words) took 4.3s, 286315 effective words/s\n",
      "2020-02-03 23:00:36,879 : INFO : EPOCH 3 - PROGRESS: at 22.91% examples, 286722 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:37,901 : INFO : EPOCH 3 - PROGRESS: at 49.16% examples, 303195 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:00:38,914 : INFO : EPOCH 3 - PROGRESS: at 77.09% examples, 314977 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:39,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:00:39,763 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:39,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:39,772 : INFO : EPOCH - 3 : training on 1788017 raw words (1241996 effective words) took 3.9s, 318041 effective words/s\n",
      "2020-02-03 23:00:40,832 : INFO : EPOCH 4 - PROGRESS: at 24.02% examples, 294015 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:41,833 : INFO : EPOCH 4 - PROGRESS: at 48.60% examples, 299578 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:42,837 : INFO : EPOCH 4 - PROGRESS: at 72.07% examples, 294732 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:43,837 : INFO : EPOCH 4 - PROGRESS: at 94.41% examples, 290616 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:44,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:44,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:44,075 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:44,075 : INFO : EPOCH - 4 : training on 1788017 raw words (1242904 effective words) took 4.3s, 290369 effective words/s\n",
      "2020-02-03 23:00:45,143 : INFO : EPOCH 5 - PROGRESS: at 18.99% examples, 230735 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:46,185 : INFO : EPOCH 5 - PROGRESS: at 42.46% examples, 256016 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:47,195 : INFO : EPOCH 5 - PROGRESS: at 71.51% examples, 287257 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:48,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:48,153 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:48,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:48,164 : INFO : EPOCH - 5 : training on 1788017 raw words (1242489 effective words) took 4.1s, 305652 effective words/s\n",
      "2020-02-03 23:00:48,165 : INFO : training on a 8940085 raw words (6212163 effective words) took 20.7s, 299527 effective words/s\n",
      "2020-02-03 23:00:48,173 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:00:48,300 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:00:48,716 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:00:48,716 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:00:48,793 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:00:48,794 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:00:48,862 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:00:48,866 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:00:48,867 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:00:48,929 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-02-03 23:00:48,930 : INFO : resetting layer weights\n",
      "2020-02-03 23:00:52,731 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:00:53,783 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 316414 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:54,790 : INFO : EPOCH 1 - PROGRESS: at 56.98% examples, 348977 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:55,811 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 354412 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:56,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:00:56,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:00:56,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:00:56,240 : INFO : EPOCH - 1 : training on 1788017 raw words (1241449 effective words) took 3.5s, 356028 effective words/s\n",
      "2020-02-03 23:00:57,290 : INFO : EPOCH 2 - PROGRESS: at 24.02% examples, 295277 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:58,318 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 309502 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:00:59,347 : INFO : EPOCH 2 - PROGRESS: at 77.09% examples, 310772 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-03 23:01:00,243 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:00,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:00,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:00,305 : INFO : EPOCH - 2 : training on 1788017 raw words (1241539 effective words) took 4.0s, 306983 effective words/s\n",
      "2020-02-03 23:01:01,373 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 191046 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:02,398 : INFO : EPOCH 3 - PROGRESS: at 37.99% examples, 231719 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:03,432 : INFO : EPOCH 3 - PROGRESS: at 62.57% examples, 251006 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:04,433 : INFO : EPOCH 3 - PROGRESS: at 88.27% examples, 268022 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:04,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:04,897 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:04,904 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:04,905 : INFO : EPOCH - 3 : training on 1788017 raw words (1242879 effective words) took 4.6s, 271919 effective words/s\n",
      "2020-02-03 23:01:05,958 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 274935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:06,958 : INFO : EPOCH 4 - PROGRESS: at 53.07% examples, 326745 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:07,960 : INFO : EPOCH 4 - PROGRESS: at 80.45% examples, 330014 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:08,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:08,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:08,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:08,643 : INFO : EPOCH - 4 : training on 1788017 raw words (1242504 effective words) took 3.7s, 334342 effective words/s\n",
      "2020-02-03 23:01:09,697 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 315057 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:10,713 : INFO : EPOCH 5 - PROGRESS: at 57.54% examples, 350209 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:11,736 : INFO : EPOCH 5 - PROGRESS: at 88.83% examples, 359686 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:12,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:12,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:12,110 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:12,110 : INFO : EPOCH - 5 : training on 1788017 raw words (1242241 effective words) took 3.4s, 360436 effective words/s\n",
      "2020-02-03 23:01:12,111 : INFO : training on a 8940085 raw words (6210612 effective words) took 19.4s, 320481 effective words/s\n",
      "2020-02-03 23:01:12,120 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:01:12,257 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 24.407532930374146, 'train_time_std': 1.284500796488715}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:01:12,659 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:01:12,660 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:01:12,723 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:01:12,724 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:01:12,800 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:01:12,804 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:01:12,805 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:01:12,828 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:01:13,323 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:01:13,363 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:01:13,364 : INFO : resetting layer weights\n",
      "2020-02-03 23:01:17,141 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:01:18,191 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 131773 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:19,236 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 156761 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:20,267 : INFO : EPOCH 1 - PROGRESS: at 41.34% examples, 167313 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:21,288 : INFO : EPOCH 1 - PROGRESS: at 56.98% examples, 172127 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:22,302 : INFO : EPOCH 1 - PROGRESS: at 72.07% examples, 174169 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:23,320 : INFO : EPOCH 1 - PROGRESS: at 87.15% examples, 175969 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:24,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:24,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:24,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:24,201 : INFO : EPOCH - 1 : training on 1788017 raw words (1242193 effective words) took 7.0s, 176437 effective words/s\n",
      "2020-02-03 23:01:25,255 : INFO : EPOCH 2 - PROGRESS: at 12.29% examples, 151527 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:26,261 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 170256 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:27,266 : INFO : EPOCH 2 - PROGRESS: at 43.02% examples, 177512 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:28,266 : INFO : EPOCH 2 - PROGRESS: at 58.66% examples, 180555 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:29,284 : INFO : EPOCH 2 - PROGRESS: at 73.74% examples, 181108 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:30,320 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 181205 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:31,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:31,088 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:31,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:31,105 : INFO : EPOCH - 2 : training on 1788017 raw words (1242625 effective words) took 6.9s, 180468 effective words/s\n",
      "2020-02-03 23:01:32,137 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 134488 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:33,173 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 159035 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:34,221 : INFO : EPOCH 3 - PROGRESS: at 39.11% examples, 159060 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:35,242 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 154802 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:36,305 : INFO : EPOCH 3 - PROGRESS: at 64.25% examples, 154032 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:37,306 : INFO : EPOCH 3 - PROGRESS: at 77.65% examples, 156353 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:38,316 : INFO : EPOCH 3 - PROGRESS: at 91.06% examples, 157596 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:38,893 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:38,981 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:38,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:38,995 : INFO : EPOCH - 3 : training on 1788017 raw words (1242187 effective words) took 7.9s, 157852 effective words/s\n",
      "2020-02-03 23:01:40,050 : INFO : EPOCH 4 - PROGRESS: at 10.61% examples, 131080 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:41,087 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 136637 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:42,132 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 144398 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:43,223 : INFO : EPOCH 4 - PROGRESS: at 50.84% examples, 151499 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:44,261 : INFO : EPOCH 4 - PROGRESS: at 65.92% examples, 156060 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:45,277 : INFO : EPOCH 4 - PROGRESS: at 78.77% examples, 156523 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:46,348 : INFO : EPOCH 4 - PROGRESS: at 89.39% examples, 151656 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:47,045 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:47,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:47,140 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:47,141 : INFO : EPOCH - 4 : training on 1788017 raw words (1242564 effective words) took 8.1s, 152881 effective words/s\n",
      "2020-02-03 23:01:48,192 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 131533 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:49,192 : INFO : EPOCH 5 - PROGRESS: at 24.58% examples, 153050 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-03 23:01:50,222 : INFO : EPOCH 5 - PROGRESS: at 39.66% examples, 162935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:51,247 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 165558 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:52,276 : INFO : EPOCH 5 - PROGRESS: at 69.27% examples, 168132 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:01:53,319 : INFO : EPOCH 5 - PROGRESS: at 83.80% examples, 169189 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:01:54,381 : INFO : EPOCH 5 - PROGRESS: at 97.77% examples, 168388 words/s, in_qsize 4, out_qsize 0\n",
      "2020-02-03 23:01:54,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:01:54,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:01:54,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:01:54,494 : INFO : EPOCH - 5 : training on 1788017 raw words (1242277 effective words) took 7.3s, 169345 effective words/s\n",
      "2020-02-03 23:01:54,495 : INFO : training on a 8940085 raw words (6211846 effective words) took 37.4s, 166299 effective words/s\n",
      "2020-02-03 23:01:54,503 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:01:54,637 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:01:55,043 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:01:55,043 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:01:55,100 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:01:55,100 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:01:55,159 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:01:55,164 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:01:55,165 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:01:55,190 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:01:55,759 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:01:55,805 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:01:55,806 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:01:59,696 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:02:00,715 : INFO : EPOCH 1 - PROGRESS: at 11.17% examples, 143105 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:01,745 : INFO : EPOCH 1 - PROGRESS: at 24.58% examples, 153479 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:02,751 : INFO : EPOCH 1 - PROGRESS: at 38.55% examples, 159956 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:03,769 : INFO : EPOCH 1 - PROGRESS: at 53.63% examples, 165375 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:04,791 : INFO : EPOCH 1 - PROGRESS: at 68.16% examples, 166723 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:05,792 : INFO : EPOCH 1 - PROGRESS: at 82.68% examples, 169215 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:06,792 : INFO : EPOCH 1 - PROGRESS: at 97.21% examples, 170844 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:06,910 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:06,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:06,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:06,988 : INFO : EPOCH - 1 : training on 1788017 raw words (1242519 effective words) took 7.3s, 170829 effective words/s\n",
      "2020-02-03 23:02:08,011 : INFO : EPOCH 2 - PROGRESS: at 11.17% examples, 142391 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:09,086 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 156747 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:10,086 : INFO : EPOCH 2 - PROGRESS: at 39.66% examples, 162257 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:11,129 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 164270 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:12,133 : INFO : EPOCH 2 - PROGRESS: at 68.72% examples, 166547 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:13,172 : INFO : EPOCH 2 - PROGRESS: at 82.68% examples, 166825 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:14,208 : INFO : EPOCH 2 - PROGRESS: at 96.09% examples, 165940 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:14,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:14,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:14,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:14,458 : INFO : EPOCH - 2 : training on 1788017 raw words (1242059 effective words) took 7.5s, 166691 effective words/s\n",
      "2020-02-03 23:02:15,512 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 131232 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:16,519 : INFO : EPOCH 3 - PROGRESS: at 24.58% examples, 152708 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:17,548 : INFO : EPOCH 3 - PROGRESS: at 39.66% examples, 162631 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:18,561 : INFO : EPOCH 3 - PROGRESS: at 54.75% examples, 167413 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:19,594 : INFO : EPOCH 3 - PROGRESS: at 69.27% examples, 168226 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:20,595 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 171561 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:21,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:21,634 : INFO : EPOCH 3 - PROGRESS: at 99.44% examples, 172635 words/s, in_qsize 1, out_qsize 1\n",
      "2020-02-03 23:02:21,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:21,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:21,652 : INFO : EPOCH - 3 : training on 1788017 raw words (1242659 effective words) took 7.2s, 173157 effective words/s\n",
      "2020-02-03 23:02:22,708 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 151148 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:23,752 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 166931 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:24,784 : INFO : EPOCH 4 - PROGRESS: at 42.46% examples, 171576 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:25,811 : INFO : EPOCH 4 - PROGRESS: at 58.10% examples, 174876 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:26,813 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 176962 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:27,830 : INFO : EPOCH 4 - PROGRESS: at 88.83% examples, 179446 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:28,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:28,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:28,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:28,538 : INFO : EPOCH - 4 : training on 1788017 raw words (1242592 effective words) took 6.9s, 180937 effective words/s\n",
      "2020-02-03 23:02:29,569 : INFO : EPOCH 5 - PROGRESS: at 12.29% examples, 154329 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:30,584 : INFO : EPOCH 5 - PROGRESS: at 27.37% examples, 170993 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:31,608 : INFO : EPOCH 5 - PROGRESS: at 43.02% examples, 176932 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:32,614 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 179918 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:33,640 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 178898 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:34,652 : INFO : EPOCH 5 - PROGRESS: at 87.71% examples, 178963 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:35,379 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:35,447 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:35,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:35,459 : INFO : EPOCH - 5 : training on 1788017 raw words (1242147 effective words) took 6.9s, 179915 effective words/s\n",
      "2020-02-03 23:02:35,460 : INFO : training on a 8940085 raw words (6211976 effective words) took 35.8s, 173696 effective words/s\n",
      "2020-02-03 23:02:35,495 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:02:35,618 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:02:36,015 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:02:36,016 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:02:36,069 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:02:36,070 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:02:36,123 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:02:36,127 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:02:36,128 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:02:36,149 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:02:36,633 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:02:36,671 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:02:36,672 : INFO : resetting layer weights\n",
      "2020-02-03 23:02:40,344 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:02:41,374 : INFO : EPOCH 1 - PROGRESS: at 10.61% examples, 134071 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:42,395 : INFO : EPOCH 1 - PROGRESS: at 24.02% examples, 149697 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:43,438 : INFO : EPOCH 1 - PROGRESS: at 37.99% examples, 155280 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:44,535 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 157404 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:45,542 : INFO : EPOCH 1 - PROGRESS: at 66.48% examples, 159309 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:46,564 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 163482 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:47,604 : INFO : EPOCH 1 - PROGRESS: at 95.53% examples, 164007 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:47,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:02:47,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:47,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:47,894 : INFO : EPOCH - 1 : training on 1788017 raw words (1242143 effective words) took 7.5s, 164867 effective words/s\n",
      "2020-02-03 23:02:48,949 : INFO : EPOCH 2 - PROGRESS: at 8.94% examples, 110725 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:49,954 : INFO : EPOCH 2 - PROGRESS: at 21.23% examples, 132040 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:50,959 : INFO : EPOCH 2 - PROGRESS: at 36.31% examples, 150066 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:51,996 : INFO : EPOCH 2 - PROGRESS: at 51.40% examples, 157749 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:02:53,013 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 157899 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:54,038 : INFO : EPOCH 2 - PROGRESS: at 78.21% examples, 158902 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:55,071 : INFO : EPOCH 2 - PROGRESS: at 92.74% examples, 161125 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:55,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:02:55,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:02:55,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:02:55,541 : INFO : EPOCH - 2 : training on 1788017 raw words (1242104 effective words) took 7.6s, 162858 effective words/s\n",
      "2020-02-03 23:02:56,573 : INFO : EPOCH 3 - PROGRESS: at 11.73% examples, 147595 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:57,591 : INFO : EPOCH 3 - PROGRESS: at 24.02% examples, 149731 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:58,645 : INFO : EPOCH 3 - PROGRESS: at 39.11% examples, 159543 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:02:59,647 : INFO : EPOCH 3 - PROGRESS: at 54.19% examples, 165621 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:00,665 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 169924 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:01,730 : INFO : EPOCH 3 - PROGRESS: at 84.36% examples, 170066 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:02,836 : INFO : EPOCH 3 - PROGRESS: at 97.77% examples, 167133 words/s, in_qsize 4, out_qsize 0\n",
      "2020-02-03 23:03:02,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:02,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:02,972 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:02,973 : INFO : EPOCH - 3 : training on 1788017 raw words (1242611 effective words) took 7.4s, 167580 effective words/s\n",
      "2020-02-03 23:03:04,088 : INFO : EPOCH 4 - PROGRESS: at 7.26% examples, 85002 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:03:05,123 : INFO : EPOCH 4 - PROGRESS: at 20.67% examples, 123261 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:06,131 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 141256 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:07,146 : INFO : EPOCH 4 - PROGRESS: at 48.04% examples, 145226 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:08,151 : INFO : EPOCH 4 - PROGRESS: at 60.89% examples, 146759 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:09,241 : INFO : EPOCH 4 - PROGRESS: at 74.86% examples, 149041 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:10,264 : INFO : EPOCH 4 - PROGRESS: at 88.27% examples, 151088 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:10,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:11,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:11,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:11,050 : INFO : EPOCH - 4 : training on 1788017 raw words (1242769 effective words) took 8.1s, 154222 effective words/s\n",
      "2020-02-03 23:03:12,074 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 135150 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:13,115 : INFO : EPOCH 5 - PROGRESS: at 25.70% examples, 159137 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:03:14,125 : INFO : EPOCH 5 - PROGRESS: at 40.22% examples, 165718 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:15,159 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 165588 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:16,198 : INFO : EPOCH 5 - PROGRESS: at 70.39% examples, 170537 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:17,275 : INFO : EPOCH 5 - PROGRESS: at 85.47% examples, 171249 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:18,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:18,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:18,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:18,242 : INFO : EPOCH - 5 : training on 1788017 raw words (1242011 effective words) took 7.2s, 173169 effective words/s\n",
      "2020-02-03 23:03:18,243 : INFO : training on a 8940085 raw words (6211638 effective words) took 37.9s, 163901 effective words/s\n",
      "2020-02-03 23:03:18,270 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:03:18,396 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 42.05006639162699, 'train_time_std': 0.7657778590513281}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:03:18,781 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:03:18,782 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:03:18,839 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:03:18,840 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:03:18,907 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:03:18,911 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:03:18,911 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:03:18,936 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:03:19,538 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:03:19,576 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:03:19,577 : INFO : resetting layer weights\n",
      "2020-02-03 23:03:23,304 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:03:24,323 : INFO : EPOCH 1 - PROGRESS: at 12.29% examples, 156004 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:25,401 : INFO : EPOCH 1 - PROGRESS: at 29.05% examples, 176837 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:26,467 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 182645 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:27,480 : INFO : EPOCH 1 - PROGRESS: at 62.01% examples, 185235 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:28,493 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 181367 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:29,509 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 179702 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:03:30,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:30,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:30,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:30,241 : INFO : EPOCH - 1 : training on 1788017 raw words (1242194 effective words) took 6.9s, 179507 effective words/s\n",
      "2020-02-03 23:03:31,282 : INFO : EPOCH 2 - PROGRESS: at 12.29% examples, 153214 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:32,311 : INFO : EPOCH 2 - PROGRESS: at 27.93% examples, 172696 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:03:33,321 : INFO : EPOCH 2 - PROGRESS: at 43.58% examples, 178692 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:34,361 : INFO : EPOCH 2 - PROGRESS: at 59.22% examples, 179716 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:35,408 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 180816 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:36,412 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 180736 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:37,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:37,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:37,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:37,115 : INFO : EPOCH - 2 : training on 1788017 raw words (1242140 effective words) took 6.9s, 181180 effective words/s\n",
      "2020-02-03 23:03:38,141 : INFO : EPOCH 3 - PROGRESS: at 11.73% examples, 148550 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:39,176 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 159431 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:40,194 : INFO : EPOCH 3 - PROGRESS: at 41.34% examples, 169867 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:41,195 : INFO : EPOCH 3 - PROGRESS: at 56.98% examples, 174949 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:42,196 : INFO : EPOCH 3 - PROGRESS: at 72.07% examples, 176904 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:43,214 : INFO : EPOCH 3 - PROGRESS: at 86.03% examples, 175930 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:44,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:44,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:44,187 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:44,188 : INFO : EPOCH - 3 : training on 1788017 raw words (1241957 effective words) took 7.1s, 176021 effective words/s\n",
      "2020-02-03 23:03:45,212 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 155595 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:46,216 : INFO : EPOCH 4 - PROGRESS: at 27.93% examples, 176124 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:47,272 : INFO : EPOCH 4 - PROGRESS: at 44.13% examples, 180803 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:48,325 : INFO : EPOCH 4 - PROGRESS: at 60.89% examples, 183827 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:49,333 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 185849 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:50,364 : INFO : EPOCH 4 - PROGRESS: at 90.50% examples, 182982 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:51,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:51,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:51,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:51,131 : INFO : EPOCH - 4 : training on 1788017 raw words (1242878 effective words) took 6.9s, 179446 effective words/s\n",
      "2020-02-03 23:03:52,180 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 132762 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:53,245 : INFO : EPOCH 5 - PROGRESS: at 24.02% examples, 145776 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:54,289 : INFO : EPOCH 5 - PROGRESS: at 37.99% examples, 152686 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:55,308 : INFO : EPOCH 5 - PROGRESS: at 50.84% examples, 153590 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:56,368 : INFO : EPOCH 5 - PROGRESS: at 66.48% examples, 158460 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:03:57,407 : INFO : EPOCH 5 - PROGRESS: at 81.56% examples, 162292 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:58,449 : INFO : EPOCH 5 - PROGRESS: at 96.09% examples, 163994 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:03:58,603 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:03:58,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:03:58,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:03:58,666 : INFO : EPOCH - 5 : training on 1788017 raw words (1242870 effective words) took 7.5s, 165501 effective words/s\n",
      "2020-02-03 23:03:58,666 : INFO : training on a 8940085 raw words (6212039 effective words) took 35.4s, 175669 effective words/s\n",
      "2020-02-03 23:03:58,695 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:03:58,819 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:03:59,251 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:03:59,252 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:03:59,307 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:03:59,307 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:03:59,362 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:03:59,366 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:03:59,367 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:03:59,389 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:03:59,880 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:03:59,921 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:03:59,921 : INFO : resetting layer weights\n",
      "2020-02-03 23:04:03,799 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:04:04,818 : INFO : EPOCH 1 - PROGRESS: at 11.17% examples, 142626 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:04:05,834 : INFO : EPOCH 1 - PROGRESS: at 26.26% examples, 164977 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:06,877 : INFO : EPOCH 1 - PROGRESS: at 42.46% examples, 174495 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:07,942 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 178742 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:08,952 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 182796 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:09,985 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 183781 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:10,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:10,531 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:10,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:10,544 : INFO : EPOCH - 1 : training on 1788017 raw words (1242946 effective words) took 6.7s, 184710 effective words/s\n",
      "2020-02-03 23:04:11,571 : INFO : EPOCH 2 - PROGRESS: at 12.85% examples, 162331 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:12,575 : INFO : EPOCH 2 - PROGRESS: at 27.93% examples, 175989 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:13,601 : INFO : EPOCH 2 - PROGRESS: at 44.13% examples, 182397 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:14,672 : INFO : EPOCH 2 - PROGRESS: at 60.89% examples, 184161 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:15,686 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 183078 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:16,692 : INFO : EPOCH 2 - PROGRESS: at 89.94% examples, 182544 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:17,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:17,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:17,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:17,440 : INFO : EPOCH - 2 : training on 1788017 raw words (1241718 effective words) took 6.9s, 180538 effective words/s\n",
      "2020-02-03 23:04:18,541 : INFO : EPOCH 3 - PROGRESS: at 10.61% examples, 125527 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:19,580 : INFO : EPOCH 3 - PROGRESS: at 25.70% examples, 153616 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:20,627 : INFO : EPOCH 3 - PROGRESS: at 40.78% examples, 162079 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:21,657 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 166118 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:22,673 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 166400 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:04:23,746 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 162413 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:04:24,749 : INFO : EPOCH 3 - PROGRESS: at 96.09% examples, 163932 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:24,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:24,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:24,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:24,968 : INFO : EPOCH - 3 : training on 1788017 raw words (1242375 effective words) took 7.5s, 165439 effective words/s\n",
      "2020-02-03 23:04:26,025 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 150645 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:27,031 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 169645 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:28,038 : INFO : EPOCH 4 - PROGRESS: at 43.02% examples, 177054 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:29,048 : INFO : EPOCH 4 - PROGRESS: at 58.66% examples, 179709 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:30,051 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 179520 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:04:31,071 : INFO : EPOCH 4 - PROGRESS: at 88.27% examples, 180452 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:31,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:31,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:31,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:31,924 : INFO : EPOCH - 4 : training on 1788017 raw words (1241991 effective words) took 6.9s, 178982 effective words/s\n",
      "2020-02-03 23:04:32,979 : INFO : EPOCH 5 - PROGRESS: at 10.61% examples, 131101 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:34,044 : INFO : EPOCH 5 - PROGRESS: at 22.35% examples, 134789 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:35,075 : INFO : EPOCH 5 - PROGRESS: at 36.31% examples, 145732 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:36,104 : INFO : EPOCH 5 - PROGRESS: at 49.16% examples, 148138 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:37,131 : INFO : EPOCH 5 - PROGRESS: at 62.57% examples, 149797 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:38,131 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 153935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:39,156 : INFO : EPOCH 5 - PROGRESS: at 92.18% examples, 158970 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:39,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:39,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:39,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:39,662 : INFO : EPOCH - 5 : training on 1788017 raw words (1242623 effective words) took 7.7s, 160974 effective words/s\n",
      "2020-02-03 23:04:39,663 : INFO : training on a 8940085 raw words (6211653 effective words) took 35.9s, 173201 effective words/s\n",
      "2020-02-03 23:04:39,693 : INFO : collecting all words and their counts\n",
      "2020-02-03 23:04:39,821 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-03 23:04:40,243 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-02-03 23:04:40,244 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 23:04:40,305 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-02-03 23:04:40,305 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-02-03 23:04:40,362 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-02-03 23:04:40,367 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-02-03 23:04:40,368 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-02-03 23:04:40,389 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-02-03 23:04:40,919 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-02-03 23:04:40,961 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-02-03 23:04:40,962 : INFO : resetting layer weights\n",
      "2020-02-03 23:04:44,973 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-02-03 23:04:46,110 : INFO : EPOCH 1 - PROGRESS: at 13.41% examples, 169357 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:47,184 : INFO : EPOCH 1 - PROGRESS: at 27.37% examples, 166916 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:48,208 : INFO : EPOCH 1 - PROGRESS: at 41.90% examples, 169840 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:49,226 : INFO : EPOCH 1 - PROGRESS: at 55.31% examples, 167642 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:50,251 : INFO : EPOCH 1 - PROGRESS: at 70.39% examples, 170086 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:51,293 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 171867 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:52,292 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:52,344 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 170737 words/s, in_qsize 1, out_qsize 1\n",
      "2020-02-03 23:04:52,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:52,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:52,361 : INFO : EPOCH - 1 : training on 1788017 raw words (1242984 effective words) took 7.3s, 171300 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:04:53,381 : INFO : EPOCH 2 - PROGRESS: at 11.17% examples, 142380 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:54,439 : INFO : EPOCH 2 - PROGRESS: at 25.70% examples, 157941 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:55,450 : INFO : EPOCH 2 - PROGRESS: at 40.78% examples, 167091 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:56,536 : INFO : EPOCH 2 - PROGRESS: at 55.87% examples, 167765 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:04:57,567 : INFO : EPOCH 2 - PROGRESS: at 70.95% examples, 169903 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:04:58,647 : INFO : EPOCH 2 - PROGRESS: at 85.47% examples, 169567 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:04:59,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:04:59,658 : INFO : EPOCH 2 - PROGRESS: at 99.44% examples, 169682 words/s, in_qsize 1, out_qsize 1\n",
      "2020-02-03 23:04:59,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:04:59,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:04:59,685 : INFO : EPOCH - 2 : training on 1788017 raw words (1242254 effective words) took 7.3s, 170006 effective words/s\n",
      "2020-02-03 23:05:00,781 : INFO : EPOCH 3 - PROGRESS: at 12.29% examples, 145748 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:01,792 : INFO : EPOCH 3 - PROGRESS: at 27.37% examples, 166363 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:02,804 : INFO : EPOCH 3 - PROGRESS: at 43.02% examples, 174524 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:03,832 : INFO : EPOCH 3 - PROGRESS: at 57.54% examples, 173890 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:05:04,872 : INFO : EPOCH 3 - PROGRESS: at 72.63% examples, 174793 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:05,901 : INFO : EPOCH 3 - PROGRESS: at 87.71% examples, 176167 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:06,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:05:06,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:05:06,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:05:06,706 : INFO : EPOCH - 3 : training on 1788017 raw words (1242608 effective words) took 7.0s, 177490 effective words/s\n",
      "2020-02-03 23:05:07,743 : INFO : EPOCH 4 - PROGRESS: at 12.29% examples, 153542 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:08,778 : INFO : EPOCH 4 - PROGRESS: at 27.37% examples, 168907 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:09,810 : INFO : EPOCH 4 - PROGRESS: at 43.58% examples, 177287 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:10,826 : INFO : EPOCH 4 - PROGRESS: at 59.78% examples, 181285 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:11,854 : INFO : EPOCH 4 - PROGRESS: at 75.42% examples, 182888 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:12,871 : INFO : EPOCH 4 - PROGRESS: at 91.62% examples, 185403 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:13,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:05:13,417 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:05:13,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:05:13,432 : INFO : EPOCH - 4 : training on 1788017 raw words (1242404 effective words) took 6.7s, 185172 effective words/s\n",
      "2020-02-03 23:05:14,531 : INFO : EPOCH 5 - PROGRESS: at 12.29% examples, 144939 words/s, in_qsize 6, out_qsize 0\n",
      "2020-02-03 23:05:15,563 : INFO : EPOCH 5 - PROGRESS: at 27.37% examples, 164285 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:16,583 : INFO : EPOCH 5 - PROGRESS: at 43.58% examples, 174702 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:17,586 : INFO : EPOCH 5 - PROGRESS: at 58.10% examples, 175015 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:18,596 : INFO : EPOCH 5 - PROGRESS: at 71.51% examples, 172783 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:19,613 : INFO : EPOCH 5 - PROGRESS: at 86.59% examples, 174818 words/s, in_qsize 5, out_qsize 0\n",
      "2020-02-03 23:05:20,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 23:05:20,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 23:05:20,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 23:05:20,611 : INFO : EPOCH - 5 : training on 1788017 raw words (1242375 effective words) took 7.2s, 173495 effective words/s\n",
      "2020-02-03 23:05:20,612 : INFO : training on a 8940085 raw words (6212625 effective words) took 35.6s, 174325 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 40.79019276301066, 'train_time_std': 0.2595709934863263}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         0.847283        0.066428\n",
      "5        25kB         False   1   0         0.765171        0.005743\n",
      "6        25kB          True   1   1         1.478252        0.204977\n",
      "7        25kB         False   1   1         2.092017        0.867424\n",
      "0        25kB          True   0   0         0.622560        0.008212\n",
      "1        25kB         False   0   0         0.621660        0.028678\n",
      "2        25kB          True   0   1         0.787105        0.023877\n",
      "3        25kB         False   0   1         0.773115        0.005728\n",
      "12        1MB          True   1   0         2.475293        0.265729\n",
      "13        1MB         False   1   0         2.220606        0.046947\n",
      "14        1MB          True   1   1         3.995769        0.219305\n",
      "15        1MB         False   1   1         3.981336        0.259691\n",
      "8         1MB          True   0   0         1.758597        0.407172\n",
      "9         1MB         False   0   0         1.407256        0.039179\n",
      "10        1MB          True   0   1         1.988531        0.072841\n",
      "11        1MB         False   0   1         1.963837        0.091330\n",
      "20       10MB          True   1   0        22.757127        0.152660\n",
      "21       10MB         False   1   0        24.407533        1.284501\n",
      "22       10MB          True   1   1        42.050066        0.765778\n",
      "23       10MB         False   1   1        40.790193        0.259571\n",
      "16       10MB          True   0   0        12.098690        0.110054\n",
      "17       10MB         False   0   0        11.358401        0.569930\n",
      "18       10MB          True   0   1        17.665090        1.224967\n",
      "19       10MB         False   0   1        18.446553        2.277916\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Word2Vec \"model to dict\" method to production pipeline\n",
    "-------------------------------------------------------------\n",
    "\n",
    "Suppose, we still want more performance improvement in production.\n",
    "\n",
    "One good way is to cache all the similar words in a dictionary.\n",
    "\n",
    "So that next time when we get the similar query word, we'll search it first in the dict.\n",
    "\n",
    "And if it's a hit then we will show the result directly from the dictionary.\n",
    "\n",
    "otherwise we will query the word and then cache it so that it doesn't miss next time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 23:05:20,711 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the [('on', 0.9999356269836426), ('by', 0.9999175071716309), ('which', 0.9999114274978638), ('also', 0.9999108910560608), ('and', 0.9999102354049683), ('an', 0.9999089241027832), ('for', 0.9999087452888489), ('days', 0.9999085664749146), ('with', 0.9999066591262817), ('australian', 0.9999063014984131)]\n",
      "to [('also', 0.9999505877494812), ('about', 0.9999481439590454), ('for', 0.9999478459358215), ('from', 0.9999448657035828), ('but', 0.9999440312385559), ('at', 0.9999434947967529), ('company', 0.9999430775642395), ('or', 0.9999391436576843), ('before', 0.9999383687973022), ('who', 0.9999364018440247)]\n",
      "of [('and', 0.9999475479125977), ('in', 0.9999444484710693), ('on', 0.9999402761459351), ('with', 0.9999359846115112), ('over', 0.9999345541000366), ('which', 0.9999303221702576), ('after', 0.9999282956123352), ('two', 0.9999276995658875), ('an', 0.9999268651008606), ('into', 0.9999268054962158)]\n"
     ]
    }
   ],
   "source": [
    "# re-enable logging\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "most_similars_precalc = {word : model.wv.most_similar(word) for word in model.wv.index2word}\n",
    "for i, (key, value) in enumerate(most_similars_precalc.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with and without caching\n",
    "-----------------------------------\n",
    "\n",
    "for time being lets take 4 words randomly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "words = ['voted', 'few', 'their', 'around']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without caching\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lower', 0.9980545043945312), ('army', 0.9980535507202148), ('unions', 0.9980233907699585), ('first', 0.9980073571205139), ('secretary', 0.9980006217956543), ('israel', 0.997992753982544), ('weather', 0.9979914426803589), ('air', 0.9979841709136963), ('child', 0.997980535030365), ('team', 0.9979622960090637)]\n",
      "[('were', 0.9997997283935547), ('around', 0.9997900724411011), ('with', 0.9997897744178772), ('three', 0.999785840511322), ('which', 0.9997817873954773), ('for', 0.9997814893722534), ('two', 0.9997813701629639), ('into', 0.9997802376747131), ('now', 0.9997799396514893), ('as', 0.999779462814331)]\n",
      "[('for', 0.9999517202377319), ('at', 0.9999475479125977), ('with', 0.9999464750289917), ('from', 0.9999454021453857), ('also', 0.9999444484710693), ('but', 0.9999433159828186), ('and', 0.999941349029541), ('his', 0.9999404549598694), ('which', 0.9999392032623291), ('were', 0.9999378323554993)]\n",
      "[('with', 0.9999535083770752), ('and', 0.9999483823776245), ('for', 0.9999468326568604), ('after', 0.999946117401123), ('today', 0.9999440908432007), ('which', 0.9999431371688843), ('his', 0.9999428987503052), ('at', 0.9999428391456604), ('an', 0.9999419450759888), ('from', 0.9999410510063171)]\n",
      "0.0024161338806152344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    result = model.wv.most_similar(word)\n",
    "    print(result)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with caching\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lower', 0.9980545043945312), ('army', 0.9980535507202148), ('unions', 0.9980233907699585), ('first', 0.9980073571205139), ('secretary', 0.9980006217956543), ('israel', 0.997992753982544), ('weather', 0.9979914426803589), ('air', 0.9979841709136963), ('child', 0.997980535030365), ('team', 0.9979622960090637)]\n",
      "[('were', 0.9997997283935547), ('around', 0.9997900724411011), ('with', 0.9997897744178772), ('three', 0.999785840511322), ('which', 0.9997817873954773), ('for', 0.9997814893722534), ('two', 0.9997813701629639), ('into', 0.9997802376747131), ('now', 0.9997799396514893), ('as', 0.999779462814331)]\n",
      "[('for', 0.9999517202377319), ('at', 0.9999475479125977), ('with', 0.9999464750289917), ('from', 0.9999454021453857), ('also', 0.9999444484710693), ('but', 0.9999433159828186), ('and', 0.999941349029541), ('his', 0.9999404549598694), ('which', 0.9999392032623291), ('were', 0.9999378323554993)]\n",
      "[('with', 0.9999535083770752), ('and', 0.9999483823776245), ('for', 0.9999468326568604), ('after', 0.999946117401123), ('today', 0.9999440908432007), ('which', 0.9999431371688843), ('his', 0.9999428987503052), ('at', 0.9999428391456604), ('an', 0.9999419450759888), ('from', 0.9999410510063171)]\n",
      "0.0004448890686035156\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    if 'voted' in most_similars_precalc:\n",
    "        result = most_similars_precalc[word]\n",
    "        print(result)\n",
    "    else:\n",
    "        result = model.wv.most_similar(word)\n",
    "        most_similars_precalc[word] = result\n",
    "        print(result)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly you can see the improvement but this difference will be even larger\n",
    "when we take more words in the consideration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the Word Embeddings\n",
    "-------------------------------\n",
    "\n",
    "The word embeddings made by the model can be visualised by reducing\n",
    "dimensionality of the words to 2 dimensions using tSNE.\n",
    "\n",
    "Visualisations can be used to notice semantic and syntactic trends in the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Semantic: words like cat, dog, cow, etc. have a tendency to lie close by\n",
    "* Syntactic: words like run, running or cut, cutting lie close together.\n",
    "\n",
    "Vector relations like vKing - vMan = vQueen - vWoman can also be noticed.\n",
    "\n",
    ".. Important::\n",
    "  The model used for the visualisation is trained on a small corpus. Thus\n",
    "  some of the relations might not be so clear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "hundreds",
          "of",
          "people",
          "have",
          "been",
          "forced",
          "to",
          "their",
          "homes",
          "in",
          "the",
          "southern",
          "new",
          "south",
          "wales",
          "as",
          "strong",
          "winds",
          "today",
          "huge",
          "towards",
          "town",
          "hill",
          "top",
          "blaze",
          "near",
          "west",
          "sydney",
          "has",
          "highway",
          "at",
          "about",
          "pm",
          "aedt",
          "weather",
          "storm",
          "moved",
          "east",
          "across",
          "blue",
          "mountains",
          "authorities",
          "make",
          "decision",
          "from",
          "streets",
          "an",
          "residents",
          "left",
          "for",
          "nearby",
          "rural",
          "fire",
          "service",
          "says",
          "conditions",
          "which",
          "caused",
          "now",
          "and",
          "around",
          "are",
          "all",
          "more",
          "than",
          "blazes",
          "on",
          "year",
          "eve",
          "crews",
          "called",
          "while",
          "few",
          "details",
          "available",
          "this",
          "stage",
          "it",
          "closed",
          "both",
          "meanwhile",
          "is",
          "no",
          "longer",
          "threatening",
          "area",
          "rain",
          "some",
          "parts",
          "illawarra",
          "hunter",
          "north",
          "coast",
          "but",
          "bureau",
          "done",
          "little",
          "any",
          "hundred",
          "fires",
          "still",
          "burning",
          "state",
          "quite",
          "those",
          "areas",
          "less",
          "five",
          "she",
          "said",
          "places",
          "really",
          "not",
          "significant",
          "so",
          "there",
          "much",
          "far",
          "concerned",
          "fact",
          "they",
          "ve",
          "probably",
          "efforts",
          "firefighters",
          "because",
          "wind",
          "that",
          "with",
          "indian",
          "security",
          "forces",
          "shot",
          "dead",
          "eight",
          "suspected",
          "militants",
          "night",
          "long",
          "kashmir",
          "took",
          "place",
          "capital",
          "deaths",
          "came",
          "pakistani",
          "police",
          "arrested",
          "two",
          "groups",
          "accused",
          "attack",
          "india",
          "parliament",
          "pakistan",
          "based",
          "mohammad",
          "carrying",
          "out",
          "december",
          "military",
          "intelligence",
          "tensions",
          "since",
          "raid",
          "sides",
          "troops",
          "along",
          "border",
          "trading",
          "diplomatic",
          "yesterday",
          "announced",
          "had",
          "chief",
          "mohammed",
          "say",
          "likely",
          "raids",
          "will",
          "be",
          "launched",
          "against",
          "well",
          "other",
          "militant",
          "organisations",
          "between",
          "level",
          "seen",
          "war",
          "national",
          "road",
          "toll",
          "christmas",
          "holiday",
          "period",
          "same",
          "time",
          "last",
          "died",
          "roads",
          "queensland",
          "victoria",
          "western",
          "australia",
          "northern",
          "territory",
          "each",
          "recorded",
          "three",
          "act",
          "tasmania",
          "remain",
          "free",
          "argentina",
          "political",
          "economic",
          "crisis",
          "its",
          "interim",
          "president",
          "who",
          "office",
          "just",
          "week",
          "ago",
          "told",
          "nation",
          "he",
          "could",
          "rescue",
          "key",
          "fellow",
          "would",
          "support",
          "his",
          "massive",
          "foreign",
          "debt",
          "or",
          "plan",
          "was",
          "only",
          "million",
          "jobs",
          "end",
          "four",
          "years",
          "recession",
          "days",
          "after",
          "following",
          "series",
          "failed",
          "senate",
          "leader",
          "until",
          "government",
          "too",
          "another",
          "senior",
          "role",
          "elections",
          "scheduled",
          "march",
          "leaving",
          "worst",
          "by",
          "international",
          "six",
          "suspended",
          "hospital",
          "inappropriate",
          "use",
          "during",
          "work",
          "hours",
          "women",
          "were",
          "labour",
          "health",
          "investigation",
          "further",
          "within",
          "executive",
          "officer",
          "tony",
          "one",
          "put",
          "risk",
          "staff",
          "involved",
          "able",
          "take",
          "over",
          "we",
          "re",
          "very",
          "body",
          "our",
          "these",
          "should",
          "know",
          "better",
          "why",
          "action",
          "them",
          "ll",
          "next",
          "federal",
          "asylum",
          "seekers",
          "return",
          "home",
          "when",
          "environment",
          "secure",
          "kabul",
          "affairs",
          "minister",
          "alexander",
          "downer",
          "refused",
          "how",
          "claims",
          "process",
          "hold",
          "major",
          "threat",
          "most",
          "seeking",
          "many",
          "tried",
          "get",
          "into",
          "matter",
          "britain",
          "countries",
          "europe",
          "claimed",
          "fleeing",
          "taliban",
          "power",
          "afghanistan",
          "finished",
          "mass",
          "detainees",
          "island",
          "pacific",
          "nauru",
          "total",
          "operations",
          "using",
          "aircraft",
          "second",
          "delivered",
          "where",
          "temporary",
          "department",
          "immigration",
          "remaining",
          "spokesman",
          "future",
          "yet",
          "made",
          "united",
          "states",
          "team",
          "seles",
          "michael",
          "scored",
          "victory",
          "france",
          "first",
          "hopman",
          "cup",
          "match",
          "perth",
          "up",
          "event",
          "won",
          "singles",
          "give",
          "us",
          "lead",
          "old",
          "currently",
          "start",
          "fight",
          "hard",
          "winning",
          "then",
          "st",
          "down",
          "determined",
          "th",
          "win",
          "americans",
          "go",
          "swiss",
          "final",
          "great",
          "way",
          "tennis",
          "got",
          "my",
          "am",
          "beat",
          "him",
          "even",
          "though",
          "bit",
          "here",
          "keep",
          "if",
          "do",
          "think",
          "chance",
          "anyone",
          "playing",
          "before",
          "taking",
          "set",
          "american",
          "breaking",
          "third",
          "games",
          "expected",
          "her",
          "tough",
          "player",
          "world",
          "position",
          "you",
          "play",
          "want",
          "try",
          "early",
          "season",
          "opening",
          "quickly",
          "game",
          "completed",
          "despite",
          "celebrations",
          "river",
          "kilometres",
          "battling",
          "hot",
          "melbourne",
          "strongly",
          "contested",
          "afternoon",
          "thursday",
          "line",
          "others",
          "fell",
          "red",
          "cross",
          "overnight",
          "containment",
          "lines",
          "severe",
          "getting",
          "forecast",
          "continue",
          "temperatures",
          "high",
          "least",
          "friday",
          "means",
          "fighters",
          "guard",
          "lot",
          "known",
          "contained",
          "however",
          "given",
          "coming",
          "property",
          "greater",
          "brought",
          "under",
          "control",
          "spencer",
          "city",
          "lower",
          "kilometre",
          "protect",
          "communities",
          "morning",
          "large",
          "above",
          "also",
          "used",
          "drop",
          "commissioner",
          "activity",
          "smoke",
          "being",
          "asked",
          "avoid",
          "reduced",
          "hour",
          "access",
          "royal",
          "park",
          "local",
          "allowed",
          "continuing",
          "thousands",
          "storms",
          "struck",
          "force",
          "trees",
          "cars",
          "energy",
          "every",
          "person",
          "working",
          "through",
          "brisbane",
          "toowoomba",
          "car",
          "inside",
          "fierce",
          "sent",
          "tree",
          "house",
          "injured",
          "entered",
          "official",
          "killed",
          "destroyed",
          "part",
          "began",
          "heritage",
          "traditional",
          "trapped",
          "flames",
          "markets",
          "buildings",
          "blame",
          "death",
          "themselves",
          "victims",
          "public",
          "cut",
          "short",
          "inquiry",
          "general",
          "musharraf",
          "wants",
          "prepared",
          "respond",
          "peace",
          "reduce",
          "tension",
          "move",
          "taken",
          "measures",
          "armed",
          "face",
          "might",
          "received",
          "parties",
          "welcomed",
          "community",
          "trying",
          "like",
          "positive",
          "union",
          "group",
          "nations",
          "among",
          "resolve",
          "stand",
          "off",
          "offer",
          "holding",
          "talks",
          "prime",
          "saying",
          "gives",
          "me",
          "accept",
          "reject",
          "meet",
          "january",
          "regional",
          "cooperation",
          "summit",
          "ruled",
          "assault",
          "warned",
          "saturday",
          "dispute",
          "growing",
          "small",
          "conflict",
          "sunday",
          "meeting",
          "situation",
          "domestic",
          "society",
          "form",
          "terrorism",
          "eastern",
          "afghan",
          "british",
          "officials",
          "ended",
          "without",
          "agreement",
          "lack",
          "document",
          "delay",
          "giving",
          "weeks",
          "number",
          "peacekeepers",
          "allow",
          "dr",
          "appeared",
          "signed",
          "already",
          "soon",
          "nothing",
          "sign",
          "proposals",
          "commanders",
          "occupation",
          "israeli",
          "army",
          "palestinian",
          "attacked",
          "gaza",
          "strip",
          "palestinians",
          "opened",
          "vehicle",
          "jewish",
          "edge",
          "sources",
          "post",
          "gunmen",
          "killing",
          "months",
          "including",
          "israelis",
          "october",
          "radical",
          "islamic",
          "hamas",
          "settlement",
          "can",
          "stop",
          "overall",
          "honours",
          "hobart",
          "yacht",
          "race",
          "ian",
          "boat",
          "appears",
          "title",
          "rival",
          "away",
          "nine",
          "metre",
          "boats",
          "australian",
          "losing",
          "geoff",
          "point",
          "apparently",
          "reported",
          "injuries",
          "africa",
          "spinner",
          "test",
          "african",
          "squad",
          "tour",
          "due",
          "injury",
          "captain",
          "shaun",
          "pollock",
          "hopes",
          "prepare",
          "ready",
          "going",
          "come",
          "best",
          "possible",
          "begun",
          "campaign",
          "doubles",
          "hoping",
          "nice",
          "always",
          "good",
          "looking",
          "forward",
          "see",
          "again",
          "hewitt",
          "putting",
          "pressure",
          "himself",
          "month",
          "open",
          "switzerland",
          "tie",
          "reach",
          "grand",
          "per",
          "cent",
          "happens",
          "times",
          "sort",
          "zealand",
          "lord",
          "director",
          "peter",
          "list",
          "seven",
          "classic",
          "country",
          "order",
          "budget",
          "biggest",
          "ever",
          "become",
          "dropped",
          "front",
          "predicted",
          "change",
          "mark",
          "williams",
          "incident",
          "region",
          "back",
          "close",
          "mr",
          "something",
          "don",
          "banks",
          "help",
          "payment",
          "workers",
          "issued",
          "leaders",
          "banking",
          "what",
          "happened",
          "monday",
          "man",
          "crash",
          "mid",
          "boy",
          "hit",
          "telephone",
          "remains",
          "condition",
          "petrol",
          "david",
          "laws",
          "hoped",
          "built",
          "prior",
          "required",
          "such",
          "increase",
          "separate",
          "flights",
          "gun",
          "carry",
          "finally",
          "stopped",
          "plane",
          "travelled",
          "attempting",
          "board",
          "flight",
          "personnel",
          "hand",
          "released",
          "planning",
          "terrorist",
          "ability",
          "airline",
          "problems",
          "follows",
          "paris",
          "explosives",
          "shoes",
          "tourists",
          "safety",
          "central",
          "emergency",
          "search",
          "became",
          "soft",
          "ground",
          "unit",
          "officers",
          "walk",
          "winner",
          "decided",
          "gary",
          "crossed",
          "almost",
          "half",
          "fleet",
          "leading",
          "victorian",
          "minute",
          "clear",
          "fast",
          "skipper",
          "blake",
          "successful",
          "weekend",
          "lost",
          "greatest",
          "concern",
          "changes",
          "extensive",
          "conducted",
          "heading",
          "battle",
          "suicide",
          "backed",
          "never",
          "mind",
          "side",
          "round",
          "ocean",
          "assa",
          "abloy",
          "accompanied",
          "light",
          "starting",
          "crowd",
          "behind",
          "crew",
          "yachts",
          "rest",
          "laden",
          "hearing",
          "court",
          "richard",
          "reid",
          "placed",
          "wall",
          "created",
          "grant",
          "possibility",
          "later",
          "charged",
          "jail",
          "terms",
          "charges",
          "allegedly",
          "airlines",
          "enough",
          "disaster",
          "leadership",
          "calling",
          "envoy",
          "anthony",
          "zinni",
          "cease",
          "retired",
          "marine",
          "late",
          "november",
          "secretary",
          "colin",
          "powell",
          "earlier",
          "bring",
          "halt",
          "statement",
          "yasser",
          "arafat",
          "calls",
          "violence",
          "confidence",
          "building",
          "agreed",
          "several",
          "played",
          "administration",
          "believe",
          "presence",
          "effective",
          "bringing",
          "council",
          "rate",
          "hiv",
          "male",
          "sex",
          "twice",
          "report",
          "centre",
          "disease",
          "need",
          "feel",
          "statistics",
          "show",
          "previous",
          "figures",
          "wake",
          "call",
          "rise",
          "sea",
          "levels",
          "global",
          "according",
          "survey",
          "antarctic",
          "organisation",
          "giant",
          "ice",
          "vaughan",
          "case",
          "serious",
          "increased",
          "water",
          "did",
          "metres",
          "break",
          "related",
          "impact",
          "human",
          "industrial",
          "cannot",
          "problem",
          "potential",
          "cities",
          "low",
          "september",
          "shane",
          "may",
          "room",
          "outlook",
          "certainly",
          "ahead",
          "concerns",
          "continues",
          "carried",
          "mt",
          "targeted",
          "boys",
          "heights",
          "ministry",
          "embassy",
          "representation",
          "ban",
          "planes",
          "delhi",
          "ahmed",
          "actions",
          "complex",
          "mission",
          "movement",
          "added",
          "result",
          "non",
          "operating",
          "threatened",
          "defence",
          "osama",
          "bin",
          "saudi",
          "protection",
          "supporters",
          "helped",
          "create",
          "sure",
          "lives",
          "information",
          "men",
          "arrest",
          "head",
          "party",
          "al",
          "qaeda",
          "network",
          "attacks",
          "york",
          "washington",
          "collapsed",
          "completely",
          "individuals",
          "resistance",
          "mayor",
          "giuliani",
          "led",
          "past",
          "trade",
          "speaking",
          "day",
          "crime",
          "source",
          "difficult",
          "deadly",
          "comes",
          "ensure",
          "your",
          "felt",
          "job",
          "turn",
          "believed",
          "served",
          "term",
          "prevent",
          "media",
          "batsmen",
          "boxing",
          "wicket",
          "runs",
          "andy",
          "bichel",
          "langer",
          "matthew",
          "hayden",
          "went",
          "innings",
          "bowling",
          "jacques",
          "kallis",
          "neil",
          "mckenzie",
          "wickets",
          "balls",
          "caught",
          "although",
          "showed",
          "ball",
          "klusener",
          "boucher",
          "adding",
          "waugh",
          "paid",
          "brett",
          "lee",
          "leg",
          "continued",
          "field",
          "running",
          "henderson",
          "direct",
          "allan",
          "donald",
          "ricky",
          "ponting",
          "returning",
          "glenn",
          "mcgrath",
          "rafter",
          "swept",
          "nearly",
          "whether",
          "survived",
          "pulled",
          "member",
          "found",
          "helicopter",
          "big",
          "wave",
          "knew",
          "arrived",
          "damage",
          "news",
          "radio",
          "suburbs",
          "throughout",
          "average",
          "things",
          "expects",
          "john",
          "confirm",
          "criminal",
          "muslim",
          "extremists",
          "jihad",
          "beginning",
          "television",
          "held",
          "virgin",
          "attempt",
          "ansett",
          "internet",
          "travel",
          "adelaide",
          "launceston",
          "canberra",
          "customers",
          "largest",
          "base",
          "market",
          "press",
          "main",
          "business",
          "endeavour",
          "claim",
          "suffered",
          "life",
          "run",
          "land",
          "bank",
          "heavy",
          "tanks",
          "helicopters",
          "jenin",
          "attacking",
          "immediately",
          "israel",
          "soldiers",
          "returned",
          "escaped",
          "self",
          "rule",
          "authority",
          "injuring",
          "slightly",
          "fired",
          "exchange",
          "sir",
          "actor",
          "civil",
          "yes",
          "wednesday",
          "heart",
          "aged",
          "cancer",
          "having",
          "treatment",
          "awards",
          "approval",
          "range",
          "king",
          "george",
          "secret",
          "thing",
          "cricket",
          "proteas",
          "resume",
          "affected",
          "flying",
          "band",
          "expect",
          "population",
          "passed",
          "mountain",
          "confident",
          "tomorrow",
          "services",
          "whole",
          "fair",
          "share",
          "find",
          "expressed",
          "circumstances",
          "whatever",
          "needs",
          "annual",
          "speech",
          "changed",
          "itself",
          "beyond",
          "america",
          "history",
          "humanity",
          "live",
          "terror",
          "wounded",
          "fighter",
          "weapons",
          "kandahar",
          "governor",
          "custody",
          "surrender",
          "bombing",
          "airport",
          "militia",
          "handed",
          "russian",
          "important",
          "republic",
          "spread",
          "money",
          "look",
          "system",
          "project",
          "ways",
          "prisoners",
          "justice",
          "coalition",
          "families",
          "financial",
          "rights",
          "spokeswoman",
          "trial",
          "education",
          "programs",
          "ms",
          "centrelink",
          "income",
          "employment",
          "pay",
          "child",
          "shopping",
          "sergeant",
          "shortly",
          "members",
          "stuart",
          "bush",
          "question",
          "improve",
          "receiving",
          "questions",
          "pace",
          "jason",
          "gillespie",
          "right",
          "hopefully",
          "provide",
          "bowler",
          "jets",
          "saw",
          "passengers",
          "ceremony",
          "hamid",
          "karzai",
          "cabinet",
          "economy",
          "cost",
          "dollars",
          "must",
          "plans",
          "projects",
          "various",
          "believes",
          "tora",
          "bora",
          "caves",
          "visit",
          "bid",
          "does",
          "enter",
          "searching",
          "signs",
          "suspect",
          "warplanes",
          "commander",
          "charge",
          "gone",
          "pentagon",
          "macgill",
          "full",
          "steve",
          "adam",
          "warne",
          "rejected",
          "terrorists",
          "ariel",
          "sharon",
          "declared",
          "staying",
          "bombings",
          "smaller",
          "follow",
          "save",
          "young",
          "requested",
          "normal",
          "technology",
          "ill",
          "professor",
          "deputy",
          "institute",
          "law",
          "opposition",
          "thought",
          "family",
          "making",
          "japanese",
          "unidentified",
          "reports",
          "japan",
          "warning",
          "approach",
          "church",
          "handling",
          "alleged",
          "abuse",
          "anglican",
          "school",
          "howard",
          "hollingworth",
          "criticism",
          "archbishop",
          "resign",
          "costello",
          "explanation",
          "needed",
          "step",
          "understanding",
          "simon",
          "crean",
          "described",
          "legal",
          "advice",
          "heard",
          "understand",
          "gave",
          "confirmed",
          "timor",
          "comment",
          "responsibility",
          "leave",
          "company",
          "guess",
          "unity",
          "followed",
          "program",
          "fund",
          "policy",
          "effort",
          "freeze",
          "qantas",
          "maintenance",
          "relations",
          "commission",
          "employees",
          "billion",
          "gas",
          "reached",
          "phillips",
          "deal",
          "offered",
          "ministers",
          "abu",
          "worked",
          "documents",
          "factory",
          "former",
          "true",
          "read",
          "tell",
          "real",
          "detail",
          "names",
          "premier",
          "facility",
          "allegations",
          "knowledge",
          "evidence",
          "voted",
          "deployed",
          "initial",
          "mandate",
          "assistance",
          "un",
          "resolution",
          "numbers",
          "eventually",
          "germany",
          "bonn",
          "anti",
          "nuclear",
          "assisting",
          "bomb",
          "provided",
          "crackdown",
          "food",
          "clashes",
          "powers",
          "fear",
          "unrest",
          "own",
          "woomera",
          "detention",
          "visa",
          "outside",
          "recent",
          "bill",
          "private",
          "sector",
          "credit",
          "data",
          "doctors",
          "ask",
          "research",
          "companies",
          "medical",
          "record",
          "often",
          "solution",
          "consumers",
          "dozens",
          "seriously",
          "roof",
          "children",
          "witnesses",
          "collapse",
          "everything",
          "fine",
          "manager",
          "afp",
          "agency",
          "corporation",
          "son",
          "zimbabwe",
          "white",
          "commonwealth",
          "mean",
          "issue",
          "declaration",
          "table",
          "waiting",
          "response",
          "request",
          "observers",
          "election",
          "territories",
          "nablus",
          "improved",
          "pre",
          "bombers",
          "jerusalem",
          "haifa",
          "interest",
          "unfortunately",
          "robert",
          "august",
          "senator",
          "whereabouts",
          "hicks",
          "fighting",
          "alongside",
          "vote",
          "relationship",
          "operation",
          "latest",
          "stay",
          "assembly",
          "elders",
          "draft",
          "damaged",
          "current",
          "voice",
          "twenty",
          "reveal",
          "refugees",
          "australians",
          "detain",
          "transport",
          "air",
          "strachan",
          "training",
          "crashed",
          "strike",
          "accident",
          "students",
          "findings",
          "harris",
          "investment",
          "asic",
          "include",
          "counts",
          "acting",
          "management",
          "coroner",
          "investigating",
          "hearings",
          "ray",
          "qc",
          "representing",
          "experts",
          "begin",
          "named",
          "sometimes",
          "advance",
          "marines",
          "revealed",
          "captured",
          "hunt",
          "jalalabad",
          "bomber",
          "strikes",
          "actually",
          "responding",
          "insurance",
          "alliance",
          "approached",
          "july",
          "proposed",
          "labor",
          "issues",
          "options",
          "didn",
          "single",
          "anything",
          "fatah",
          "factions",
          "rather",
          "offices",
          "started",
          "tuesday",
          "focus",
          "strategic",
          "targets",
          "review",
          "meetings",
          "violent",
          "farm",
          "discussions",
          "debate",
          "disappointed",
          "philip",
          "ruddock",
          "understood",
          "attorney",
          "daryl",
          "aboard",
          "asio",
          "appropriate",
          "present",
          "finding",
          "tribal",
          "doubt",
          "pilot",
          "procedures",
          "aboriginal",
          "sentence",
          "administrators",
          "paying",
          "entitlements",
          "redundancy",
          "decide",
          "absolutely",
          "hih",
          "creditors",
          "firm",
          "chairman",
          "finance",
          "directors",
          "receive",
          "tailenders",
          "scene",
          "channel",
          "facilities",
          "whose",
          "examination",
          "unions",
          "adequate",
          "together",
          "necessary",
          "rumsfeld",
          "networks",
          "recovery",
          "decisions",
          "oil",
          "growth",
          "structure",
          "university",
          "cause",
          "negotiations",
          "club",
          "elected",
          "happy",
          "picked",
          "outcome",
          "treated",
          "hope",
          "headquarters",
          "cave",
          "interview",
          "different",
          "investigate",
          "escalating",
          "doing",
          "french",
          "negotiating",
          "address",
          "middle",
          "wanted",
          "locked",
          "wage",
          "manufacturing",
          "doug",
          "cameron",
          "seemed",
          "sharing",
          "sending",
          "quarter",
          "coup",
          "invasion",
          "shows",
          "volunteers",
          "clean",
          "track",
          "space",
          "shuttle",
          "station",
          "landed",
          "trip",
          "walked",
          "proposal",
          "publicly",
          "hotel",
          "indonesian",
          "suharto",
          "vice",
          "indonesia",
          "solomon",
          "islands",
          "ballot",
          "positions",
          "ethnic",
          "success",
          "conference",
          "met",
          "words",
          "target",
          "fall",
          "special",
          "interests",
          "promised",
          "doesn",
          "costs",
          "yallourn",
          "mining",
          "convicted",
          "whiting",
          "murder",
          "sarah",
          "career",
          "hijacked",
          "tape",
          "sheikh",
          "aware",
          "denied",
          "connection",
          "underway",
          "woman",
          "infected",
          "gunships",
          "bus",
          "ambush",
          "blasted",
          "ramallah",
          "wing",
          "responsible",
          "unemployment",
          "westpac",
          "anz",
          "bargaining",
          "industry",
          "lording",
          "construction",
          "cfmeu",
          "martin",
          "kingham",
          "faces",
          "bob",
          "neville",
          "headed",
          "clearly",
          "unable",
          "guilty",
          "verdict",
          "ford",
          "lockett",
          "interlaken",
          "tragedy",
          "adventure",
          "canyoning",
          "manslaughter",
          "guides",
          "farmers",
          "coach",
          "co",
          "friedli",
          "francs",
          "gang",
          "reserve",
          "committee",
          "drug",
          "study",
          "decades",
          "results",
          "doctor",
          "gambier",
          "path",
          "amin",
          "peres",
          "determine",
          "lung",
          "kieren",
          "champion",
          "suggested",
          "rates",
          "provisional",
          "liquidation",
          "civilians",
          "sultan",
          "course",
          "butterfly",
          "afroz",
          "goshen",
          "wayne",
          "flood",
          "gorge",
          "gerber",
          "kissinger",
          "stability",
          "replied",
          "launch",
          "davis",
          "krishna",
          "products",
          "chosen",
          "treasurer",
          "cuts",
          "natural",
          "races",
          "eliminated",
          "austar",
          "traveland",
          "apra",
          "masood",
          "tonight",
          "rabbani",
          "virus",
          "ses",
          "harrison",
          "ashes",
          "benares",
          "beatle",
          "hare",
          "choosing",
          "owen"
         ],
         "type": "scatter",
         "x": [
          -12.49445915222168,
          55.020111083984375,
          52.11457443237305,
          55.17595672607422,
          52.84236145019531,
          -22.01788902282715,
          55.626834869384766,
          54.48806381225586,
          -35.29669952392578,
          55.29194259643555,
          54.064823150634766,
          -10.054299354553223,
          54.80254364013672,
          54.75698471069336,
          20.19831657409668,
          55.10423278808594,
          22.411130905151367,
          16.985227584838867,
          53.11782455444336,
          -44.55323791503906,
          -13.73154354095459,
          -22.352815628051758,
          20.30546760559082,
          -39.555015563964844,
          0.0016319080023095012,
          45.58504867553711,
          46.31407165527344,
          50.57473373413086,
          55.75495529174805,
          -42.029457092285156,
          55.724884033203125,
          53.79914474487305,
          -16.446151733398438,
          -18.983726501464844,
          31.204137802124023,
          -14.096541404724121,
          3.6540884971618652,
          45.4666633605957,
          19.172863006591797,
          1.657549500465393,
          16.37669563293457,
          25.986526489257812,
          34.10365295410156,
          2.7699618339538574,
          55.77836227416992,
          21.479507446289062,
          54.871097564697266,
          -38.40876388549805,
          39.61507797241211,
          55.44145965576172,
          17.096853256225586,
          -37.17818069458008,
          52.658443450927734,
          28.274993896484375,
          55.37104034423828,
          17.111295700073242,
          54.21613693237305,
          -44.16450119018555,
          51.28910446166992,
          55.255577087402344,
          50.79532241821289,
          55.44769287109375,
          50.92283630371094,
          53.29655075073242,
          52.10264205932617,
          5.050864219665527,
          55.58917999267578,
          53.88882827758789,
          16.303722381591797,
          3.997213363647461,
          35.833091735839844,
          46.75838851928711,
          10.835441589355469,
          -26.585115432739258,
          -44.4093132019043,
          54.349857330322266,
          -31.35323143005371,
          54.178035736083984,
          11.67601203918457,
          31.560964584350586,
          40.005470275878906,
          55.2210693359375,
          51.3885498046875,
          -8.147910118103027,
          16.491682052612305,
          38.449737548828125,
          13.84128475189209,
          51.37407302856445,
          13.281671524047852,
          16.40268325805664,
          4.589776515960693,
          42.400264739990234,
          -33.212120056152344,
          54.67912292480469,
          1.940852403640747,
          -39.9106330871582,
          7.072291851043701,
          51.15826416015625,
          7.532176971435547,
          6.537481784820557,
          50.31991195678711,
          -37.50724411010742,
          47.569026947021484,
          -41.60829544067383,
          43.98863983154297,
          42.18946075439453,
          -39.75769805908203,
          48.94847869873047,
          42.73683166503906,
          54.7765998840332,
          -32.13826370239258,
          1.1861038208007812,
          54.055267333984375,
          -40.42177200317383,
          48.42385482788086,
          52.432411193847656,
          13.213031768798828,
          -44.578495025634766,
          -43.41343307495117,
          16.447162628173828,
          54.642799377441406,
          35.91136932373047,
          -36.51720428466797,
          16.150516510009766,
          11.739582061767578,
          45.127994537353516,
          0.513700008392334,
          54.71750259399414,
          55.674583435058594,
          28.181427001953125,
          51.15463638305664,
          45.90859603881836,
          -7.821333885192871,
          15.625496864318848,
          38.052547454833984,
          -41.308441162109375,
          17.692625045776367,
          44.15863800048828,
          36.1984977722168,
          9.040755271911621,
          17.95916748046875,
          32.654842376708984,
          -30.793354034423828,
          -28.110490798950195,
          8.8060941696167,
          -39.89732360839844,
          51.86484909057617,
          4.071391582489014,
          54.99821472167969,
          34.51055145263672,
          -4.019925117492676,
          43.29726028442383,
          35.733394622802734,
          -23.78297996520996,
          47.0733528137207,
          -24.347360610961914,
          -10.411368370056152,
          -10.628006935119629,
          53.87865447998047,
          10.87021541595459,
          46.93095016479492,
          -38.861690521240234,
          13.402504920959473,
          43.4542350769043,
          16.28459930419922,
          15.220739364624023,
          23.031641006469727,
          -0.028703350573778152,
          -44.85806655883789,
          0.1207953691482544,
          15.84861946105957,
          49.09025955200195,
          -40.206687927246094,
          54.522220611572266,
          38.48880386352539,
          10.289761543273926,
          50.95368194580078,
          -41.40241622924805,
          -44.303890228271484,
          54.518001556396484,
          53.5393180847168,
          -6.457818984985352,
          52.91469192504883,
          41.163448333740234,
          48.88412857055664,
          -35.00470733642578,
          -15.910881042480469,
          46.27433395385742,
          10.308094024658203,
          -30.98959732055664,
          15.1356840133667,
          45.49327087402344,
          -39.12260818481445,
          0.4514407813549042,
          31.108293533325195,
          7.9768571853637695,
          -39.86130142211914,
          -37.939918518066406,
          46.49000549316406,
          53.17931365966797,
          41.13996505737305,
          -18.016199111938477,
          28.51923370361328,
          -43.95705795288086,
          -23.266632080078125,
          52.61781692504883,
          39.836891174316406,
          -30.970706939697266,
          -33.86326599121094,
          -5.6478095054626465,
          52.74962615966797,
          -6.602885723114014,
          -7.939851760864258,
          -3.278406858444214,
          -13.819392204284668,
          -26.00867462158203,
          -7.53117036819458,
          14.606440544128418,
          0.7378872632980347,
          53.433753967285156,
          18.380245208740234,
          50.70555877685547,
          54.455753326416016,
          -32.34546661376953,
          49.78509521484375,
          41.71857833862305,
          36.85905456542969,
          53.13185119628906,
          -23.088314056396484,
          53.121246337890625,
          51.71699905395508,
          16.177152633666992,
          -0.7137146592140198,
          1.4195351600646973,
          53.5007438659668,
          29.233766555786133,
          54.99588394165039,
          -45.838623046875,
          42.99578094482422,
          -21.55352783203125,
          52.330299377441406,
          3.4482522010803223,
          53.6986198425293,
          38.871559143066406,
          -7.261913776397705,
          -24.8358097076416,
          33.12970733642578,
          51.963722229003906,
          39.04872131347656,
          21.267658233642578,
          49.61699676513672,
          55.750606536865234,
          38.193931579589844,
          -42.31508255004883,
          -28.211278915405273,
          -8.781936645507812,
          44.32265090942383,
          -44.850929260253906,
          52.524818420410156,
          25.677974700927734,
          40.821311950683594,
          37.1110954284668,
          3.465892791748047,
          -10.841669082641602,
          9.678325653076172,
          -6.606879711151123,
          -2.405317783355713,
          -11.87809944152832,
          55.36552429199219,
          47.090660095214844,
          44.7228889465332,
          14.357340812683105,
          33.669063568115234,
          6.486199855804443,
          -2.92879056930542,
          43.565643310546875,
          35.10602951049805,
          40.96857833862305,
          -29.385530471801758,
          55.37973403930664,
          0.3521845042705536,
          13.75926399230957,
          -43.287906646728516,
          42.990848541259766,
          -27.940834045410156,
          -8.619616508483887,
          -44.1116943359375,
          -23.225940704345703,
          52.70397186279297,
          31.764060974121094,
          2.733612298965454,
          40.48747634887695,
          -37.62126922607422,
          -40.7890739440918,
          39.39573669433594,
          53.27996826171875,
          54.78400421142578,
          46.96540069580078,
          50.07201385498047,
          7.032276153564453,
          47.676422119140625,
          36.54268264770508,
          42.977684020996094,
          35.32401657104492,
          21.069400787353516,
          16.14577293395996,
          48.116817474365234,
          50.28848648071289,
          3.5937743186950684,
          47.41598129272461,
          44.95382308959961,
          20.496973037719727,
          18.07258415222168,
          4.062146186828613,
          -5.324862480163574,
          54.38218688964844,
          19.028005599975586,
          10.231147766113281,
          -11.360869407653809,
          19.28783416748047,
          54.968902587890625,
          -45.11469650268555,
          -11.082618713378906,
          -31.349838256835938,
          36.79210662841797,
          40.333091735839844,
          7.4961957931518555,
          10.627026557922363,
          12.646942138671875,
          -38.3040885925293,
          39.340763092041016,
          6.216203212738037,
          36.2823486328125,
          6.915467739105225,
          42.67972183227539,
          54.1357307434082,
          -44.62827682495117,
          -2.942913055419922,
          -13.476244926452637,
          8.16152286529541,
          -7.251429080963135,
          -22.201082229614258,
          50.966339111328125,
          41.06924819946289,
          52.25968551635742,
          18.329805374145508,
          -11.535842895507812,
          22.532506942749023,
          -45.512062072753906,
          -23.463932037353516,
          -41.16160583496094,
          -0.4388323128223419,
          -35.6345329284668,
          -42.87376022338867,
          23.63214683532715,
          44.34318542480469,
          -5.075011730194092,
          49.49677658081055,
          3.7600913047790527,
          -21.251728057861328,
          -40.7056884765625,
          11.074946403503418,
          26.956222534179688,
          0.0014531896449625492,
          -18.361061096191406,
          47.36408615112305,
          49.15038299560547,
          50.667579650878906,
          40.77415466308594,
          17.24605369567871,
          2.4609804153442383,
          19.79878044128418,
          -19.732290267944336,
          -4.928314208984375,
          53.230064392089844,
          14.478710174560547,
          27.777856826782227,
          20.771255493164062,
          -40.560707092285156,
          53.740577697753906,
          9.463117599487305,
          26.139862060546875,
          3.915987014770508,
          -1.9586087465286255,
          52.955284118652344,
          14.650367736816406,
          47.273128509521484,
          -41.837181091308594,
          27.07137680053711,
          -42.31621170043945,
          -15.60762882232666,
          -6.22139835357666,
          40.244468688964844,
          18.013803482055664,
          49.03567886352539,
          -19.213775634765625,
          2.146848201751709,
          25.584327697753906,
          -11.779606819152832,
          38.96891784667969,
          -33.7855224609375,
          -13.028340339660645,
          -21.861650466918945,
          17.29146957397461,
          -40.08289337158203,
          8.002287864685059,
          -30.862119674682617,
          40.02039337158203,
          -44.70114517211914,
          42.64238739013672,
          18.893354415893555,
          -44.73053741455078,
          7.013421058654785,
          0.635797381401062,
          -18.882797241210938,
          53.63247299194336,
          37.563987731933594,
          48.30784225463867,
          -3.5741398334503174,
          -13.682205200195312,
          -39.1129264831543,
          53.732521057128906,
          -26.804908752441406,
          38.45545959472656,
          -3.4433183670043945,
          19.72844696044922,
          34.42900085449219,
          -17.340200424194336,
          30.104459762573242,
          11.27469253540039,
          21.692323684692383,
          5.954702854156494,
          52.76416778564453,
          -15.01302719116211,
          53.5932502746582,
          14.946006774902344,
          12.438104629516602,
          -43.337459564208984,
          9.356472969055176,
          -41.715476989746094,
          -37.901519775390625,
          -44.64073944091797,
          -0.593230664730072,
          -16.8835391998291,
          16.511564254760742,
          18.114234924316406,
          27.782230377197266,
          -42.692665100097656,
          19.6557559967041,
          5.566519737243652,
          42.1246452331543,
          12.9765625,
          2.097168445587158,
          -42.99742889404297,
          -37.90163040161133,
          20.81451416015625,
          -8.237899780273438,
          16.802658081054688,
          -13.281123161315918,
          18.36837387084961,
          22.59388542175293,
          19.502153396606445,
          -32.398216247558594,
          -24.56598472595215,
          -40.034603118896484,
          -17.93609619140625,
          -8.8029203414917,
          -17.390151977539062,
          31.514209747314453,
          -41.81496047973633,
          -37.294227600097656,
          -18.707365036010742,
          33.6474494934082,
          15.6942720413208,
          -2.4737167358398438,
          -35.46638107299805,
          -18.6118106842041,
          22.530729293823242,
          28.177749633789062,
          15.9600830078125,
          -17.376895904541016,
          -28.712888717651367,
          -12.890669822692871,
          47.636505126953125,
          10.326537132263184,
          14.666142463684082,
          45.0463752746582,
          -44.852169036865234,
          11.608062744140625,
          -40.9514045715332,
          2.4741265773773193,
          43.233375549316406,
          -18.984363555908203,
          17.673425674438477,
          53.69934844970703,
          10.081666946411133,
          -43.74879455566406,
          -13.082319259643555,
          -32.169551849365234,
          -9.756959915161133,
          49.912071228027344,
          26.21824073791504,
          16.243070602416992,
          1.4300682544708252,
          -18.084623336791992,
          -39.70833969116211,
          37.625999450683594,
          21.998720169067383,
          47.64049530029297,
          -5.066882133483887,
          -17.046030044555664,
          -33.13038635253906,
          -42.1634407043457,
          -35.825687408447266,
          43.720191955566406,
          -26.755481719970703,
          3.2038848400115967,
          2.6157705783843994,
          0.700657308101654,
          -3.3933682441711426,
          12.84287166595459,
          46.364742279052734,
          -34.53535079956055,
          16.575984954833984,
          -36.99375915527344,
          -40.393348693847656,
          4.948148727416992,
          -42.67792892456055,
          12.022978782653809,
          8.206470489501953,
          12.284930229187012,
          21.394441604614258,
          33.66312789916992,
          43.37147903442383,
          -9.899002075195312,
          22.859825134277344,
          -45.289306640625,
          11.535582542419434,
          19.56614112854004,
          20.428598403930664,
          -9.411809921264648,
          0.02480427920818329,
          -30.09309196472168,
          -3.8308684825897217,
          -23.68024253845215,
          5.832739353179932,
          19.788000106811523,
          32.65721130371094,
          0.9086244702339172,
          -30.209787368774414,
          -42.57746505737305,
          51.47346115112305,
          -12.812432289123535,
          -45.528263092041016,
          12.847396850585938,
          5.456657886505127,
          37.949462890625,
          -15.164544105529785,
          18.705585479736328,
          -10.848381042480469,
          6.3369460105896,
          -38.638126373291016,
          5.620513916015625,
          -14.545989990234375,
          -18.59168243408203,
          -4.309532642364502,
          -29.790620803833008,
          -13.051201820373535,
          -5.3736572265625,
          4.11247444152832,
          32.99428939819336,
          4.0298919677734375,
          48.74807357788086,
          48.341556549072266,
          -1.7365782260894775,
          -19.141321182250977,
          -21.094289779663086,
          -18.084991455078125,
          44.37400817871094,
          14.198009490966797,
          -18.616214752197266,
          33.00727844238281,
          28.761058807373047,
          27.775619506835938,
          -16.078414916992188,
          -34.57032012939453,
          -21.881715774536133,
          6.584284782409668,
          18.52934455871582,
          20.65412139892578,
          0.10415294021368027,
          -12.410590171813965,
          19.868440628051758,
          15.835236549377441,
          16.181047439575195,
          -43.692508697509766,
          -15.803078651428223,
          -18.446935653686523,
          -15.024028778076172,
          21.657045364379883,
          4.8805623054504395,
          -23.7355899810791,
          46.67898178100586,
          -41.02706527709961,
          10.238702774047852,
          1.4075604677200317,
          -44.82384490966797,
          21.902528762817383,
          -0.22434934973716736,
          45.7053108215332,
          13.758384704589844,
          46.83857345581055,
          13.398771286010742,
          25.462541580200195,
          27.25275421142578,
          14.261774063110352,
          21.079790115356445,
          -22.49371337890625,
          -43.14228057861328,
          -25.984392166137695,
          38.46006774902344,
          18.308813095092773,
          -12.355536460876465,
          32.91038513183594,
          -22.351192474365234,
          -10.826624870300293,
          -3.3476290702819824,
          -31.09383201599121,
          0.7377815246582031,
          19.090200424194336,
          17.316959381103516,
          -11.815529823303223,
          -27.146907806396484,
          53.18452453613281,
          -15.301145553588867,
          54.13895034790039,
          21.128700256347656,
          44.54839324951172,
          -24.047853469848633,
          -5.418498992919922,
          -27.419998168945312,
          -20.266159057617188,
          7.833260536193848,
          7.9297871589660645,
          -41.04811096191406,
          -41.917755126953125,
          -34.06919860839844,
          -33.37279510498047,
          39.78579330444336,
          46.524131774902344,
          2.860750675201416,
          -23.73433494567871,
          -22.831941604614258,
          45.89739227294922,
          47.30860137939453,
          5.085324764251709,
          49.3868408203125,
          6.740398406982422,
          -37.67167282104492,
          21.663185119628906,
          -43.99078369140625,
          -39.784000396728516,
          32.50724411010742,
          20.04357147216797,
          -19.591936111450195,
          8.283878326416016,
          -3.4103965759277344,
          20.850881576538086,
          -38.47383499145508,
          16.611881256103516,
          20.82097625732422,
          18.49530029296875,
          54.83116149902344,
          5.26511812210083,
          -44.911991119384766,
          -6.850325584411621,
          11.94946002960205,
          -44.209754943847656,
          18.066429138183594,
          7.11790657043457,
          -3.973318338394165,
          50.29159927368164,
          -7.399674415588379,
          18.543109893798828,
          -23.407493591308594,
          0.5576720237731934,
          13.729338645935059,
          17.769432067871094,
          -41.34672927856445,
          -45.01293182373047,
          17.060441970825195,
          8.962685585021973,
          -8.23430061340332,
          32.23979949951172,
          33.220916748046875,
          -2.87813138961792,
          13.67853832244873,
          1.1943492889404297,
          -0.8162147998809814,
          -34.13283157348633,
          20.01097869873047,
          -15.085856437683105,
          -43.27125930786133,
          22.704500198364258,
          25.134410858154297,
          -32.47905349731445,
          -11.350924491882324,
          -0.2522362172603607,
          -40.802913665771484,
          -23.166101455688477,
          9.978034973144531,
          -23.195520401000977,
          44.25033950805664,
          -12.856393814086914,
          21.163928985595703,
          -1.1953846216201782,
          18.205127716064453,
          17.781789779663086,
          47.01769256591797,
          49.30824279785156,
          17.5380859375,
          -42.24021911621094,
          20.989452362060547,
          -35.02614974975586,
          -2.277555227279663,
          21.563709259033203,
          36.96432113647461,
          -28.48929786682129,
          -23.137239456176758,
          12.927525520324707,
          -8.589566230773926,
          -43.727813720703125,
          0.19719088077545166,
          -36.02598190307617,
          -4.274661064147949,
          -37.30955123901367,
          19.02048110961914,
          -37.13417053222656,
          14.092643737792969,
          16.790584564208984,
          9.146965980529785,
          19.771503448486328,
          -7.987490177154541,
          2.12626576423645,
          39.60554122924805,
          27.2115478515625,
          54.014408111572266,
          -36.11121368408203,
          37.29484176635742,
          -42.687381744384766,
          24.94644546508789,
          16.573179244995117,
          48.962764739990234,
          -5.840967655181885,
          10.640377044677734,
          -12.052047729492188,
          49.366722106933594,
          19.592084884643555,
          19.378305435180664,
          43.716156005859375,
          -22.222469329833984,
          19.02008056640625,
          -32.51442337036133,
          28.686748504638672,
          4.809787273406982,
          -10.427916526794434,
          19.29393196105957,
          -6.690701961517334,
          -1.1197723150253296,
          -26.693668365478516,
          -30.456985473632812,
          -13.882079124450684,
          14.129671096801758,
          -7.568148612976074,
          -7.7622199058532715,
          -32.029056549072266,
          -14.599780082702637,
          -43.06575012207031,
          -10.308676719665527,
          12.62861442565918,
          18.82349967956543,
          -2.4969019889831543,
          -17.87324333190918,
          17.780677795410156,
          -0.5689141750335693,
          -27.313156127929688,
          -24.253305435180664,
          4.582822322845459,
          -22.272518157958984,
          13.861353874206543,
          -38.43978500366211,
          12.992959022521973,
          -30.262170791625977,
          18.7828426361084,
          -11.791071891784668,
          18.57310676574707,
          -9.387548446655273,
          0.5772721171379089,
          -31.856769561767578,
          -40.3291130065918,
          28.46179962158203,
          2.25860857963562,
          -15.73443603515625,
          16.100746154785156,
          19.383535385131836,
          21.156457901000977,
          -43.68878936767578,
          7.177173137664795,
          -12.50881290435791,
          21.58918571472168,
          -43.28391647338867,
          -43.1318359375,
          9.82232666015625,
          6.256849765777588,
          -23.30791664123535,
          -43.30471420288086,
          -24.994476318359375,
          6.516464710235596,
          -23.335247039794922,
          10.138301849365234,
          8.1683931350708,
          -21.696144104003906,
          -29.481735229492188,
          -13.0247163772583,
          -11.017273902893066,
          -17.710939407348633,
          -3.0174190998077393,
          20.307992935180664,
          -27.16854476928711,
          -44.09020233154297,
          19.892608642578125,
          18.487573623657227,
          -10.7702054977417,
          -4.2039875984191895,
          46.1130485534668,
          -13.501031875610352,
          -9.133575439453125,
          -21.931665420532227,
          -35.549781799316406,
          -39.7562255859375,
          17.886877059936523,
          -0.749016523361206,
          -4.162211894989014,
          18.722246170043945,
          7.993806838989258,
          -6.848008155822754,
          -43.9135627746582,
          1.5019809007644653,
          9.826610565185547,
          -17.840593338012695,
          15.414807319641113,
          49.6399040222168,
          -0.4533572494983673,
          33.12154006958008,
          -3.5545480251312256,
          -14.063443183898926,
          -33.9827766418457,
          -6.04891300201416,
          -6.205697536468506,
          -1.4030216932296753,
          -21.33706283569336,
          -14.026286125183105,
          -41.355411529541016,
          -43.03177261352539,
          -44.52192687988281,
          10.646848678588867,
          9.567787170410156,
          -40.020545959472656,
          -42.33205032348633,
          -26.6612606048584,
          -8.285783767700195,
          -24.024658203125,
          -34.077762603759766,
          -28.435592651367188,
          5.7219767570495605,
          -4.107591152191162,
          11.008074760437012,
          12.025497436523438,
          -6.347211837768555,
          -43.8688850402832,
          36.70685577392578,
          12.154744148254395,
          -9.740888595581055,
          44.045753479003906,
          4.633545875549316,
          8.034158706665039,
          35.4539680480957,
          27.65406036376953,
          51.66172790527344,
          -39.30633544921875,
          10.252229690551758,
          14.937081336975098,
          29.25960922241211,
          8.265103340148926,
          43.76450729370117,
          -24.384841918945312,
          -3.7541537284851074,
          8.334988594055176,
          -8.788456916809082,
          20.125736236572266,
          -17.152170181274414,
          15.147871017456055,
          10.797563552856445,
          -2.7289891242980957,
          9.545156478881836,
          -42.524044036865234,
          -8.788710594177246,
          42.6188850402832,
          43.46627426147461,
          -29.469778060913086,
          15.787721633911133,
          17.522497177124023,
          15.447530746459961,
          -45.40361022949219,
          3.9428164958953857,
          -44.45234680175781,
          11.0889892578125,
          -22.400148391723633,
          -33.258323669433594,
          -38.735260009765625,
          -8.213305473327637,
          -33.330692291259766,
          -26.578563690185547,
          -15.54548454284668,
          13.629755973815918,
          -44.678855895996094,
          -33.7755126953125,
          -15.112027168273926,
          15.759539604187012,
          -31.47842025756836,
          -45.027103424072266,
          -17.55902099609375,
          -2.463787794113159,
          11.778627395629883,
          43.086936950683594,
          -38.52471160888672,
          8.17796802520752,
          -31.267602920532227,
          -35.90013122558594,
          33.304771423339844,
          -26.34864044189453,
          1.8021024465560913,
          -14.278609275817871,
          18.344005584716797,
          14.410895347595215,
          29.98880386352539,
          9.024016380310059,
          13.485508918762207,
          3.4793572425842285,
          1.0826212167739868,
          -39.017005920410156,
          10.856244087219238,
          16.06818199157715,
          11.691006660461426,
          -44.4103889465332,
          -2.4418201446533203,
          6.2981743812561035,
          18.1474552154541,
          10.662590980529785,
          -5.043787956237793,
          6.959690093994141,
          -38.42216873168945,
          20.499528884887695,
          20.652748107910156,
          -4.58551025390625,
          19.937240600585938,
          -25.81007957458496,
          -45.51158142089844,
          -38.42213821411133,
          -14.654274940490723,
          -35.91353225708008,
          -19.067628860473633,
          -3.7381062507629395,
          -9.335721969604492,
          19.155555725097656,
          40.24428939819336,
          40.7655143737793,
          50.4290885925293,
          18.945085525512695,
          20.51335334777832,
          -26.63544273376465,
          4.104704856872559,
          -22.39359474182129,
          -44.52919387817383,
          -24.836915969848633,
          7.280148506164551,
          7.622426986694336,
          26.352548599243164,
          3.1069931983947754,
          4.811017990112305,
          49.03807067871094,
          46.167232513427734,
          -23.97056770324707,
          49.898216247558594,
          -39.065032958984375,
          -31.569507598876953,
          18.764028549194336,
          16.16533660888672,
          6.961907863616943,
          -30.68402862548828,
          10.137479782104492,
          -2.203627824783325,
          19.88812255859375,
          -31.0932559967041,
          -26.736370086669922,
          -35.388553619384766,
          51.203006744384766,
          9.306061744689941,
          -5.518133163452148,
          10.61337947845459,
          11.011276245117188,
          -43.876129150390625,
          -10.322552680969238,
          21.740447998046875,
          19.317590713500977,
          -25.907695770263672,
          -0.25811007618904114,
          -18.668659210205078,
          -1.6286581754684448,
          18.030973434448242,
          -22.93575096130371,
          -21.073328018188477,
          -2.1117103099823,
          -5.801956653594971,
          -36.2501106262207,
          5.694543838500977,
          -43.35242462158203,
          6.273709297180176,
          18.372665405273438,
          0.31068024039268494,
          -34.039283752441406,
          18.318143844604492,
          -30.040069580078125,
          -36.70550537109375,
          -39.05324172973633,
          -13.469698905944824,
          -7.809794902801514,
          -44.312828063964844,
          -16.762723922729492,
          -18.710615158081055,
          -35.79670715332031,
          12.355931282043457,
          20.182687759399414,
          -1.5723944902420044,
          -0.014453024603426456,
          -22.345779418945312,
          2.8105313777923584,
          33.52159881591797,
          10.840516090393066,
          -34.42837905883789,
          22.073612213134766,
          -38.98948287963867,
          -42.14162826538086,
          -0.29607605934143066,
          -19.646953582763672,
          6.48014497756958,
          -35.3214225769043,
          -44.85791778564453,
          -43.1988525390625,
          -19.820283889770508,
          -16.0548095703125,
          -5.173451900482178,
          -36.11809158325195,
          -26.702144622802734,
          -37.500064849853516,
          12.244173049926758,
          -15.531746864318848,
          37.65088653564453,
          8.093867301940918,
          13.779080390930176,
          -14.383763313293457,
          29.072463989257812,
          -11.214729309082031,
          -44.606136322021484,
          -41.52203369140625,
          -3.982797145843506,
          -14.268044471740723,
          7.415810585021973,
          14.785006523132324,
          23.51175880432129,
          15.876057624816895,
          4.997437477111816,
          11.647825241088867,
          5.107263088226318,
          11.828742980957031,
          32.96696090698242,
          20.02205467224121,
          14.898689270019531,
          -13.487970352172852,
          4.180504322052002,
          -33.58758544921875,
          9.033266067504883,
          -45.384185791015625,
          14.450060844421387,
          -2.038022756576538,
          -39.27128219604492,
          -44.9306755065918,
          -21.0069637298584,
          -30.74773406982422,
          22.41279411315918,
          -8.026365280151367,
          16.20724105834961,
          -5.660597324371338,
          -4.330458164215088,
          -19.85291290283203,
          -15.108966827392578,
          17.53296661376953,
          -45.11289978027344,
          -21.579519271850586,
          -38.61061096191406,
          9.633952140808105,
          -3.376721143722534,
          -11.09507942199707,
          -37.70743942260742,
          -0.5665685534477234,
          45.92625427246094,
          -25.032264709472656,
          -19.96971321105957,
          6.280146598815918,
          -35.3055419921875,
          15.889031410217285,
          -39.668174743652344,
          43.84886169433594,
          -13.983288764953613,
          -9.514570236206055,
          -1.6616218090057373,
          -0.9612398743629456,
          -30.56052017211914,
          37.19171905517578,
          -10.014747619628906,
          -15.947508811950684,
          0.456141859292984,
          -0.4666166305541992,
          -44.99624252319336,
          -19.804908752441406,
          -19.391483306884766,
          -39.635772705078125,
          -7.550126552581787,
          22.750539779663086,
          20.282485961914062,
          0.554419994354248,
          -40.177364349365234,
          -8.818029403686523,
          -25.935537338256836,
          -6.821070671081543,
          19.502565383911133,
          -6.9171881675720215,
          27.858430862426758,
          -24.4204044342041,
          13.073854446411133,
          -2.9087436199188232,
          -0.20298486948013306,
          -17.602127075195312,
          -18.536916732788086,
          -24.933876037597656,
          -19.352848052978516,
          -44.07961654663086,
          -43.73731231689453,
          8.381653785705566,
          -33.29409408569336,
          14.926734924316406,
          9.752442359924316,
          35.15099334716797,
          18.961315155029297,
          17.042783737182617,
          15.70490550994873,
          -38.283836364746094,
          -39.39191818237305,
          -44.153533935546875,
          -12.516847610473633,
          -41.907222747802734,
          -36.93397903442383,
          18.507841110229492,
          -30.375526428222656,
          -16.037256240844727,
          -40.83094024658203,
          8.733038902282715,
          -7.3647871017456055,
          -31.442272186279297,
          -24.81520652770996,
          -2.0280568599700928,
          -34.39393997192383,
          -34.40077209472656,
          -14.568795204162598,
          9.662178039550781,
          11.410489082336426,
          9.85910701751709,
          -38.72314453125,
          -30.259611129760742,
          -26.485811233520508,
          -40.873382568359375,
          -27.09905242919922,
          8.58825397491455,
          -43.39107894897461,
          -2.5276565551757812,
          4.945517063140869,
          -18.231204986572266,
          -34.991966247558594,
          17.88913345336914,
          19.566837310791016,
          4.954881191253662,
          -3.2780721187591553,
          -17.277921676635742,
          -29.707799911499023,
          -9.460591316223145,
          -23.21752166748047,
          -19.09053611755371,
          9.2350492477417,
          20.101118087768555,
          14.604788780212402,
          0.7524213790893555,
          -11.067919731140137,
          -8.120772361755371,
          -13.565620422363281,
          5.3268866539001465,
          30.850723266601562,
          39.952857971191406,
          4.979135036468506,
          19.355701446533203,
          -44.89900207519531,
          44.91707229614258,
          -22.083532333374023,
          -15.214247703552246,
          -30.05832290649414,
          -27.482135772705078,
          -6.075100898742676,
          17.924560546875,
          -25.699249267578125,
          -44.6847038269043,
          -34.8038444519043,
          -31.406408309936523,
          17.514986038208008,
          21.129150390625,
          26.619112014770508,
          14.503623962402344,
          -9.24873161315918,
          -23.85181999206543,
          -6.557422637939453,
          18.463857650756836,
          -35.13462829589844,
          -40.32878112792969,
          12.549560546875,
          -41.399539947509766,
          12.920236587524414,
          25.884647369384766,
          -5.962954998016357,
          16.343050003051758,
          -5.9330315589904785,
          -29.058027267456055,
          31.952991485595703,
          35.2410774230957,
          -16.141429901123047,
          -8.999528884887695,
          -37.76791763305664,
          1.1026575565338135,
          17.45246696472168,
          -28.614883422851562,
          -18.627275466918945,
          18.643457412719727,
          -33.80083465576172,
          -40.25326919555664,
          5.480541229248047,
          -10.358880996704102,
          -8.835351943969727,
          -39.19216537475586,
          -26.533166885375977,
          -43.85312271118164,
          18.86149787902832,
          0.5960416197776794,
          -44.0337028503418,
          -19.34798240661621,
          -25.436655044555664,
          37.219520568847656,
          -45.14839553833008,
          -25.0037784576416,
          -42.099449157714844,
          11.127297401428223,
          -21.67375946044922,
          -18.61003875732422,
          -43.344322204589844,
          -1.6392452716827393,
          18.46303367614746,
          18.953941345214844,
          -0.3690589368343353,
          17.25988006591797,
          -44.72088623046875,
          5.259955406188965,
          -13.107845306396484,
          1.017629623413086,
          -43.79344177246094,
          14.29973030090332,
          -43.1190185546875,
          -21.60260772705078,
          -14.031416893005371,
          19.300716400146484,
          -11.223886489868164,
          -13.07726001739502,
          -14.98763370513916,
          -26.64109992980957,
          -16.679899215698242,
          -43.289363861083984,
          4.714383602142334,
          -43.51314926147461,
          -17.835323333740234,
          -43.296390533447266,
          -0.4759913682937622,
          -10.01803207397461,
          13.451444625854492,
          6.922624111175537,
          -23.579334259033203,
          14.136308670043945,
          18.87137794494629,
          -20.55121421813965,
          -14.502812385559082,
          -45.25278854370117,
          -38.35865020751953,
          -3.034721851348877,
          11.319737434387207,
          -41.45183563232422,
          -8.123313903808594,
          -22.59519386291504,
          -40.28422546386719,
          8.456130981445312,
          -5.079128742218018,
          -27.3698673248291,
          -42.245933532714844,
          12.38808536529541,
          50.75869369506836,
          -9.729178428649902,
          -10.665614128112793,
          -39.49086380004883,
          -43.31635665893555,
          0.35917428135871887,
          2.723649501800537,
          -25.629831314086914,
          -7.580564498901367,
          41.36343765258789,
          16.496307373046875,
          -41.4277458190918,
          48.015296936035156,
          -41.92527770996094,
          9.250948905944824,
          -19.14407730102539,
          -30.45186996459961,
          -24.925569534301758,
          -43.798702239990234,
          -22.365501403808594,
          -40.031517028808594,
          -25.82796859741211,
          18.411588668823242,
          -13.991129875183105,
          10.645520210266113,
          39.39688491821289,
          -0.6856261491775513,
          18.131406784057617,
          -4.550933837890625,
          -5.647465229034424,
          -26.584318161010742,
          -22.352375030517578,
          16.46285629272461,
          -43.475440979003906,
          -26.160655975341797,
          17.893966674804688,
          -42.02303695678711,
          13.109429359436035,
          13.049137115478516,
          10.246249198913574,
          -23.594621658325195,
          -24.978721618652344,
          -24.35594367980957,
          -17.470458984375,
          8.639577865600586,
          20.57740020751953,
          3.7375526428222656,
          12.380424499511719,
          8.642594337463379,
          18.628950119018555,
          -43.6667366027832,
          -45.09989547729492,
          -17.74903106689453,
          20.006208419799805,
          17.79072380065918,
          15.259407997131348,
          -43.90680694580078,
          -11.295730590820312,
          15.062723159790039,
          -37.943260192871094,
          -29.902788162231445,
          -44.02487564086914,
          12.67625617980957,
          -13.760019302368164,
          -7.6977081298828125,
          -13.653787612915039,
          -1.3129675388336182,
          -41.64347457885742,
          19.897907257080078,
          20.5159854888916,
          -27.17365074157715,
          -5.975549697875977,
          -13.433218955993652,
          9.795516014099121,
          2.7009825706481934,
          18.521127700805664,
          9.301518440246582,
          -11.045769691467285,
          -16.44873046875,
          19.993526458740234,
          6.486088752746582,
          18.967432022094727,
          35.5078125,
          -42.21294403076172,
          -27.109642028808594,
          -31.102863311767578,
          15.757101058959961,
          6.283496379852295,
          -45.10987091064453,
          -25.46734046936035,
          20.55586051940918,
          0.4210258722305298,
          -31.892215728759766,
          -11.444742202758789,
          -32.2800178527832,
          -21.02425193786621,
          -34.4173583984375,
          -7.568177700042725,
          16.829132080078125,
          -12.628218650817871,
          -33.87884521484375,
          17.14677619934082,
          -8.430230140686035,
          20.939809799194336,
          -31.21000099182129,
          -27.03853988647461,
          19.660594940185547,
          0.2334890514612198,
          -40.926414489746094,
          17.185754776000977,
          -25.038808822631836,
          10.74750804901123,
          -21.819026947021484,
          -3.0391769409179688,
          17.318384170532227,
          -44.946353912353516,
          -18.098283767700195,
          -7.119657516479492,
          11.065252304077148,
          10.440189361572266,
          -4.885158538818359,
          10.476337432861328,
          13.396232604980469,
          -16.077198028564453,
          15.010226249694824,
          15.85671329498291,
          21.36204719543457,
          7.818861484527588,
          9.930163383483887,
          -5.630258083343506,
          20.926183700561523,
          5.787164211273193,
          6.33730411529541,
          17.625497817993164,
          -6.02711820602417,
          9.383551597595215,
          17.826574325561523,
          37.88322448730469,
          -11.843585014343262,
          5.974865436553955,
          8.590583801269531,
          -10.420003890991211,
          -32.9766845703125,
          13.784196853637695,
          -30.606101989746094,
          -4.77640438079834,
          0.3076208829879761,
          19.49988555908203,
          5.912290096282959,
          15.8558988571167,
          -24.21360206604004,
          -13.504444122314453,
          -9.7577543258667,
          17.87183952331543,
          -44.85629653930664,
          -36.682308197021484,
          -42.77009582519531,
          13.516058921813965,
          -19.861948013305664,
          -11.763492584228516,
          21.207477569580078,
          -6.18765926361084,
          1.8494104146957397,
          -14.030871391296387,
          5.217572212219238,
          10.232583999633789,
          -3.022538423538208,
          19.95473289489746,
          -44.992122650146484,
          1.1633319854736328,
          -44.229454040527344,
          19.93882179260254,
          -42.3849983215332,
          6.946078777313232,
          -25.13774299621582,
          -45.5028190612793,
          -26.94449234008789,
          21.210962295532227,
          -41.3185920715332,
          21.070358276367188,
          18.239971160888672,
          -23.67340087890625,
          -44.210304260253906,
          14.798638343811035,
          17.115026473999023,
          -44.69206619262695,
          -9.153436660766602,
          9.867666244506836,
          -27.196495056152344,
          -0.9134482741355896,
          -31.949552536010742,
          -29.52935218811035,
          5.855056285858154,
          -5.287965297698975,
          8.732807159423828,
          -23.91925621032715,
          -15.682117462158203,
          -44.163780212402344,
          16.092161178588867,
          21.094104766845703,
          1.419771432876587,
          -10.714216232299805,
          -42.47279739379883,
          -43.17680740356445,
          -11.719832420349121,
          -20.897274017333984,
          2.6284804344177246,
          13.97832202911377,
          -29.706520080566406,
          -22.494518280029297,
          8.416257858276367,
          -43.09101486206055,
          6.558800220489502,
          -13.135668754577637,
          -44.228614807128906,
          -0.43657833337783813,
          -31.606643676757812,
          -25.184799194335938,
          -8.357340812683105,
          -41.91315460205078,
          -5.189136981964111,
          14.51655387878418,
          -15.881216049194336,
          16.49640464782715,
          -40.433372497558594,
          -11.654728889465332,
          -39.86754608154297,
          -1.4106969833374023,
          9.122565269470215,
          14.775187492370605,
          -22.551729202270508,
          18.041439056396484,
          -44.58335494995117,
          12.56164264678955,
          33.962974548339844,
          16.778167724609375,
          -43.994197845458984,
          17.208209991455078,
          -12.811617851257324,
          0.6019467711448669,
          -15.114398956298828,
          -12.589716911315918,
          14.844945907592773,
          -44.46684646606445,
          8.873506546020508,
          -14.87975788116455,
          6.811683177947998,
          -36.240028381347656,
          -0.9210101962089539,
          -1.6956965923309326,
          -29.993541717529297,
          -26.50383758544922,
          13.915092468261719,
          -13.359760284423828,
          16.932090759277344,
          7.530083179473877,
          12.492939949035645,
          -9.343039512634277,
          -15.369117736816406,
          -22.91675567626953,
          -30.279714584350586,
          -26.57326316833496,
          -3.1442787647247314,
          11.338747024536133,
          -29.905649185180664,
          -14.247111320495605,
          7.494791507720947,
          -7.079194068908691,
          -25.53708267211914,
          17.377765655517578,
          -20.499357223510742,
          11.470466613769531,
          -29.683208465576172,
          15.148791313171387,
          -8.896275520324707,
          -42.89900588989258,
          -28.220129013061523,
          6.0814337730407715,
          0.015558948740363121,
          -40.76897430419922,
          -27.499540328979492,
          -22.07210350036621,
          -4.849730491638184,
          -44.6647834777832,
          18.54924201965332,
          6.232490539550781,
          -16.42134666442871,
          16.837013244628906,
          -22.89269256591797,
          -1.9398764371871948,
          -11.523530960083008,
          9.3359375,
          -34.2556037902832,
          -15.596657752990723,
          -17.264385223388672,
          -0.531842827796936,
          -30.694843292236328,
          -45.10843276977539,
          -31.047229766845703,
          4.929882526397705,
          -22.872859954833984,
          -21.043325424194336,
          20.429702758789062,
          -7.569798946380615,
          -3.2827091217041016,
          -14.920291900634766,
          -25.014385223388672,
          -29.3778018951416,
          12.972637176513672,
          -22.14422035217285,
          -22.84029769897461,
          16.771440505981445,
          15.746798515319824,
          -29.248720169067383,
          0.8015104532241821,
          -1.3938499689102173,
          22.36443328857422,
          18.2891788482666,
          20.45320701599121,
          -42.98078155517578,
          9.651175498962402,
          -31.515405654907227,
          -28.491743087768555,
          -18.729400634765625,
          17.529674530029297,
          -0.5508946776390076,
          18.088754653930664,
          19.5604305267334,
          -22.505537033081055,
          -24.504844665527344,
          -0.8500159978866577,
          18.140655517578125,
          20.109291076660156,
          -12.54705810546875,
          15.766101837158203,
          -23.25269889831543,
          -18.026321411132812,
          15.259428024291992,
          -4.22314453125,
          -28.32808494567871,
          -41.01702117919922,
          -44.76502227783203,
          -44.884212493896484,
          3.442993640899658,
          -5.511295795440674,
          11.537433624267578,
          -37.207862854003906,
          -20.786218643188477,
          15.513361930847168,
          -9.983755111694336,
          -8.297576904296875,
          11.630828857421875,
          21.19379425048828,
          -25.868640899658203,
          -44.438961029052734,
          -16.8875789642334,
          -39.0728874206543,
          1.590059518814087,
          17.74774932861328,
          -45.5356330871582,
          -31.6832275390625,
          -4.764875888824463,
          21.04723358154297,
          18.74431610107422,
          12.39432430267334,
          17.12123680114746,
          -34.05341720581055,
          17.043115615844727,
          19.53626251220703,
          -14.448827743530273,
          -9.685233116149902,
          19.515846252441406,
          20.686681747436523,
          -7.133171558380127,
          17.730012893676758,
          -12.879846572875977,
          12.461548805236816,
          14.645416259765625,
          20.635517120361328,
          14.087530136108398,
          -30.384340286254883,
          21.5159912109375,
          23.61266326904297,
          -41.81907272338867,
          -41.117313385009766,
          -33.74640655517578,
          21.692508697509766,
          -4.037600994110107,
          20.370655059814453,
          -14.544063568115234,
          18.65321922302246,
          11.24276351928711,
          19.407333374023438,
          0.10475312918424606,
          -13.001270294189453,
          -26.370258331298828,
          19.52216339111328,
          15.103771209716797,
          15.554337501525879,
          -5.312028408050537,
          -33.51158142089844,
          -17.001697540283203,
          6.460422515869141,
          -2.15840220451355,
          14.298258781433105,
          20.97422218322754,
          14.19015121459961,
          -0.9732308387756348,
          -21.88735580444336,
          21.884037017822266,
          8.372593879699707,
          13.080425262451172,
          -24.861120223999023,
          -20.019424438476562,
          -44.04291534423828,
          -36.00847625732422,
          -28.896198272705078,
          -7.7519049644470215,
          -6.540621757507324,
          -28.21112823486328,
          20.307815551757812,
          19.531719207763672,
          22.943593978881836
         ],
         "y": [
          -33.12831115722656,
          7.869945526123047,
          -3.6310155391693115,
          8.15921688079834,
          -1.8443814516067505,
          -35.58109664916992,
          8.218822479248047,
          5.187628269195557,
          -29.87061309814453,
          8.786349296569824,
          3.281350612640381,
          -32.68077087402344,
          6.183350086212158,
          7.173294544219971,
          -41.67083740234375,
          7.253289222717285,
          -40.802120208740234,
          -40.086753845214844,
          -0.559442400932312,
          -1.3108912706375122,
          -33.58606719970703,
          -34.90346145629883,
          -40.8943977355957,
          -22.4481201171875,
          41.701820373535156,
          -17.72667121887207,
          -16.743976593017578,
          -7.49009370803833,
          8.735600471496582,
          2.545872211456299,
          8.694430351257324,
          2.2268881797790527,
          -34.44069290161133,
          -34.9815788269043,
          -37.4548454284668,
          -34.753318786621094,
          38.88670349121094,
          -17.952449798583984,
          -40.779544830322266,
          -30.71967887878418,
          -39.90399169921875,
          -40.464569091796875,
          -35.131900787353516,
          -31.01151466369629,
          9.330466270446777,
          17.371328353881836,
          6.209864139556885,
          7.215008735656738,
          -27.922882080078125,
          7.982801914215088,
          7.0615458488464355,
          6.876572608947754,
          -1.9624909162521362,
          -39.076515197753906,
          7.323670864105225,
          -40.14109802246094,
          4.260157108306885,
          -8.823648452758789,
          -5.831896781921387,
          8.426783561706543,
          -7.202296733856201,
          7.65347146987915,
          -6.974741458892822,
          0.9943863749504089,
          -3.6546719074249268,
          41.79663848876953,
          9.310149192810059,
          3.014913320541382,
          28.268457412719727,
          40.258766174316406,
          -33.31494140625,
          -15.42935848236084,
          -35.628944396972656,
          9.736355781555176,
          -2.432826280593872,
          3.9640188217163086,
          9.867901802062988,
          3.1442155838012695,
          4.677338123321533,
          -37.21966552734375,
          -27.903444290161133,
          7.1226487159729,
          -5.613714218139648,
          4.240262985229492,
          33.088905334472656,
          -29.993488311767578,
          4.887671947479248,
          -5.635669231414795,
          4.8857269287109375,
          29.215763092041016,
          38.7056999206543,
          -23.62281036376953,
          -29.908184051513672,
          5.384268283843994,
          -31.245807647705078,
          6.325882911682129,
          -0.6299958229064941,
          -6.221399784088135,
          39.87600326538086,
          -32.522457122802734,
          -8.02492618560791,
          -26.43345832824707,
          -13.919143676757812,
          -20.924959182739258,
          -20.850337982177734,
          -23.976266860961914,
          3.3547863960266113,
          -10.697364807128906,
          -22.525287628173828,
          5.125740051269531,
          9.3467435836792,
          -29.992982864379883,
          2.701010227203369,
          5.864980220794678,
          -12.147308349609375,
          -2.709803819656372,
          -38.22437286376953,
          -11.60086727142334,
          -16.527084350585938,
          7.685035705566406,
          4.605922698974609,
          -33.16952896118164,
          -28.179126739501953,
          8.87906265258789,
          -37.48404312133789,
          -18.566381454467773,
          1.7734252214431763,
          4.952264308929443,
          9.30178451538086,
          -39.6325798034668,
          -6.301237106323242,
          -17.07342529296875,
          -32.2417106628418,
          -39.551734924316406,
          -30.50086212158203,
          -22.46996307373047,
          -40.24829864501953,
          -20.16004180908203,
          -32.83635711669922,
          38.151939392089844,
          -40.33073425292969,
          -36.56906509399414,
          -32.05861282348633,
          -33.35483932495117,
          -34.494224548339844,
          -23.060489654541016,
          -4.329348564147949,
          -31.465246200561523,
          7.596200942993164,
          -34.71711730957031,
          -30.96343994140625,
          -22.017658233642578,
          -33.37872314453125,
          -34.44187927246094,
          -14.493560791015625,
          -34.49007034301758,
          5.869226455688477,
          -32.79994583129883,
          1.9887737035751343,
          -35.66031265258789,
          -14.91690731048584,
          -25.121280670166016,
          2.4586069583892822,
          -22.149412155151367,
          31.58929443359375,
          7.672552585601807,
          -40.79210662841797,
          -30.563417434692383,
          -14.728365898132324,
          42.14814376831055,
          10.494965553283691,
          -10.629826545715332,
          4.004000663757324,
          4.3162055015563965,
          -29.83843421936035,
          35.67620849609375,
          -6.574198246002197,
          1.753092885017395,
          -13.696955680847168,
          3.976553201675415,
          0.4516494572162628,
          -31.22764778137207,
          -0.8270215392112732,
          -25.756284713745117,
          -11.057828903198242,
          -29.038843154907227,
          8.262136459350586,
          -16.424312591552734,
          -0.5412668585777283,
          9.5182466506958,
          -39.005741119384766,
          -17.896135330200195,
          -25.928245544433594,
          43.44056701660156,
          -37.536251068115234,
          36.49811553955078,
          6.132416725158691,
          -26.63119888305664,
          -15.88350772857666,
          -0.21739299595355988,
          -25.813480377197266,
          43.608863830566406,
          -39.43016815185547,
          -3.6398472785949707,
          -35.34321975708008,
          -2.041722297668457,
          -27.705284118652344,
          -31.95197296142578,
          -30.1472225189209,
          2.1795544624328613,
          -1.4355642795562744,
          -31.059158325195312,
          4.139832973480225,
          -30.122892379760742,
          45.0703125,
          10.979798316955566,
          -31.506343841552734,
          -38.99738693237305,
          -0.9682136178016663,
          0.9717366099357605,
          -40.51066589355469,
          -7.302575588226318,
          4.771836757659912,
          8.826406478881836,
          -9.322875022888184,
          -24.80145263671875,
          -32.15738296508789,
          -0.5591884255409241,
          10.621259689331055,
          -1.2992366552352905,
          -4.734043121337891,
          4.923435688018799,
          -30.58557891845703,
          0.30741697549819946,
          0.5106003880500793,
          -38.76042938232422,
          6.705630779266357,
          -8.513113975524902,
          -22.808549880981445,
          11.088494300842285,
          -3.003552198410034,
          39.63254165649414,
          2.1759424209594727,
          -29.34449005126953,
          -32.101898193359375,
          -35.08933639526367,
          -36.36500549316406,
          -4.053591728210449,
          -29.057741165161133,
          12.144245147705078,
          -9.769503593444824,
          9.183740615844727,
          -30.235816955566406,
          -20.766193389892578,
          -33.378013610839844,
          44.44026184082031,
          -19.838655471801758,
          -4.8608832359313965,
          -2.4260146617889404,
          -40.388885498046875,
          -26.2763671875,
          -31.53902244567871,
          -31.163881301879883,
          5.234180927276611,
          1.0431404113769531,
          -31.352458953857422,
          43.51112747192383,
          4.691744327545166,
          8.9653902053833,
          -14.569310188293457,
          -19.33724021911621,
          35.52529525756836,
          -35.914554595947266,
          39.755496978759766,
          -30.69721031188965,
          -21.24717903137207,
          -34.042118072509766,
          -26.088769912719727,
          -33.516746520996094,
          7.791271686553955,
          0.30085644125938416,
          -38.331031799316406,
          -3.4737093448638916,
          -22.549928665161133,
          -34.09450912475586,
          -32.40176773071289,
          -12.887929916381836,
          11.687766075134277,
          -1.6872318983078003,
          -37.021583557128906,
          -30.639026641845703,
          -26.763113021850586,
          5.439530849456787,
          -23.752187728881836,
          -28.596773147583008,
          0.6151644587516785,
          5.4759297370910645,
          -15.384320259094238,
          -8.655355453491211,
          37.72368621826172,
          -13.702985763549805,
          -32.33882522583008,
          -22.067941665649414,
          -33.719505310058594,
          -40.766841888427734,
          30.10606575012207,
          -12.792960166931152,
          -8.175710678100586,
          -1.1888850927352905,
          -14.708780288696289,
          -18.879440307617188,
          -40.86570358276367,
          -40.58536911010742,
          -31.441999435424805,
          -31.075342178344727,
          4.403141498565674,
          25.424758911132812,
          36.37108612060547,
          -32.8704948425293,
          11.193658828735352,
          6.743927955627441,
          -8.264362335205078,
          -32.9790153503418,
          9.129402160644531,
          -32.01045227050781,
          -27.13006591796875,
          -33.43100357055664,
          0.20935307443141937,
          -37.76686477661133,
          7.273685455322266,
          -28.626632690429688,
          1.103835105895996,
          -32.75719451904297,
          2.2146549224853516,
          -23.125492095947266,
          3.6411185264587402,
          -5.777048587799072,
          -30.831605911254883,
          -34.126792907714844,
          37.170223236083984,
          -31.340686798095703,
          9.548480987548828,
          -6.752622127532959,
          -25.92543601989746,
          -3.2177693843841553,
          25.396665573120117,
          44.51361083984375,
          -41.025699615478516,
          -5.8383989334106445,
          -35.33387756347656,
          3.6649303436279297,
          -1.6997296810150146,
          -29.650545120239258,
          -20.916114807128906,
          -40.69331359863281,
          -20.0629940032959,
          44.621822357177734,
          -10.00875473022461,
          40.95582962036133,
          -34.84711456298828,
          -25.235319137573242,
          2.076993942260742,
          -39.99577331542969,
          -1.101049542427063,
          9.253302574157715,
          -14.78013801574707,
          -9.915229797363281,
          -7.74916934967041,
          -26.32911491394043,
          8.512578964233398,
          1.2470306158065796,
          24.039836883544922,
          -35.14580535888672,
          1.8799058198928833,
          -0.12784552574157715,
          4.530543804168701,
          -39.65397262573242,
          -41.003662109375,
          -23.501235961914062,
          1.992154836654663,
          -35.217430114746094,
          -40.41777420043945,
          0.8882838487625122,
          -30.549610137939453,
          -0.9577689170837402,
          -39.40608596801758,
          -15.363167762756348,
          -20.6381893157959,
          -39.76456069946289,
          -19.81739616394043,
          -34.31296920776367,
          1.060219645500183,
          -27.179519653320312,
          23.50956153869629,
          -10.59434700012207,
          44.022865295410156,
          -30.624160766601562,
          -40.2369499206543,
          43.602935791015625,
          -29.18670654296875,
          -29.582122802734375,
          -34.17597961425781,
          -34.87565994262695,
          -40.13382339477539,
          -23.61085319519043,
          -33.82904052734375,
          -32.77568435668945,
          -27.521526336669922,
          -8.31347942352295,
          -23.09333038330078,
          -40.64056396484375,
          -7.123566150665283,
          38.960350036621094,
          -30.427753448486328,
          44.885250091552734,
          1.0705407857894897,
          -30.914661407470703,
          -12.398171424865723,
          0.11912032216787338,
          5.763051509857178,
          6.287104606628418,
          2.0856473445892334,
          -34.5766716003418,
          -29.858102798461914,
          -30.88711166381836,
          13.1961088180542,
          -34.82210922241211,
          45.203125,
          -38.19404220581055,
          -36.406978607177734,
          12.116202354431152,
          40.499351501464844,
          -1.5693691968917847,
          -34.41249084472656,
          0.8703256845474243,
          -38.69404983520508,
          -37.16267395019531,
          -2.5111753940582275,
          -34.82204055786133,
          1.66825270652771,
          -27.730337142944336,
          -10.649391174316406,
          0.02899092249572277,
          43.43321990966797,
          -39.882999420166016,
          5.187976837158203,
          -39.353729248046875,
          2.229701042175293,
          14.834029197692871,
          38.308231353759766,
          -24.09600257873535,
          3.6106982231140137,
          39.41963195800781,
          -0.6711186766624451,
          6.545965194702148,
          -40.79173278808594,
          -31.592729568481445,
          32.68438720703125,
          6.286826133728027,
          9.390873908996582,
          -40.583641052246094,
          9.796289443969727,
          8.775315284729004,
          11.073633193969727,
          -21.83033561706543,
          8.40487289428711,
          -31.900798797607422,
          43.98192596435547,
          -37.228824615478516,
          -23.638999938964844,
          6.809541702270508,
          8.40611457824707,
          -36.287418365478516,
          31.654077529907227,
          -30.691089630126953,
          -28.358049392700195,
          44.9619255065918,
          -40.71377944946289,
          -39.030029296875,
          28.204832077026367,
          9.22449016571045,
          10.76364803314209,
          -33.60463333129883,
          -13.783353805541992,
          -35.33332443237305,
          33.007381439208984,
          -18.719768524169922,
          -15.75456428527832,
          33.73612976074219,
          4.687764644622803,
          40.105201721191406,
          -21.515735626220703,
          -34.77550506591797,
          22.538877487182617,
          1.6316827535629272,
          -35.0218391418457,
          -16.7894287109375,
          -33.93577575683594,
          8.433095932006836,
          4.851951599121094,
          -8.999268531799316,
          -40.00032043457031,
          9.001017570495605,
          42.7149658203125,
          -34.699249267578125,
          -23.536468505859375,
          -31.11762046813965,
          14.86684799194336,
          -13.766603469848633,
          42.78776550292969,
          -34.51744842529297,
          10.326637268066406,
          -19.134021759033203,
          8.412702560424805,
          -21.310543060302734,
          -33.46507263183594,
          -0.3937689960002899,
          -30.488513946533203,
          -30.48023796081543,
          -30.549161911010742,
          -37.670555114746094,
          -16.19743537902832,
          -29.351228713989258,
          27.13006019592285,
          9.084980010986328,
          -23.854053497314453,
          0.24385932087898254,
          -18.360824584960938,
          3.6218526363372803,
          -33.9805908203125,
          -37.77348709106445,
          21.787057876586914,
          -35.711700439453125,
          -22.49703025817871,
          5.770335674285889,
          -40.77430725097656,
          -10.449002265930176,
          0.6206251978874207,
          19.528270721435547,
          21.109954833984375,
          4.089503288269043,
          0.06871465593576431,
          -32.76943588256836,
          44.44846725463867,
          -35.457847595214844,
          -0.19533531367778778,
          10.416714668273926,
          -36.25125503540039,
          -29.835247039794922,
          -33.236446380615234,
          -1.0847586393356323,
          -5.395441055297852,
          5.748064994812012,
          -12.276147842407227,
          0.7421899437904358,
          39.53960037231445,
          -30.584726333618164,
          8.031646728515625,
          23.29692268371582,
          -33.31060791015625,
          -32.30406188964844,
          -25.49827766418457,
          -32.23303985595703,
          -33.84843444824219,
          -34.54435729980469,
          -30.462787628173828,
          -32.24301528930664,
          44.97755432128906,
          -31.215225219726562,
          -31.462223052978516,
          -35.65493392944336,
          41.0281867980957,
          -11.433588027954102,
          -12.325011253356934,
          -30.402774810791016,
          -34.47761917114258,
          10.876172065734863,
          44.691810607910156,
          -20.257017135620117,
          -38.617740631103516,
          44.09782028198242,
          -35.99168014526367,
          -39.86296463012695,
          -39.204586029052734,
          6.342217922210693,
          -30.96868133544922,
          11.180076599121094,
          39.22784423828125,
          17.785804748535156,
          18.77606201171875,
          -1.7120145559310913,
          44.87922286987305,
          24.316083908081055,
          30.19500160217285,
          7.0841217041015625,
          -17.530330657958984,
          7.175492286682129,
          -35.25674057006836,
          44.46711730957031,
          15.198389053344727,
          0.9785419702529907,
          -34.65866470336914,
          -15.654473304748535,
          -21.503009796142578,
          37.20069885253906,
          43.736576080322266,
          -14.276220321655273,
          -40.837337493896484,
          -30.03166389465332,
          -17.482351303100586,
          -38.747642517089844,
          -14.939332008361816,
          2.2972168922424316,
          -40.364112854003906,
          -39.90460205078125,
          35.12470626831055,
          17.740360260009766,
          43.946510314941406,
          0.9339357614517212,
          -34.50063705444336,
          -29.955249786376953,
          29.875770568847656,
          -33.30046463012695,
          -35.610591888427734,
          11.868780136108398,
          4.06207799911499,
          -30.864944458007812,
          10.17807388305664,
          41.11922836303711,
          13.961405754089355,
          10.22104549407959,
          4.641188144683838,
          43.74953079223633,
          0.06845276057720184,
          -33.933658599853516,
          4.83344030380249,
          15.871175765991211,
          -19.646055221557617,
          -33.99214553833008,
          -30.57071304321289,
          -34.173484802246094,
          44.393829345703125,
          0.9272343516349792,
          37.81975173950195,
          -23.29833984375,
          -20.057865142822266,
          9.165406227111816,
          -31.21268081665039,
          -28.250951766967773,
          -15.938272476196289,
          -31.007474899291992,
          10.367719650268555,
          -34.750648498535156,
          -17.161874771118164,
          -14.509572982788086,
          -0.4382530152797699,
          -10.472684860229492,
          -32.935672760009766,
          7.547877311706543,
          20.184736251831055,
          -4.3891825675964355,
          -24.396265029907227,
          -36.27071762084961,
          7.848743915557861,
          -34.586605072021484,
          39.44050216674805,
          41.394569396972656,
          21.726158142089844,
          6.3585004806518555,
          7.2734055519104,
          12.74968433380127,
          16.869779586791992,
          6.050083160400391,
          39.90937423706055,
          -13.627299308776855,
          -31.84807777404785,
          3.877128839492798,
          -7.353611469268799,
          30.462629318237305,
          -32.47640609741211,
          2.4226527214050293,
          -8.17978286743164,
          -31.0224609375,
          22.179737091064453,
          9.97568130493164,
          -30.486772537231445,
          5.3139166831970215,
          -40.32297897338867,
          2.9992148876190186,
          -5.073997974395752,
          5.871679782867432,
          36.90290832519531,
          45.133724212646484,
          -36.706298828125,
          -35.6854362487793,
          -29.988723754882812,
          -38.133819580078125,
          40.82149887084961,
          -30.157785415649414,
          8.187850952148438,
          16.700727462768555,
          43.779685974121094,
          -20.050416946411133,
          -41.27682876586914,
          -40.41267395019531,
          -31.29070281982422,
          -33.04988479614258,
          -30.28247833251953,
          4.601604461669922,
          43.39491271972656,
          -35.76314926147461,
          -35.032142639160156,
          -20.404680252075195,
          -34.40256118774414,
          13.7391996383667,
          43.02241134643555,
          10.539095878601074,
          4.933994293212891,
          -15.918866157531738,
          -10.920738220214844,
          9.450384140014648,
          -0.009077871218323708,
          17.12655258178711,
          -29.315513610839844,
          1.2275938987731934,
          -40.9776725769043,
          -31.855253219604492,
          10.853124618530273,
          -35.308143615722656,
          3.390454053878784,
          -32.05645751953125,
          -2.546712636947632,
          40.630374908447266,
          -28.747711181640625,
          2.970672607421875,
          -27.076745986938477,
          12.776606559753418,
          7.98179292678833,
          6.623579025268555,
          -39.92905044555664,
          -34.84109878540039,
          -40.72203826904297,
          3.203857183456421,
          -30.64319610595703,
          -28.048049926757812,
          -39.8963737487793,
          2.245539903640747,
          8.170044898986816,
          -31.44611358642578,
          0.7017551064491272,
          -40.500736236572266,
          3.888777017593384,
          -10.632026672363281,
          43.56275939941406,
          -36.426998138427734,
          43.155216217041016,
          -10.639376640319824,
          13.158880233764648,
          -40.69133758544922,
          -21.652877807617188,
          -35.5728759765625,
          23.335325241088867,
          -31.3570613861084,
          -38.942413330078125,
          38.85591125488281,
          4.851182460784912,
          18.10222625732422,
          42.835182189941406,
          -30.713685989379883,
          -34.504398345947266,
          43.08218002319336,
          44.677452087402344,
          2.6080141067504883,
          42.006797790527344,
          -31.889789581298828,
          9.722946166992188,
          44.427425384521484,
          -16.365068435668945,
          43.226680755615234,
          32.86604690551758,
          29.84832000732422,
          0.1698116511106491,
          -34.93386459350586,
          27.060834884643555,
          40.17095947265625,
          -33.444618225097656,
          -34.779022216796875,
          40.9102897644043,
          44.76377868652344,
          -38.206153869628906,
          5.309015274047852,
          -38.69845962524414,
          43.42827224731445,
          -40.629878997802734,
          3.408647060394287,
          6.302537441253662,
          44.367515563964844,
          40.714508056640625,
          43.093589782714844,
          3.607576370239258,
          -39.34055709838867,
          0.5063285827636719,
          -34.893802642822266,
          5.687730312347412,
          20.151477813720703,
          25.291934967041016,
          -15.123458862304688,
          -0.21619023382663727,
          -34.03099822998047,
          23.289308547973633,
          -17.126441955566406,
          -1.8648145198822021,
          37.82691955566406,
          -0.1731289178133011,
          11.11225414276123,
          -0.5188626646995544,
          10.278884887695312,
          -32.80806350708008,
          10.462933540344238,
          -0.49726107716560364,
          -0.11138251423835754,
          -35.10027313232422,
          43.361820220947266,
          5.598185062408447,
          6.479384899139404,
          -35.11697769165039,
          1.6268900632858276,
          17.640169143676758,
          11.113688468933105,
          -5.703242301940918,
          11.831011772155762,
          19.809555053710938,
          4.674076557159424,
          1.0769954919815063,
          -16.624053955078125,
          43.484806060791016,
          2.9204206466674805,
          44.5334358215332,
          -29.100740432739258,
          4.8872880935668945,
          10.420493125915527,
          -0.046293437480926514,
          2.4880216121673584,
          19.19827651977539,
          -1.4772191047668457,
          1.4127038717269897,
          -5.947048664093018,
          -30.77311134338379,
          -34.87432098388672,
          9.23347282409668,
          32.87580490112305,
          -9.49622917175293,
          1.4340765476226807,
          -36.28541564941406,
          0.587744414806366,
          45.18001174926758,
          8.775160789489746,
          0.875965416431427,
          41.92326354980469,
          -1.3750003576278687,
          44.10572814941406,
          -34.29334259033203,
          -21.8658504486084,
          -18.292770385742188,
          -12.804588317871094,
          37.795799255371094,
          35.18677520751953,
          5.182344436645508,
          0.9276803731918335,
          10.563329696655273,
          43.71207809448242,
          11.033463478088379,
          10.10285758972168,
          9.75313949584961,
          -32.26200866699219,
          1.5302804708480835,
          36.277305603027344,
          1.3889126777648926,
          -31.40410041809082,
          -17.062280654907227,
          -31.95269775390625,
          35.993106842041016,
          2.9931631088256836,
          -20.608964920043945,
          0.5570632815361023,
          37.89686584472656,
          -33.78829574584961,
          -40.19661331176758,
          -4.897038459777832,
          -25.97425651550293,
          -36.13474655151367,
          5.407493591308594,
          -38.78129959106445,
          36.888004302978516,
          -21.189565658569336,
          10.631747245788574,
          -30.638626098632812,
          -34.09159851074219,
          43.443084716796875,
          24.53634262084961,
          44.19801712036133,
          -39.21659851074219,
          -36.38126754760742,
          42.2622184753418,
          39.03978729248047,
          -21.411916732788086,
          3.031578540802002,
          -23.226360321044922,
          -22.090673446655273,
          -33.62386703491211,
          -39.52299499511719,
          27.71925163269043,
          6.944169521331787,
          -9.195674896240234,
          40.98883056640625,
          -16.58045196533203,
          2.6592366695404053,
          -34.655609130859375,
          10.124510765075684,
          5.204504013061523,
          2.01415753364563,
          9.472160339355469,
          -34.926849365234375,
          6.964870452880859,
          4.457122325897217,
          -3.7530434131622314,
          7.623987197875977,
          6.135995864868164,
          9.127702713012695,
          10.418622016906738,
          -5.8689069747924805,
          43.82410430908203,
          -30.7438907623291,
          -36.67660140991211,
          -21.938751220703125,
          -27.124584197998047,
          39.26599884033203,
          43.314598083496094,
          -28.74489402770996,
          -35.47492218017578,
          10.66862964630127,
          -0.5108203291893005,
          7.622090816497803,
          8.94613265991211,
          2.6157925128936768,
          -38.29966735839844,
          -34.57343292236328,
          -38.06013488769531,
          41.110984802246094,
          41.82746505737305,
          -26.26349449157715,
          -36.579044342041016,
          28.013927459716797,
          2.7638723850250244,
          -15.691141128540039,
          44.095619201660156,
          37.69118881225586,
          29.103225708007812,
          37.66860580444336,
          0.799072265625,
          37.81196975708008,
          7.860804557800293,
          14.800028800964355,
          14.721138954162598,
          -0.24456091225147247,
          11.304624557495117,
          43.9578742980957,
          -11.7001371383667,
          -25.029212951660156,
          -33.54534912109375,
          -28.033361434936523,
          -34.63722229003906,
          0.9330956935882568,
          5.631369113922119,
          23.916240692138672,
          -27.319347381591797,
          -26.815298080444336,
          -6.921142578125,
          10.354363441467285,
          11.159503936767578,
          9.923518180847168,
          -0.7789505124092102,
          43.525726318359375,
          -8.311349868774414,
          10.853653907775879,
          -33.252052307128906,
          -33.50251388549805,
          -40.0710334777832,
          -31.071992874145508,
          -31.788827896118164,
          -11.114706993103027,
          -15.347272872924805,
          -35.9210319519043,
          -9.027315139770508,
          -24.111093521118164,
          -31.783863067626953,
          21.28125,
          29.79623031616211,
          1.932051181793213,
          43.040348052978516,
          2.955298900604248,
          40.88584518432617,
          22.27977180480957,
          -32.659385681152344,
          -35.62507629394531,
          9.274394035339355,
          -6.12864875793457,
          39.85296630859375,
          0.21255947649478912,
          1.0012089014053345,
          1.4524013996124268,
          -14.411785125732422,
          4.262362480163574,
          -40.88525390625,
          20.43120574951172,
          -33.781620025634766,
          43.0239372253418,
          -35.43095397949219,
          41.96367263793945,
          24.588579177856445,
          9.544937133789062,
          8.857181549072266,
          40.94550704956055,
          3.3992161750793457,
          -28.273548126220703,
          2.0963611602783203,
          -4.430069446563721,
          -32.712059020996094,
          22.65742301940918,
          39.85689163208008,
          8.565155029296875,
          24.713653564453125,
          -32.05939865112305,
          8.02949333190918,
          4.208088397979736,
          -33.818519592285156,
          2.4387032985687256,
          -1.8587679862976074,
          7.128547668457031,
          43.248329162597656,
          -29.657859802246094,
          4.112732410430908,
          23.530567169189453,
          -0.9193270206451416,
          -1.3913984298706055,
          10.411419868469238,
          41.7162971496582,
          -35.740684509277344,
          0.9674216508865356,
          -30.186311721801758,
          -41.02033615112305,
          4.511523723602295,
          -20.798686981201172,
          1.0975244045257568,
          9.827253341674805,
          41.07103729248047,
          8.81396484375,
          -7.262190341949463,
          -1.9859528541564941,
          9.335165023803711,
          7.7665534019470215,
          41.85513687133789,
          7.486311435699463,
          -33.72877502441406,
          7.462303638458252,
          34.27928924560547,
          5.959390640258789,
          -31.054262161254883,
          35.919219970703125,
          33.027652740478516,
          -33.982208251953125,
          -38.82954406738281,
          5.782203674316406,
          -6.555339336395264,
          3.2182223796844482,
          43.412235260009766,
          6.144183158874512,
          -33.32183837890625,
          -39.2863883972168,
          -40.867645263671875,
          8.940827369689941,
          0.5901756286621094,
          37.13064956665039,
          37.785865783691406,
          3.0443482398986816,
          -36.43294906616211,
          22.406309127807617,
          32.43133544921875,
          5.061739921569824,
          -0.5944685935974121,
          -31.084774017333984,
          -0.3166491687297821,
          -7.324386119842529,
          -38.79386520385742,
          0.2635042369365692,
          5.544525146484375,
          -10.892410278320312,
          9.698770523071289,
          -32.37153625488281,
          -41.254478454589844,
          43.3405876159668,
          10.515369415283203,
          43.583717346191406,
          43.495548248291016,
          10.554978370666504,
          6.0626444816589355,
          11.645597457885742,
          -8.187688827514648,
          11.725113868713379,
          7.017856121063232,
          36.88352966308594,
          1.4735698699951172,
          -33.385765075683594,
          7.346088886260986,
          43.77352523803711,
          -17.05097770690918,
          10.695549011230469,
          9.199734687805176,
          -32.75877380371094,
          8.66759967803955,
          33.25471878051758,
          -25.43761444091797,
          -20.515052795410156,
          -33.570247650146484,
          4.186162948608398,
          41.9300537109375,
          0.8067572116851807,
          -32.67643737792969,
          -32.003883361816406,
          3.7146592140197754,
          44.72907638549805,
          44.058834075927734,
          41.986942291259766,
          -5.960935115814209,
          44.149139404296875,
          9.943158149719238,
          4.187535762786865,
          45.12186050415039,
          14.975228309631348,
          20.603557586669922,
          -30.900184631347656,
          -24.477310180664062,
          4.613275051116943,
          43.301788330078125,
          44.3489990234375,
          22.802453994750977,
          43.9240608215332,
          -39.46452331542969,
          9.673657417297363,
          4.410528659820557,
          -30.641857147216797,
          43.103397369384766,
          44.64320755004883,
          8.17988395690918,
          -34.51841354370117,
          45.15476608276367,
          -14.465526580810547,
          0.18160982429981232,
          39.21603775024414,
          10.129018783569336,
          29.725257873535156,
          -35.499427795410156,
          -33.986473083496094,
          11.702179908752441,
          32.453857421875,
          6.404319763183594,
          -26.451980590820312,
          5.3985772132873535,
          -3.9110829830169678,
          5.664684772491455,
          -22.827573776245117,
          -27.082904815673828,
          23.95769691467285,
          10.39339828491211,
          7.22318172454834,
          -22.18163299560547,
          1.3023889064788818,
          43.44192886352539,
          43.21511459350586,
          43.97187805175781,
          1.6031488180160522,
          -29.053993225097656,
          -29.651168823242188,
          -34.880855560302734,
          -35.74665832519531,
          -36.404937744140625,
          35.99062728881836,
          -26.596097946166992,
          -32.586429595947266,
          -33.72909927368164,
          -25.157155990600586,
          43.157623291015625,
          0.5267012119293213,
          -14.619194984436035,
          42.432308197021484,
          1.2092794179916382,
          -34.790592193603516,
          8.18315315246582,
          23.742238998413086,
          24.524192810058594,
          -1.2058522701263428,
          1.2198141813278198,
          -34.42348861694336,
          10.469108581542969,
          45.40556716918945,
          -34.90065002441406,
          -35.15186309814453,
          2.81296968460083,
          14.39470100402832,
          33.54283905029297,
          -0.17732490599155426,
          -32.93849182128906,
          2.4389758110046387,
          7.212474346160889,
          -0.057417821139097214,
          -37.70621109008789,
          -27.954971313476562,
          41.61433410644531,
          22.295106887817383,
          -12.444784164428711,
          -18.961959838867188,
          10.659340858459473,
          -34.03470993041992,
          43.3066291809082,
          43.67373275756836,
          2.911703586578369,
          13.905437469482422,
          10.250945091247559,
          -4.172916412353516,
          -29.89045524597168,
          -32.01114273071289,
          30.59877586364746,
          15.736227989196777,
          -39.82087326049805,
          34.017581939697266,
          43.17327117919922,
          43.89402389526367,
          2.8027660846710205,
          21.41427230834961,
          7.8808441162109375,
          -23.07133674621582,
          -37.49154281616211,
          3.885465621948242,
          34.582374572753906,
          -40.24678039550781,
          -31.334354400634766,
          30.798267364501953,
          44.317508697509766,
          9.54261302947998,
          -37.1651725769043,
          -34.175594329833984,
          9.035470008850098,
          42.33184051513672,
          -27.05078125,
          -29.870059967041016,
          13.181361198425293,
          43.34507751464844,
          43.229148864746094,
          11.194314956665039,
          -30.324691772460938,
          -22.19781494140625,
          40.480167388916016,
          44.00894546508789,
          -32.432960510253906,
          -26.45594024658203,
          -34.1380500793457,
          -15.446172714233398,
          13.442768096923828,
          -30.3250675201416,
          -11.953404426574707,
          44.53459548950195,
          11.950901985168457,
          -31.98577117919922,
          -3.502626895904541,
          43.6891975402832,
          -19.001081466674805,
          34.32624053955078,
          45.04793930053711,
          44.82270431518555,
          -3.247087001800537,
          43.548622131347656,
          26.810771942138672,
          12.621891021728516,
          42.7507209777832,
          10.025623321533203,
          -13.143661499023438,
          -0.638878583908081,
          6.67576789855957,
          -30.9327335357666,
          -14.174806594848633,
          -38.52277374267578,
          -15.351194381713867,
          43.82520294189453,
          45.28901290893555,
          -40.62965774536133,
          5.709776401519775,
          7.149698734283447,
          45.506736755371094,
          44.39179992675781,
          45.163143157958984,
          1.1274046897888184,
          -31.750064849853516,
          -4.697388172149658,
          -34.39649963378906,
          -20.178512573242188,
          -30.7707462310791,
          5.899537086486816,
          34.85562515258789,
          36.71001434326172,
          9.830671310424805,
          31.55860137939453,
          12.298948287963867,
          10.60644817352295,
          44.71753692626953,
          -11.739526748657227,
          -24.830039978027344,
          41.38677215576172,
          -36.475318908691406,
          2.729034423828125,
          -32.13258361816406,
          11.84610652923584,
          5.270270347595215,
          -34.28001022338867,
          -31.37517547607422,
          43.46819305419922,
          -21.567222595214844,
          5.990306854248047,
          -7.241334915161133,
          42.328495025634766,
          43.896480560302734,
          -23.263399124145508,
          -15.344701766967773,
          43.95625686645508,
          -31.088485717773438,
          43.749149322509766,
          -31.497516632080078,
          -25.420942306518555,
          -39.707584381103516,
          -24.294418334960938,
          -13.002409934997559,
          1.0371216535568237,
          -0.25870266556739807,
          8.879983901977539,
          -33.51250457763672,
          43.84945297241211,
          -7.08658504486084,
          11.089203834533691,
          2.9430487155914307,
          44.06598663330078,
          22.091588973999023,
          43.97321701049805,
          2.583434820175171,
          -28.545982360839844,
          -0.9441036581993103,
          28.74520492553711,
          44.451168060302734,
          42.72996520996094,
          43.378055572509766,
          44.608394622802734,
          29.409774780273438,
          -2.8159704208374023,
          -34.684303283691406,
          8.48585319519043,
          -21.946205139160156,
          32.03241729736328,
          36.24755859375,
          3.495985746383667,
          44.618324279785156,
          12.085854530334473,
          -35.56576919555664,
          8.444225311279297,
          2.0129330158233643,
          18.971906661987305,
          0.140264093875885,
          2.45635986328125,
          -33.98261260986328,
          27.011789321899414,
          -13.212385177612305,
          -12.868597984313965,
          43.30006408691406,
          7.733821868896484,
          12.232925415039062,
          33.351200103759766,
          -1.4587305784225464,
          43.61347579956055,
          33.706329345703125,
          -26.122148513793945,
          -32.31208801269531,
          -12.195649147033691,
          35.583030700683594,
          -34.21607971191406,
          42.997650146484375,
          -34.629005432128906,
          0.05222223699092865,
          4.4298906326293945,
          26.430326461791992,
          12.784832000732422,
          44.008033752441406,
          42.33313751220703,
          6.336674690246582,
          0.4142763316631317,
          39.94388961791992,
          7.872644901275635,
          35.4999885559082,
          3.3393218517303467,
          43.81103515625,
          15.384912490844727,
          -0.10146117955446243,
          28.824447631835938,
          -33.65433883666992,
          0.3181512653827667,
          -33.82635498046875,
          9.482635498046875,
          31.966449737548828,
          1.0402593612670898,
          -2.674147844314575,
          -35.27312469482422,
          16.115942001342773,
          0.6638165712356567,
          9.762998580932617,
          5.117784023284912,
          -31.305097579956055,
          9.835041999816895,
          -30.44308853149414,
          45.37726974487305,
          30.73505973815918,
          44.40037536621094,
          -29.900556564331055,
          30.158321380615234,
          45.04133605957031,
          11.381577491760254,
          43.444969177246094,
          43.59313201904297,
          15.642539978027344,
          -0.07920700311660767,
          -22.407455444335938,
          27.974000930786133,
          9.390153884887695,
          -36.04664993286133,
          43.67211151123047,
          -0.6440739631652832,
          12.034648895263672,
          -15.878884315490723,
          44.86240005493164,
          -32.0479850769043,
          -35.47968673706055,
          37.7783203125,
          2.8564646244049072,
          34.8016471862793,
          1.604198694229126,
          -34.12983703613281,
          31.24631118774414,
          10.277219772338867,
          13.38049602508545,
          1.5447049140930176,
          2.5450525283813477,
          1.9995194673538208,
          10.211824417114258,
          38.6855583190918,
          0.3288806080818176,
          5.247527599334717,
          -31.541156768798828,
          36.31634521484375,
          28.003751754760742,
          -30.91596221923828,
          45.409637451171875,
          -32.45102310180664,
          37.625892639160156,
          3.747159481048584,
          9.036188125610352,
          34.26152420043945,
          43.521114349365234,
          1.8730032444000244,
          42.235252380371094,
          17.488557815551758,
          1.0941503047943115,
          4.622050762176514,
          10.358793258666992,
          -33.47107696533203,
          43.10625457763672,
          4.452328205108643,
          -8.749114990234375,
          6.784658432006836,
          -19.72176170349121,
          2.606203556060791,
          45.18486404418945,
          3.3551130294799805,
          25.18328857421875,
          43.72806167602539,
          42.13071823120117,
          43.73820877075195,
          40.086524963378906,
          -35.67435836791992,
          43.748355865478516,
          26.11355972290039,
          -13.342933654785156,
          -30.82305335998535,
          -2.2526073455810547,
          16.662771224975586,
          1.9803078174591064,
          -33.093017578125,
          43.9881706237793,
          -6.993872165679932,
          -34.50326919555664,
          -41.037559509277344,
          -20.641437530517578,
          12.705281257629395,
          5.9526896476745605,
          44.725425720214844,
          -4.733796119689941,
          3.746711254119873,
          4.127954006195068,
          -3.0585103034973145,
          4.168481826782227,
          2.0810866355895996,
          10.772525787353516,
          41.45841979980469,
          9.972848892211914,
          -32.60572052001953,
          -1.3966646194458008,
          0.7216423153877258,
          37.277992248535156,
          44.520172119140625,
          43.81294631958008,
          -6.626922130584717,
          27.741680145263672,
          19.99184799194336,
          0.5182114839553833,
          44.88422393798828,
          -20.113500595092773,
          -0.6181600093841553,
          44.483253479003906,
          -34.997779846191406,
          39.78997039794922,
          6.718947410583496,
          43.402645111083984,
          10.268911361694336,
          38.47675704956055,
          -1.1497702598571777,
          39.048866271972656,
          44.23870086669922,
          -0.8059696555137634,
          40.97300720214844,
          43.16730880737305,
          10.879237174987793,
          43.470123291015625,
          -23.836917877197266,
          1.3985450267791748,
          -39.02779769897461,
          44.705623626708984,
          7.9640913009643555,
          3.807053327560425,
          4.3531494140625,
          -22.781139373779297,
          41.27427291870117,
          39.70502853393555,
          30.236509323120117,
          44.30610275268555,
          22.51058578491211,
          -11.982684135437012,
          36.23883819580078,
          -35.24985122680664,
          6.305141448974609,
          -16.172094345092773,
          27.02723503112793,
          6.834437847137451,
          -0.13148115575313568,
          8.472857475280762,
          43.475791931152344,
          31.489608764648438,
          -14.875535011291504,
          -0.6328963041305542,
          43.55823516845703,
          37.701297760009766,
          7.657124996185303,
          -1.2828447818756104,
          0.21223214268684387,
          43.240299224853516,
          44.0215950012207,
          34.425296783447266,
          43.971099853515625,
          24.843555450439453,
          38.970760345458984,
          34.1335563659668,
          44.04927444458008,
          -34.697532653808594,
          43.461666107177734,
          43.38884353637695,
          43.66345977783203,
          2.508068323135376,
          0.22277233004570007,
          -33.074581146240234,
          -34.14754104614258,
          0.5650771856307983,
          44.03159713745117,
          -34.771240234375,
          29.613710403442383,
          9.300347328186035,
          2.168569326400757,
          43.155975341796875,
          30.527008056640625,
          42.389503479003906,
          -0.18437559902668,
          43.53094482421875,
          -0.7507842183113098,
          41.054718017578125,
          5.320736408233643,
          43.89128112792969,
          9.210844993591309,
          -31.122928619384766,
          -1.9227097034454346,
          -40.469459533691406,
          1.0963108539581299,
          8.227791786193848,
          32.95111083984375,
          44.54106903076172,
          42.45025634765625,
          5.824979782104492,
          38.2004280090332,
          9.700601577758789,
          6.790329933166504,
          8.440767288208008,
          40.2295036315918,
          10.215520858764648,
          -6.760919570922852,
          43.16157150268555,
          40.19002914428711,
          43.769439697265625,
          10.431953430175781,
          14.120931625366211,
          44.524173736572266,
          43.04639434814453,
          7.811059951782227,
          -33.7668342590332,
          43.37726593017578,
          6.275879859924316,
          44.610748291015625,
          10.412785530090332,
          29.15576934814453,
          6.012105464935303,
          43.39461898803711,
          43.084781646728516,
          42.970481872558594,
          16.474870681762695,
          8.216739654541016,
          24.134143829345703,
          0.22719433903694153,
          1.9131935834884644,
          43.18498992919922,
          9.856181144714355,
          45.40833282470703,
          27.59637451171875,
          -0.261107861995697,
          25.134767532348633,
          8.879096984863281,
          -34.126808166503906,
          11.92119026184082,
          1.7158071994781494,
          16.25221061706543,
          19.726486206054688,
          44.58101272583008,
          6.4955244064331055,
          43.939292907714844,
          45.422027587890625,
          8.846680641174316,
          -31.124624252319336,
          43.37514877319336,
          -24.82843780517578,
          -10.950554847717285,
          -9.201958656311035,
          40.02009963989258,
          1.9417030811309814,
          35.08503723144531,
          6.49416446685791,
          44.025360107421875,
          32.33343505859375,
          44.1330451965332,
          -31.9559383392334,
          3.0997226238250732,
          18.5616512298584,
          10.77120304107666,
          -15.21908187866211,
          7.675178050994873,
          -24.89786148071289,
          -30.345129013061523,
          7.31566047668457,
          -13.80162239074707,
          43.166934967041016,
          1.985012412071228,
          21.53501319885254,
          14.984646797180176,
          1.7308855056762695,
          9.009671211242676,
          -30.435895919799805,
          28.848417282104492,
          27.059961318969727,
          6.722805976867676,
          45.31837463378906,
          15.801824569702148,
          10.945653915405273,
          43.59476852416992,
          7.560025691986084,
          6.787303447723389,
          35.4937629699707,
          6.397675514221191,
          9.437660217285156,
          33.07616424560547,
          10.0283784866333,
          18.26250457763672,
          -40.780059814453125,
          3.1694369316101074,
          2.264169931411743,
          9.153777122497559,
          14.405627250671387,
          42.23050308227539,
          22.812292098999023,
          7.943108558654785,
          9.628252983093262,
          -0.48714661598205566,
          10.190424919128418,
          0.8689273595809937,
          42.91630172729492,
          44.05373764038086,
          20.347211837768555,
          29.488706588745117,
          2.932035446166992,
          0.31547409296035767,
          8.791056632995605,
          43.95124435424805,
          -1.0096261501312256,
          43.816871643066406,
          7.654519081115723,
          20.015748977661133,
          32.44385528564453,
          42.24159240722656,
          10.023467063903809,
          13.407833099365234,
          36.478946685791016,
          33.8870964050293,
          9.537409782409668,
          43.37371063232422,
          -17.032974243164062,
          8.897353172302246,
          -33.1066780090332,
          42.81251525878906,
          44.10874557495117,
          43.6652717590332,
          23.307804107666016,
          15.118268966674805,
          13.074532508850098
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"12fe3be2-d4f4-45f8-b284-91607954bbfd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"12fe3be2-d4f4-45f8-b284-91607954bbfd\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '12fe3be2-d4f4-45f8-b284-91607954bbfd',\n",
       "                        [{\"mode\": \"text\", \"text\": [\"hundreds\", \"of\", \"people\", \"have\", \"been\", \"forced\", \"to\", \"their\", \"homes\", \"in\", \"the\", \"southern\", \"new\", \"south\", \"wales\", \"as\", \"strong\", \"winds\", \"today\", \"huge\", \"towards\", \"town\", \"hill\", \"top\", \"blaze\", \"near\", \"west\", \"sydney\", \"has\", \"highway\", \"at\", \"about\", \"pm\", \"aedt\", \"weather\", \"storm\", \"moved\", \"east\", \"across\", \"blue\", \"mountains\", \"authorities\", \"make\", \"decision\", \"from\", \"streets\", \"an\", \"residents\", \"left\", \"for\", \"nearby\", \"rural\", \"fire\", \"service\", \"says\", \"conditions\", \"which\", \"caused\", \"now\", \"and\", \"around\", \"are\", \"all\", \"more\", \"than\", \"blazes\", \"on\", \"year\", \"eve\", \"crews\", \"called\", \"while\", \"few\", \"details\", \"available\", \"this\", \"stage\", \"it\", \"closed\", \"both\", \"meanwhile\", \"is\", \"no\", \"longer\", \"threatening\", \"area\", \"rain\", \"some\", \"parts\", \"illawarra\", \"hunter\", \"north\", \"coast\", \"but\", \"bureau\", \"done\", \"little\", \"any\", \"hundred\", \"fires\", \"still\", \"burning\", \"state\", \"quite\", \"those\", \"areas\", \"less\", \"five\", \"she\", \"said\", \"places\", \"really\", \"not\", \"significant\", \"so\", \"there\", \"much\", \"far\", \"concerned\", \"fact\", \"they\", \"ve\", \"probably\", \"efforts\", \"firefighters\", \"because\", \"wind\", \"that\", \"with\", \"indian\", \"security\", \"forces\", \"shot\", \"dead\", \"eight\", \"suspected\", \"militants\", \"night\", \"long\", \"kashmir\", \"took\", \"place\", \"capital\", \"deaths\", \"came\", \"pakistani\", \"police\", \"arrested\", \"two\", \"groups\", \"accused\", \"attack\", \"india\", \"parliament\", \"pakistan\", \"based\", \"mohammad\", \"carrying\", \"out\", \"december\", \"military\", \"intelligence\", \"tensions\", \"since\", \"raid\", \"sides\", \"troops\", \"along\", \"border\", \"trading\", \"diplomatic\", \"yesterday\", \"announced\", \"had\", \"chief\", \"mohammed\", \"say\", \"likely\", \"raids\", \"will\", \"be\", \"launched\", \"against\", \"well\", \"other\", \"militant\", \"organisations\", \"between\", \"level\", \"seen\", \"war\", \"national\", \"road\", \"toll\", \"christmas\", \"holiday\", \"period\", \"same\", \"time\", \"last\", \"died\", \"roads\", \"queensland\", \"victoria\", \"western\", \"australia\", \"northern\", \"territory\", \"each\", \"recorded\", \"three\", \"act\", \"tasmania\", \"remain\", \"free\", \"argentina\", \"political\", \"economic\", \"crisis\", \"its\", \"interim\", \"president\", \"who\", \"office\", \"just\", \"week\", \"ago\", \"told\", \"nation\", \"he\", \"could\", \"rescue\", \"key\", \"fellow\", \"would\", \"support\", \"his\", \"massive\", \"foreign\", \"debt\", \"or\", \"plan\", \"was\", \"only\", \"million\", \"jobs\", \"end\", \"four\", \"years\", \"recession\", \"days\", \"after\", \"following\", \"series\", \"failed\", \"senate\", \"leader\", \"until\", \"government\", \"too\", \"another\", \"senior\", \"role\", \"elections\", \"scheduled\", \"march\", \"leaving\", \"worst\", \"by\", \"international\", \"six\", \"suspended\", \"hospital\", \"inappropriate\", \"use\", \"during\", \"work\", \"hours\", \"women\", \"were\", \"labour\", \"health\", \"investigation\", \"further\", \"within\", \"executive\", \"officer\", \"tony\", \"one\", \"put\", \"risk\", \"staff\", \"involved\", \"able\", \"take\", \"over\", \"we\", \"re\", \"very\", \"body\", \"our\", \"these\", \"should\", \"know\", \"better\", \"why\", \"action\", \"them\", \"ll\", \"next\", \"federal\", \"asylum\", \"seekers\", \"return\", \"home\", \"when\", \"environment\", \"secure\", \"kabul\", \"affairs\", \"minister\", \"alexander\", \"downer\", \"refused\", \"how\", \"claims\", \"process\", \"hold\", \"major\", \"threat\", \"most\", \"seeking\", \"many\", \"tried\", \"get\", \"into\", \"matter\", \"britain\", \"countries\", \"europe\", \"claimed\", \"fleeing\", \"taliban\", \"power\", \"afghanistan\", \"finished\", \"mass\", \"detainees\", \"island\", \"pacific\", \"nauru\", \"total\", \"operations\", \"using\", \"aircraft\", \"second\", \"delivered\", \"where\", \"temporary\", \"department\", \"immigration\", \"remaining\", \"spokesman\", \"future\", \"yet\", \"made\", \"united\", \"states\", \"team\", \"seles\", \"michael\", \"scored\", \"victory\", \"france\", \"first\", \"hopman\", \"cup\", \"match\", \"perth\", \"up\", \"event\", \"won\", \"singles\", \"give\", \"us\", \"lead\", \"old\", \"currently\", \"start\", \"fight\", \"hard\", \"winning\", \"then\", \"st\", \"down\", \"determined\", \"th\", \"win\", \"americans\", \"go\", \"swiss\", \"final\", \"great\", \"way\", \"tennis\", \"got\", \"my\", \"am\", \"beat\", \"him\", \"even\", \"though\", \"bit\", \"here\", \"keep\", \"if\", \"do\", \"think\", \"chance\", \"anyone\", \"playing\", \"before\", \"taking\", \"set\", \"american\", \"breaking\", \"third\", \"games\", \"expected\", \"her\", \"tough\", \"player\", \"world\", \"position\", \"you\", \"play\", \"want\", \"try\", \"early\", \"season\", \"opening\", \"quickly\", \"game\", \"completed\", \"despite\", \"celebrations\", \"river\", \"kilometres\", \"battling\", \"hot\", \"melbourne\", \"strongly\", \"contested\", \"afternoon\", \"thursday\", \"line\", \"others\", \"fell\", \"red\", \"cross\", \"overnight\", \"containment\", \"lines\", \"severe\", \"getting\", \"forecast\", \"continue\", \"temperatures\", \"high\", \"least\", \"friday\", \"means\", \"fighters\", \"guard\", \"lot\", \"known\", \"contained\", \"however\", \"given\", \"coming\", \"property\", \"greater\", \"brought\", \"under\", \"control\", \"spencer\", \"city\", \"lower\", \"kilometre\", \"protect\", \"communities\", \"morning\", \"large\", \"above\", \"also\", \"used\", \"drop\", \"commissioner\", \"activity\", \"smoke\", \"being\", \"asked\", \"avoid\", \"reduced\", \"hour\", \"access\", \"royal\", \"park\", \"local\", \"allowed\", \"continuing\", \"thousands\", \"storms\", \"struck\", \"force\", \"trees\", \"cars\", \"energy\", \"every\", \"person\", \"working\", \"through\", \"brisbane\", \"toowoomba\", \"car\", \"inside\", \"fierce\", \"sent\", \"tree\", \"house\", \"injured\", \"entered\", \"official\", \"killed\", \"destroyed\", \"part\", \"began\", \"heritage\", \"traditional\", \"trapped\", \"flames\", \"markets\", \"buildings\", \"blame\", \"death\", \"themselves\", \"victims\", \"public\", \"cut\", \"short\", \"inquiry\", \"general\", \"musharraf\", \"wants\", \"prepared\", \"respond\", \"peace\", \"reduce\", \"tension\", \"move\", \"taken\", \"measures\", \"armed\", \"face\", \"might\", \"received\", \"parties\", \"welcomed\", \"community\", \"trying\", \"like\", \"positive\", \"union\", \"group\", \"nations\", \"among\", \"resolve\", \"stand\", \"off\", \"offer\", \"holding\", \"talks\", \"prime\", \"saying\", \"gives\", \"me\", \"accept\", \"reject\", \"meet\", \"january\", \"regional\", \"cooperation\", \"summit\", \"ruled\", \"assault\", \"warned\", \"saturday\", \"dispute\", \"growing\", \"small\", \"conflict\", \"sunday\", \"meeting\", \"situation\", \"domestic\", \"society\", \"form\", \"terrorism\", \"eastern\", \"afghan\", \"british\", \"officials\", \"ended\", \"without\", \"agreement\", \"lack\", \"document\", \"delay\", \"giving\", \"weeks\", \"number\", \"peacekeepers\", \"allow\", \"dr\", \"appeared\", \"signed\", \"already\", \"soon\", \"nothing\", \"sign\", \"proposals\", \"commanders\", \"occupation\", \"israeli\", \"army\", \"palestinian\", \"attacked\", \"gaza\", \"strip\", \"palestinians\", \"opened\", \"vehicle\", \"jewish\", \"edge\", \"sources\", \"post\", \"gunmen\", \"killing\", \"months\", \"including\", \"israelis\", \"october\", \"radical\", \"islamic\", \"hamas\", \"settlement\", \"can\", \"stop\", \"overall\", \"honours\", \"hobart\", \"yacht\", \"race\", \"ian\", \"boat\", \"appears\", \"title\", \"rival\", \"away\", \"nine\", \"metre\", \"boats\", \"australian\", \"losing\", \"geoff\", \"point\", \"apparently\", \"reported\", \"injuries\", \"africa\", \"spinner\", \"test\", \"african\", \"squad\", \"tour\", \"due\", \"injury\", \"captain\", \"shaun\", \"pollock\", \"hopes\", \"prepare\", \"ready\", \"going\", \"come\", \"best\", \"possible\", \"begun\", \"campaign\", \"doubles\", \"hoping\", \"nice\", \"always\", \"good\", \"looking\", \"forward\", \"see\", \"again\", \"hewitt\", \"putting\", \"pressure\", \"himself\", \"month\", \"open\", \"switzerland\", \"tie\", \"reach\", \"grand\", \"per\", \"cent\", \"happens\", \"times\", \"sort\", \"zealand\", \"lord\", \"director\", \"peter\", \"list\", \"seven\", \"classic\", \"country\", \"order\", \"budget\", \"biggest\", \"ever\", \"become\", \"dropped\", \"front\", \"predicted\", \"change\", \"mark\", \"williams\", \"incident\", \"region\", \"back\", \"close\", \"mr\", \"something\", \"don\", \"banks\", \"help\", \"payment\", \"workers\", \"issued\", \"leaders\", \"banking\", \"what\", \"happened\", \"monday\", \"man\", \"crash\", \"mid\", \"boy\", \"hit\", \"telephone\", \"remains\", \"condition\", \"petrol\", \"david\", \"laws\", \"hoped\", \"built\", \"prior\", \"required\", \"such\", \"increase\", \"separate\", \"flights\", \"gun\", \"carry\", \"finally\", \"stopped\", \"plane\", \"travelled\", \"attempting\", \"board\", \"flight\", \"personnel\", \"hand\", \"released\", \"planning\", \"terrorist\", \"ability\", \"airline\", \"problems\", \"follows\", \"paris\", \"explosives\", \"shoes\", \"tourists\", \"safety\", \"central\", \"emergency\", \"search\", \"became\", \"soft\", \"ground\", \"unit\", \"officers\", \"walk\", \"winner\", \"decided\", \"gary\", \"crossed\", \"almost\", \"half\", \"fleet\", \"leading\", \"victorian\", \"minute\", \"clear\", \"fast\", \"skipper\", \"blake\", \"successful\", \"weekend\", \"lost\", \"greatest\", \"concern\", \"changes\", \"extensive\", \"conducted\", \"heading\", \"battle\", \"suicide\", \"backed\", \"never\", \"mind\", \"side\", \"round\", \"ocean\", \"assa\", \"abloy\", \"accompanied\", \"light\", \"starting\", \"crowd\", \"behind\", \"crew\", \"yachts\", \"rest\", \"laden\", \"hearing\", \"court\", \"richard\", \"reid\", \"placed\", \"wall\", \"created\", \"grant\", \"possibility\", \"later\", \"charged\", \"jail\", \"terms\", \"charges\", \"allegedly\", \"airlines\", \"enough\", \"disaster\", \"leadership\", \"calling\", \"envoy\", \"anthony\", \"zinni\", \"cease\", \"retired\", \"marine\", \"late\", \"november\", \"secretary\", \"colin\", \"powell\", \"earlier\", \"bring\", \"halt\", \"statement\", \"yasser\", \"arafat\", \"calls\", \"violence\", \"confidence\", \"building\", \"agreed\", \"several\", \"played\", \"administration\", \"believe\", \"presence\", \"effective\", \"bringing\", \"council\", \"rate\", \"hiv\", \"male\", \"sex\", \"twice\", \"report\", \"centre\", \"disease\", \"need\", \"feel\", \"statistics\", \"show\", \"previous\", \"figures\", \"wake\", \"call\", \"rise\", \"sea\", \"levels\", \"global\", \"according\", \"survey\", \"antarctic\", \"organisation\", \"giant\", \"ice\", \"vaughan\", \"case\", \"serious\", \"increased\", \"water\", \"did\", \"metres\", \"break\", \"related\", \"impact\", \"human\", \"industrial\", \"cannot\", \"problem\", \"potential\", \"cities\", \"low\", \"september\", \"shane\", \"may\", \"room\", \"outlook\", \"certainly\", \"ahead\", \"concerns\", \"continues\", \"carried\", \"mt\", \"targeted\", \"boys\", \"heights\", \"ministry\", \"embassy\", \"representation\", \"ban\", \"planes\", \"delhi\", \"ahmed\", \"actions\", \"complex\", \"mission\", \"movement\", \"added\", \"result\", \"non\", \"operating\", \"threatened\", \"defence\", \"osama\", \"bin\", \"saudi\", \"protection\", \"supporters\", \"helped\", \"create\", \"sure\", \"lives\", \"information\", \"men\", \"arrest\", \"head\", \"party\", \"al\", \"qaeda\", \"network\", \"attacks\", \"york\", \"washington\", \"collapsed\", \"completely\", \"individuals\", \"resistance\", \"mayor\", \"giuliani\", \"led\", \"past\", \"trade\", \"speaking\", \"day\", \"crime\", \"source\", \"difficult\", \"deadly\", \"comes\", \"ensure\", \"your\", \"felt\", \"job\", \"turn\", \"believed\", \"served\", \"term\", \"prevent\", \"media\", \"batsmen\", \"boxing\", \"wicket\", \"runs\", \"andy\", \"bichel\", \"langer\", \"matthew\", \"hayden\", \"went\", \"innings\", \"bowling\", \"jacques\", \"kallis\", \"neil\", \"mckenzie\", \"wickets\", \"balls\", \"caught\", \"although\", \"showed\", \"ball\", \"klusener\", \"boucher\", \"adding\", \"waugh\", \"paid\", \"brett\", \"lee\", \"leg\", \"continued\", \"field\", \"running\", \"henderson\", \"direct\", \"allan\", \"donald\", \"ricky\", \"ponting\", \"returning\", \"glenn\", \"mcgrath\", \"rafter\", \"swept\", \"nearly\", \"whether\", \"survived\", \"pulled\", \"member\", \"found\", \"helicopter\", \"big\", \"wave\", \"knew\", \"arrived\", \"damage\", \"news\", \"radio\", \"suburbs\", \"throughout\", \"average\", \"things\", \"expects\", \"john\", \"confirm\", \"criminal\", \"muslim\", \"extremists\", \"jihad\", \"beginning\", \"television\", \"held\", \"virgin\", \"attempt\", \"ansett\", \"internet\", \"travel\", \"adelaide\", \"launceston\", \"canberra\", \"customers\", \"largest\", \"base\", \"market\", \"press\", \"main\", \"business\", \"endeavour\", \"claim\", \"suffered\", \"life\", \"run\", \"land\", \"bank\", \"heavy\", \"tanks\", \"helicopters\", \"jenin\", \"attacking\", \"immediately\", \"israel\", \"soldiers\", \"returned\", \"escaped\", \"self\", \"rule\", \"authority\", \"injuring\", \"slightly\", \"fired\", \"exchange\", \"sir\", \"actor\", \"civil\", \"yes\", \"wednesday\", \"heart\", \"aged\", \"cancer\", \"having\", \"treatment\", \"awards\", \"approval\", \"range\", \"king\", \"george\", \"secret\", \"thing\", \"cricket\", \"proteas\", \"resume\", \"affected\", \"flying\", \"band\", \"expect\", \"population\", \"passed\", \"mountain\", \"confident\", \"tomorrow\", \"services\", \"whole\", \"fair\", \"share\", \"find\", \"expressed\", \"circumstances\", \"whatever\", \"needs\", \"annual\", \"speech\", \"changed\", \"itself\", \"beyond\", \"america\", \"history\", \"humanity\", \"live\", \"terror\", \"wounded\", \"fighter\", \"weapons\", \"kandahar\", \"governor\", \"custody\", \"surrender\", \"bombing\", \"airport\", \"militia\", \"handed\", \"russian\", \"important\", \"republic\", \"spread\", \"money\", \"look\", \"system\", \"project\", \"ways\", \"prisoners\", \"justice\", \"coalition\", \"families\", \"financial\", \"rights\", \"spokeswoman\", \"trial\", \"education\", \"programs\", \"ms\", \"centrelink\", \"income\", \"employment\", \"pay\", \"child\", \"shopping\", \"sergeant\", \"shortly\", \"members\", \"stuart\", \"bush\", \"question\", \"improve\", \"receiving\", \"questions\", \"pace\", \"jason\", \"gillespie\", \"right\", \"hopefully\", \"provide\", \"bowler\", \"jets\", \"saw\", \"passengers\", \"ceremony\", \"hamid\", \"karzai\", \"cabinet\", \"economy\", \"cost\", \"dollars\", \"must\", \"plans\", \"projects\", \"various\", \"believes\", \"tora\", \"bora\", \"caves\", \"visit\", \"bid\", \"does\", \"enter\", \"searching\", \"signs\", \"suspect\", \"warplanes\", \"commander\", \"charge\", \"gone\", \"pentagon\", \"macgill\", \"full\", \"steve\", \"adam\", \"warne\", \"rejected\", \"terrorists\", \"ariel\", \"sharon\", \"declared\", \"staying\", \"bombings\", \"smaller\", \"follow\", \"save\", \"young\", \"requested\", \"normal\", \"technology\", \"ill\", \"professor\", \"deputy\", \"institute\", \"law\", \"opposition\", \"thought\", \"family\", \"making\", \"japanese\", \"unidentified\", \"reports\", \"japan\", \"warning\", \"approach\", \"church\", \"handling\", \"alleged\", \"abuse\", \"anglican\", \"school\", \"howard\", \"hollingworth\", \"criticism\", \"archbishop\", \"resign\", \"costello\", \"explanation\", \"needed\", \"step\", \"understanding\", \"simon\", \"crean\", \"described\", \"legal\", \"advice\", \"heard\", \"understand\", \"gave\", \"confirmed\", \"timor\", \"comment\", \"responsibility\", \"leave\", \"company\", \"guess\", \"unity\", \"followed\", \"program\", \"fund\", \"policy\", \"effort\", \"freeze\", \"qantas\", \"maintenance\", \"relations\", \"commission\", \"employees\", \"billion\", \"gas\", \"reached\", \"phillips\", \"deal\", \"offered\", \"ministers\", \"abu\", \"worked\", \"documents\", \"factory\", \"former\", \"true\", \"read\", \"tell\", \"real\", \"detail\", \"names\", \"premier\", \"facility\", \"allegations\", \"knowledge\", \"evidence\", \"voted\", \"deployed\", \"initial\", \"mandate\", \"assistance\", \"un\", \"resolution\", \"numbers\", \"eventually\", \"germany\", \"bonn\", \"anti\", \"nuclear\", \"assisting\", \"bomb\", \"provided\", \"crackdown\", \"food\", \"clashes\", \"powers\", \"fear\", \"unrest\", \"own\", \"woomera\", \"detention\", \"visa\", \"outside\", \"recent\", \"bill\", \"private\", \"sector\", \"credit\", \"data\", \"doctors\", \"ask\", \"research\", \"companies\", \"medical\", \"record\", \"often\", \"solution\", \"consumers\", \"dozens\", \"seriously\", \"roof\", \"children\", \"witnesses\", \"collapse\", \"everything\", \"fine\", \"manager\", \"afp\", \"agency\", \"corporation\", \"son\", \"zimbabwe\", \"white\", \"commonwealth\", \"mean\", \"issue\", \"declaration\", \"table\", \"waiting\", \"response\", \"request\", \"observers\", \"election\", \"territories\", \"nablus\", \"improved\", \"pre\", \"bombers\", \"jerusalem\", \"haifa\", \"interest\", \"unfortunately\", \"robert\", \"august\", \"senator\", \"whereabouts\", \"hicks\", \"fighting\", \"alongside\", \"vote\", \"relationship\", \"operation\", \"latest\", \"stay\", \"assembly\", \"elders\", \"draft\", \"damaged\", \"current\", \"voice\", \"twenty\", \"reveal\", \"refugees\", \"australians\", \"detain\", \"transport\", \"air\", \"strachan\", \"training\", \"crashed\", \"strike\", \"accident\", \"students\", \"findings\", \"harris\", \"investment\", \"asic\", \"include\", \"counts\", \"acting\", \"management\", \"coroner\", \"investigating\", \"hearings\", \"ray\", \"qc\", \"representing\", \"experts\", \"begin\", \"named\", \"sometimes\", \"advance\", \"marines\", \"revealed\", \"captured\", \"hunt\", \"jalalabad\", \"bomber\", \"strikes\", \"actually\", \"responding\", \"insurance\", \"alliance\", \"approached\", \"july\", \"proposed\", \"labor\", \"issues\", \"options\", \"didn\", \"single\", \"anything\", \"fatah\", \"factions\", \"rather\", \"offices\", \"started\", \"tuesday\", \"focus\", \"strategic\", \"targets\", \"review\", \"meetings\", \"violent\", \"farm\", \"discussions\", \"debate\", \"disappointed\", \"philip\", \"ruddock\", \"understood\", \"attorney\", \"daryl\", \"aboard\", \"asio\", \"appropriate\", \"present\", \"finding\", \"tribal\", \"doubt\", \"pilot\", \"procedures\", \"aboriginal\", \"sentence\", \"administrators\", \"paying\", \"entitlements\", \"redundancy\", \"decide\", \"absolutely\", \"hih\", \"creditors\", \"firm\", \"chairman\", \"finance\", \"directors\", \"receive\", \"tailenders\", \"scene\", \"channel\", \"facilities\", \"whose\", \"examination\", \"unions\", \"adequate\", \"together\", \"necessary\", \"rumsfeld\", \"networks\", \"recovery\", \"decisions\", \"oil\", \"growth\", \"structure\", \"university\", \"cause\", \"negotiations\", \"club\", \"elected\", \"happy\", \"picked\", \"outcome\", \"treated\", \"hope\", \"headquarters\", \"cave\", \"interview\", \"different\", \"investigate\", \"escalating\", \"doing\", \"french\", \"negotiating\", \"address\", \"middle\", \"wanted\", \"locked\", \"wage\", \"manufacturing\", \"doug\", \"cameron\", \"seemed\", \"sharing\", \"sending\", \"quarter\", \"coup\", \"invasion\", \"shows\", \"volunteers\", \"clean\", \"track\", \"space\", \"shuttle\", \"station\", \"landed\", \"trip\", \"walked\", \"proposal\", \"publicly\", \"hotel\", \"indonesian\", \"suharto\", \"vice\", \"indonesia\", \"solomon\", \"islands\", \"ballot\", \"positions\", \"ethnic\", \"success\", \"conference\", \"met\", \"words\", \"target\", \"fall\", \"special\", \"interests\", \"promised\", \"doesn\", \"costs\", \"yallourn\", \"mining\", \"convicted\", \"whiting\", \"murder\", \"sarah\", \"career\", \"hijacked\", \"tape\", \"sheikh\", \"aware\", \"denied\", \"connection\", \"underway\", \"woman\", \"infected\", \"gunships\", \"bus\", \"ambush\", \"blasted\", \"ramallah\", \"wing\", \"responsible\", \"unemployment\", \"westpac\", \"anz\", \"bargaining\", \"industry\", \"lording\", \"construction\", \"cfmeu\", \"martin\", \"kingham\", \"faces\", \"bob\", \"neville\", \"headed\", \"clearly\", \"unable\", \"guilty\", \"verdict\", \"ford\", \"lockett\", \"interlaken\", \"tragedy\", \"adventure\", \"canyoning\", \"manslaughter\", \"guides\", \"farmers\", \"coach\", \"co\", \"friedli\", \"francs\", \"gang\", \"reserve\", \"committee\", \"drug\", \"study\", \"decades\", \"results\", \"doctor\", \"gambier\", \"path\", \"amin\", \"peres\", \"determine\", \"lung\", \"kieren\", \"champion\", \"suggested\", \"rates\", \"provisional\", \"liquidation\", \"civilians\", \"sultan\", \"course\", \"butterfly\", \"afroz\", \"goshen\", \"wayne\", \"flood\", \"gorge\", \"gerber\", \"kissinger\", \"stability\", \"replied\", \"launch\", \"davis\", \"krishna\", \"products\", \"chosen\", \"treasurer\", \"cuts\", \"natural\", \"races\", \"eliminated\", \"austar\", \"traveland\", \"apra\", \"masood\", \"tonight\", \"rabbani\", \"virus\", \"ses\", \"harrison\", \"ashes\", \"benares\", \"beatle\", \"hare\", \"choosing\", \"owen\"], \"type\": \"scatter\", \"x\": [-12.49445915222168, 55.020111083984375, 52.11457443237305, 55.17595672607422, 52.84236145019531, -22.01788902282715, 55.626834869384766, 54.48806381225586, -35.29669952392578, 55.29194259643555, 54.064823150634766, -10.054299354553223, 54.80254364013672, 54.75698471069336, 20.19831657409668, 55.10423278808594, 22.411130905151367, 16.985227584838867, 53.11782455444336, -44.55323791503906, -13.73154354095459, -22.352815628051758, 20.30546760559082, -39.555015563964844, 0.0016319080023095012, 45.58504867553711, 46.31407165527344, 50.57473373413086, 55.75495529174805, -42.029457092285156, 55.724884033203125, 53.79914474487305, -16.446151733398438, -18.983726501464844, 31.204137802124023, -14.096541404724121, 3.6540884971618652, 45.4666633605957, 19.172863006591797, 1.657549500465393, 16.37669563293457, 25.986526489257812, 34.10365295410156, 2.7699618339538574, 55.77836227416992, 21.479507446289062, 54.871097564697266, -38.40876388549805, 39.61507797241211, 55.44145965576172, 17.096853256225586, -37.17818069458008, 52.658443450927734, 28.274993896484375, 55.37104034423828, 17.111295700073242, 54.21613693237305, -44.16450119018555, 51.28910446166992, 55.255577087402344, 50.79532241821289, 55.44769287109375, 50.92283630371094, 53.29655075073242, 52.10264205932617, 5.050864219665527, 55.58917999267578, 53.88882827758789, 16.303722381591797, 3.997213363647461, 35.833091735839844, 46.75838851928711, 10.835441589355469, -26.585115432739258, -44.4093132019043, 54.349857330322266, -31.35323143005371, 54.178035736083984, 11.67601203918457, 31.560964584350586, 40.005470275878906, 55.2210693359375, 51.3885498046875, -8.147910118103027, 16.491682052612305, 38.449737548828125, 13.84128475189209, 51.37407302856445, 13.281671524047852, 16.40268325805664, 4.589776515960693, 42.400264739990234, -33.212120056152344, 54.67912292480469, 1.940852403640747, -39.9106330871582, 7.072291851043701, 51.15826416015625, 7.532176971435547, 6.537481784820557, 50.31991195678711, -37.50724411010742, 47.569026947021484, -41.60829544067383, 43.98863983154297, 42.18946075439453, -39.75769805908203, 48.94847869873047, 42.73683166503906, 54.7765998840332, -32.13826370239258, 1.1861038208007812, 54.055267333984375, -40.42177200317383, 48.42385482788086, 52.432411193847656, 13.213031768798828, -44.578495025634766, -43.41343307495117, 16.447162628173828, 54.642799377441406, 35.91136932373047, -36.51720428466797, 16.150516510009766, 11.739582061767578, 45.127994537353516, 0.513700008392334, 54.71750259399414, 55.674583435058594, 28.181427001953125, 51.15463638305664, 45.90859603881836, -7.821333885192871, 15.625496864318848, 38.052547454833984, -41.308441162109375, 17.692625045776367, 44.15863800048828, 36.1984977722168, 9.040755271911621, 17.95916748046875, 32.654842376708984, -30.793354034423828, -28.110490798950195, 8.8060941696167, -39.89732360839844, 51.86484909057617, 4.071391582489014, 54.99821472167969, 34.51055145263672, -4.019925117492676, 43.29726028442383, 35.733394622802734, -23.78297996520996, 47.0733528137207, -24.347360610961914, -10.411368370056152, -10.628006935119629, 53.87865447998047, 10.87021541595459, 46.93095016479492, -38.861690521240234, 13.402504920959473, 43.4542350769043, 16.28459930419922, 15.220739364624023, 23.031641006469727, -0.028703350573778152, -44.85806655883789, 0.1207953691482544, 15.84861946105957, 49.09025955200195, -40.206687927246094, 54.522220611572266, 38.48880386352539, 10.289761543273926, 50.95368194580078, -41.40241622924805, -44.303890228271484, 54.518001556396484, 53.5393180847168, -6.457818984985352, 52.91469192504883, 41.163448333740234, 48.88412857055664, -35.00470733642578, -15.910881042480469, 46.27433395385742, 10.308094024658203, -30.98959732055664, 15.1356840133667, 45.49327087402344, -39.12260818481445, 0.4514407813549042, 31.108293533325195, 7.9768571853637695, -39.86130142211914, -37.939918518066406, 46.49000549316406, 53.17931365966797, 41.13996505737305, -18.016199111938477, 28.51923370361328, -43.95705795288086, -23.266632080078125, 52.61781692504883, 39.836891174316406, -30.970706939697266, -33.86326599121094, -5.6478095054626465, 52.74962615966797, -6.602885723114014, -7.939851760864258, -3.278406858444214, -13.819392204284668, -26.00867462158203, -7.53117036819458, 14.606440544128418, 0.7378872632980347, 53.433753967285156, 18.380245208740234, 50.70555877685547, 54.455753326416016, -32.34546661376953, 49.78509521484375, 41.71857833862305, 36.85905456542969, 53.13185119628906, -23.088314056396484, 53.121246337890625, 51.71699905395508, 16.177152633666992, -0.7137146592140198, 1.4195351600646973, 53.5007438659668, 29.233766555786133, 54.99588394165039, -45.838623046875, 42.99578094482422, -21.55352783203125, 52.330299377441406, 3.4482522010803223, 53.6986198425293, 38.871559143066406, -7.261913776397705, -24.8358097076416, 33.12970733642578, 51.963722229003906, 39.04872131347656, 21.267658233642578, 49.61699676513672, 55.750606536865234, 38.193931579589844, -42.31508255004883, -28.211278915405273, -8.781936645507812, 44.32265090942383, -44.850929260253906, 52.524818420410156, 25.677974700927734, 40.821311950683594, 37.1110954284668, 3.465892791748047, -10.841669082641602, 9.678325653076172, -6.606879711151123, -2.405317783355713, -11.87809944152832, 55.36552429199219, 47.090660095214844, 44.7228889465332, 14.357340812683105, 33.669063568115234, 6.486199855804443, -2.92879056930542, 43.565643310546875, 35.10602951049805, 40.96857833862305, -29.385530471801758, 55.37973403930664, 0.3521845042705536, 13.75926399230957, -43.287906646728516, 42.990848541259766, -27.940834045410156, -8.619616508483887, -44.1116943359375, -23.225940704345703, 52.70397186279297, 31.764060974121094, 2.733612298965454, 40.48747634887695, -37.62126922607422, -40.7890739440918, 39.39573669433594, 53.27996826171875, 54.78400421142578, 46.96540069580078, 50.07201385498047, 7.032276153564453, 47.676422119140625, 36.54268264770508, 42.977684020996094, 35.32401657104492, 21.069400787353516, 16.14577293395996, 48.116817474365234, 50.28848648071289, 3.5937743186950684, 47.41598129272461, 44.95382308959961, 20.496973037719727, 18.07258415222168, 4.062146186828613, -5.324862480163574, 54.38218688964844, 19.028005599975586, 10.231147766113281, -11.360869407653809, 19.28783416748047, 54.968902587890625, -45.11469650268555, -11.082618713378906, -31.349838256835938, 36.79210662841797, 40.333091735839844, 7.4961957931518555, 10.627026557922363, 12.646942138671875, -38.3040885925293, 39.340763092041016, 6.216203212738037, 36.2823486328125, 6.915467739105225, 42.67972183227539, 54.1357307434082, -44.62827682495117, -2.942913055419922, -13.476244926452637, 8.16152286529541, -7.251429080963135, -22.201082229614258, 50.966339111328125, 41.06924819946289, 52.25968551635742, 18.329805374145508, -11.535842895507812, 22.532506942749023, -45.512062072753906, -23.463932037353516, -41.16160583496094, -0.4388323128223419, -35.6345329284668, -42.87376022338867, 23.63214683532715, 44.34318542480469, -5.075011730194092, 49.49677658081055, 3.7600913047790527, -21.251728057861328, -40.7056884765625, 11.074946403503418, 26.956222534179688, 0.0014531896449625492, -18.361061096191406, 47.36408615112305, 49.15038299560547, 50.667579650878906, 40.77415466308594, 17.24605369567871, 2.4609804153442383, 19.79878044128418, -19.732290267944336, -4.928314208984375, 53.230064392089844, 14.478710174560547, 27.777856826782227, 20.771255493164062, -40.560707092285156, 53.740577697753906, 9.463117599487305, 26.139862060546875, 3.915987014770508, -1.9586087465286255, 52.955284118652344, 14.650367736816406, 47.273128509521484, -41.837181091308594, 27.07137680053711, -42.31621170043945, -15.60762882232666, -6.22139835357666, 40.244468688964844, 18.013803482055664, 49.03567886352539, -19.213775634765625, 2.146848201751709, 25.584327697753906, -11.779606819152832, 38.96891784667969, -33.7855224609375, -13.028340339660645, -21.861650466918945, 17.29146957397461, -40.08289337158203, 8.002287864685059, -30.862119674682617, 40.02039337158203, -44.70114517211914, 42.64238739013672, 18.893354415893555, -44.73053741455078, 7.013421058654785, 0.635797381401062, -18.882797241210938, 53.63247299194336, 37.563987731933594, 48.30784225463867, -3.5741398334503174, -13.682205200195312, -39.1129264831543, 53.732521057128906, -26.804908752441406, 38.45545959472656, -3.4433183670043945, 19.72844696044922, 34.42900085449219, -17.340200424194336, 30.104459762573242, 11.27469253540039, 21.692323684692383, 5.954702854156494, 52.76416778564453, -15.01302719116211, 53.5932502746582, 14.946006774902344, 12.438104629516602, -43.337459564208984, 9.356472969055176, -41.715476989746094, -37.901519775390625, -44.64073944091797, -0.593230664730072, -16.8835391998291, 16.511564254760742, 18.114234924316406, 27.782230377197266, -42.692665100097656, 19.6557559967041, 5.566519737243652, 42.1246452331543, 12.9765625, 2.097168445587158, -42.99742889404297, -37.90163040161133, 20.81451416015625, -8.237899780273438, 16.802658081054688, -13.281123161315918, 18.36837387084961, 22.59388542175293, 19.502153396606445, -32.398216247558594, -24.56598472595215, -40.034603118896484, -17.93609619140625, -8.8029203414917, -17.390151977539062, 31.514209747314453, -41.81496047973633, -37.294227600097656, -18.707365036010742, 33.6474494934082, 15.6942720413208, -2.4737167358398438, -35.46638107299805, -18.6118106842041, 22.530729293823242, 28.177749633789062, 15.9600830078125, -17.376895904541016, -28.712888717651367, -12.890669822692871, 47.636505126953125, 10.326537132263184, 14.666142463684082, 45.0463752746582, -44.852169036865234, 11.608062744140625, -40.9514045715332, 2.4741265773773193, 43.233375549316406, -18.984363555908203, 17.673425674438477, 53.69934844970703, 10.081666946411133, -43.74879455566406, -13.082319259643555, -32.169551849365234, -9.756959915161133, 49.912071228027344, 26.21824073791504, 16.243070602416992, 1.4300682544708252, -18.084623336791992, -39.70833969116211, 37.625999450683594, 21.998720169067383, 47.64049530029297, -5.066882133483887, -17.046030044555664, -33.13038635253906, -42.1634407043457, -35.825687408447266, 43.720191955566406, -26.755481719970703, 3.2038848400115967, 2.6157705783843994, 0.700657308101654, -3.3933682441711426, 12.84287166595459, 46.364742279052734, -34.53535079956055, 16.575984954833984, -36.99375915527344, -40.393348693847656, 4.948148727416992, -42.67792892456055, 12.022978782653809, 8.206470489501953, 12.284930229187012, 21.394441604614258, 33.66312789916992, 43.37147903442383, -9.899002075195312, 22.859825134277344, -45.289306640625, 11.535582542419434, 19.56614112854004, 20.428598403930664, -9.411809921264648, 0.02480427920818329, -30.09309196472168, -3.8308684825897217, -23.68024253845215, 5.832739353179932, 19.788000106811523, 32.65721130371094, 0.9086244702339172, -30.209787368774414, -42.57746505737305, 51.47346115112305, -12.812432289123535, -45.528263092041016, 12.847396850585938, 5.456657886505127, 37.949462890625, -15.164544105529785, 18.705585479736328, -10.848381042480469, 6.3369460105896, -38.638126373291016, 5.620513916015625, -14.545989990234375, -18.59168243408203, -4.309532642364502, -29.790620803833008, -13.051201820373535, -5.3736572265625, 4.11247444152832, 32.99428939819336, 4.0298919677734375, 48.74807357788086, 48.341556549072266, -1.7365782260894775, -19.141321182250977, -21.094289779663086, -18.084991455078125, 44.37400817871094, 14.198009490966797, -18.616214752197266, 33.00727844238281, 28.761058807373047, 27.775619506835938, -16.078414916992188, -34.57032012939453, -21.881715774536133, 6.584284782409668, 18.52934455871582, 20.65412139892578, 0.10415294021368027, -12.410590171813965, 19.868440628051758, 15.835236549377441, 16.181047439575195, -43.692508697509766, -15.803078651428223, -18.446935653686523, -15.024028778076172, 21.657045364379883, 4.8805623054504395, -23.7355899810791, 46.67898178100586, -41.02706527709961, 10.238702774047852, 1.4075604677200317, -44.82384490966797, 21.902528762817383, -0.22434934973716736, 45.7053108215332, 13.758384704589844, 46.83857345581055, 13.398771286010742, 25.462541580200195, 27.25275421142578, 14.261774063110352, 21.079790115356445, -22.49371337890625, -43.14228057861328, -25.984392166137695, 38.46006774902344, 18.308813095092773, -12.355536460876465, 32.91038513183594, -22.351192474365234, -10.826624870300293, -3.3476290702819824, -31.09383201599121, 0.7377815246582031, 19.090200424194336, 17.316959381103516, -11.815529823303223, -27.146907806396484, 53.18452453613281, -15.301145553588867, 54.13895034790039, 21.128700256347656, 44.54839324951172, -24.047853469848633, -5.418498992919922, -27.419998168945312, -20.266159057617188, 7.833260536193848, 7.9297871589660645, -41.04811096191406, -41.917755126953125, -34.06919860839844, -33.37279510498047, 39.78579330444336, 46.524131774902344, 2.860750675201416, -23.73433494567871, -22.831941604614258, 45.89739227294922, 47.30860137939453, 5.085324764251709, 49.3868408203125, 6.740398406982422, -37.67167282104492, 21.663185119628906, -43.99078369140625, -39.784000396728516, 32.50724411010742, 20.04357147216797, -19.591936111450195, 8.283878326416016, -3.4103965759277344, 20.850881576538086, -38.47383499145508, 16.611881256103516, 20.82097625732422, 18.49530029296875, 54.83116149902344, 5.26511812210083, -44.911991119384766, -6.850325584411621, 11.94946002960205, -44.209754943847656, 18.066429138183594, 7.11790657043457, -3.973318338394165, 50.29159927368164, -7.399674415588379, 18.543109893798828, -23.407493591308594, 0.5576720237731934, 13.729338645935059, 17.769432067871094, -41.34672927856445, -45.01293182373047, 17.060441970825195, 8.962685585021973, -8.23430061340332, 32.23979949951172, 33.220916748046875, -2.87813138961792, 13.67853832244873, 1.1943492889404297, -0.8162147998809814, -34.13283157348633, 20.01097869873047, -15.085856437683105, -43.27125930786133, 22.704500198364258, 25.134410858154297, -32.47905349731445, -11.350924491882324, -0.2522362172603607, -40.802913665771484, -23.166101455688477, 9.978034973144531, -23.195520401000977, 44.25033950805664, -12.856393814086914, 21.163928985595703, -1.1953846216201782, 18.205127716064453, 17.781789779663086, 47.01769256591797, 49.30824279785156, 17.5380859375, -42.24021911621094, 20.989452362060547, -35.02614974975586, -2.277555227279663, 21.563709259033203, 36.96432113647461, -28.48929786682129, -23.137239456176758, 12.927525520324707, -8.589566230773926, -43.727813720703125, 0.19719088077545166, -36.02598190307617, -4.274661064147949, -37.30955123901367, 19.02048110961914, -37.13417053222656, 14.092643737792969, 16.790584564208984, 9.146965980529785, 19.771503448486328, -7.987490177154541, 2.12626576423645, 39.60554122924805, 27.2115478515625, 54.014408111572266, -36.11121368408203, 37.29484176635742, -42.687381744384766, 24.94644546508789, 16.573179244995117, 48.962764739990234, -5.840967655181885, 10.640377044677734, -12.052047729492188, 49.366722106933594, 19.592084884643555, 19.378305435180664, 43.716156005859375, -22.222469329833984, 19.02008056640625, -32.51442337036133, 28.686748504638672, 4.809787273406982, -10.427916526794434, 19.29393196105957, -6.690701961517334, -1.1197723150253296, -26.693668365478516, -30.456985473632812, -13.882079124450684, 14.129671096801758, -7.568148612976074, -7.7622199058532715, -32.029056549072266, -14.599780082702637, -43.06575012207031, -10.308676719665527, 12.62861442565918, 18.82349967956543, -2.4969019889831543, -17.87324333190918, 17.780677795410156, -0.5689141750335693, -27.313156127929688, -24.253305435180664, 4.582822322845459, -22.272518157958984, 13.861353874206543, -38.43978500366211, 12.992959022521973, -30.262170791625977, 18.7828426361084, -11.791071891784668, 18.57310676574707, -9.387548446655273, 0.5772721171379089, -31.856769561767578, -40.3291130065918, 28.46179962158203, 2.25860857963562, -15.73443603515625, 16.100746154785156, 19.383535385131836, 21.156457901000977, -43.68878936767578, 7.177173137664795, -12.50881290435791, 21.58918571472168, -43.28391647338867, -43.1318359375, 9.82232666015625, 6.256849765777588, -23.30791664123535, -43.30471420288086, -24.994476318359375, 6.516464710235596, -23.335247039794922, 10.138301849365234, 8.1683931350708, -21.696144104003906, -29.481735229492188, -13.0247163772583, -11.017273902893066, -17.710939407348633, -3.0174190998077393, 20.307992935180664, -27.16854476928711, -44.09020233154297, 19.892608642578125, 18.487573623657227, -10.7702054977417, -4.2039875984191895, 46.1130485534668, -13.501031875610352, -9.133575439453125, -21.931665420532227, -35.549781799316406, -39.7562255859375, 17.886877059936523, -0.749016523361206, -4.162211894989014, 18.722246170043945, 7.993806838989258, -6.848008155822754, -43.9135627746582, 1.5019809007644653, 9.826610565185547, -17.840593338012695, 15.414807319641113, 49.6399040222168, -0.4533572494983673, 33.12154006958008, -3.5545480251312256, -14.063443183898926, -33.9827766418457, -6.04891300201416, -6.205697536468506, -1.4030216932296753, -21.33706283569336, -14.026286125183105, -41.355411529541016, -43.03177261352539, -44.52192687988281, 10.646848678588867, 9.567787170410156, -40.020545959472656, -42.33205032348633, -26.6612606048584, -8.285783767700195, -24.024658203125, -34.077762603759766, -28.435592651367188, 5.7219767570495605, -4.107591152191162, 11.008074760437012, 12.025497436523438, -6.347211837768555, -43.8688850402832, 36.70685577392578, 12.154744148254395, -9.740888595581055, 44.045753479003906, 4.633545875549316, 8.034158706665039, 35.4539680480957, 27.65406036376953, 51.66172790527344, -39.30633544921875, 10.252229690551758, 14.937081336975098, 29.25960922241211, 8.265103340148926, 43.76450729370117, -24.384841918945312, -3.7541537284851074, 8.334988594055176, -8.788456916809082, 20.125736236572266, -17.152170181274414, 15.147871017456055, 10.797563552856445, -2.7289891242980957, 9.545156478881836, -42.524044036865234, -8.788710594177246, 42.6188850402832, 43.46627426147461, -29.469778060913086, 15.787721633911133, 17.522497177124023, 15.447530746459961, -45.40361022949219, 3.9428164958953857, -44.45234680175781, 11.0889892578125, -22.400148391723633, -33.258323669433594, -38.735260009765625, -8.213305473327637, -33.330692291259766, -26.578563690185547, -15.54548454284668, 13.629755973815918, -44.678855895996094, -33.7755126953125, -15.112027168273926, 15.759539604187012, -31.47842025756836, -45.027103424072266, -17.55902099609375, -2.463787794113159, 11.778627395629883, 43.086936950683594, -38.52471160888672, 8.17796802520752, -31.267602920532227, -35.90013122558594, 33.304771423339844, -26.34864044189453, 1.8021024465560913, -14.278609275817871, 18.344005584716797, 14.410895347595215, 29.98880386352539, 9.024016380310059, 13.485508918762207, 3.4793572425842285, 1.0826212167739868, -39.017005920410156, 10.856244087219238, 16.06818199157715, 11.691006660461426, -44.4103889465332, -2.4418201446533203, 6.2981743812561035, 18.1474552154541, 10.662590980529785, -5.043787956237793, 6.959690093994141, -38.42216873168945, 20.499528884887695, 20.652748107910156, -4.58551025390625, 19.937240600585938, -25.81007957458496, -45.51158142089844, -38.42213821411133, -14.654274940490723, -35.91353225708008, -19.067628860473633, -3.7381062507629395, -9.335721969604492, 19.155555725097656, 40.24428939819336, 40.7655143737793, 50.4290885925293, 18.945085525512695, 20.51335334777832, -26.63544273376465, 4.104704856872559, -22.39359474182129, -44.52919387817383, -24.836915969848633, 7.280148506164551, 7.622426986694336, 26.352548599243164, 3.1069931983947754, 4.811017990112305, 49.03807067871094, 46.167232513427734, -23.97056770324707, 49.898216247558594, -39.065032958984375, -31.569507598876953, 18.764028549194336, 16.16533660888672, 6.961907863616943, -30.68402862548828, 10.137479782104492, -2.203627824783325, 19.88812255859375, -31.0932559967041, -26.736370086669922, -35.388553619384766, 51.203006744384766, 9.306061744689941, -5.518133163452148, 10.61337947845459, 11.011276245117188, -43.876129150390625, -10.322552680969238, 21.740447998046875, 19.317590713500977, -25.907695770263672, -0.25811007618904114, -18.668659210205078, -1.6286581754684448, 18.030973434448242, -22.93575096130371, -21.073328018188477, -2.1117103099823, -5.801956653594971, -36.2501106262207, 5.694543838500977, -43.35242462158203, 6.273709297180176, 18.372665405273438, 0.31068024039268494, -34.039283752441406, 18.318143844604492, -30.040069580078125, -36.70550537109375, -39.05324172973633, -13.469698905944824, -7.809794902801514, -44.312828063964844, -16.762723922729492, -18.710615158081055, -35.79670715332031, 12.355931282043457, 20.182687759399414, -1.5723944902420044, -0.014453024603426456, -22.345779418945312, 2.8105313777923584, 33.52159881591797, 10.840516090393066, -34.42837905883789, 22.073612213134766, -38.98948287963867, -42.14162826538086, -0.29607605934143066, -19.646953582763672, 6.48014497756958, -35.3214225769043, -44.85791778564453, -43.1988525390625, -19.820283889770508, -16.0548095703125, -5.173451900482178, -36.11809158325195, -26.702144622802734, -37.500064849853516, 12.244173049926758, -15.531746864318848, 37.65088653564453, 8.093867301940918, 13.779080390930176, -14.383763313293457, 29.072463989257812, -11.214729309082031, -44.606136322021484, -41.52203369140625, -3.982797145843506, -14.268044471740723, 7.415810585021973, 14.785006523132324, 23.51175880432129, 15.876057624816895, 4.997437477111816, 11.647825241088867, 5.107263088226318, 11.828742980957031, 32.96696090698242, 20.02205467224121, 14.898689270019531, -13.487970352172852, 4.180504322052002, -33.58758544921875, 9.033266067504883, -45.384185791015625, 14.450060844421387, -2.038022756576538, -39.27128219604492, -44.9306755065918, -21.0069637298584, -30.74773406982422, 22.41279411315918, -8.026365280151367, 16.20724105834961, -5.660597324371338, -4.330458164215088, -19.85291290283203, -15.108966827392578, 17.53296661376953, -45.11289978027344, -21.579519271850586, -38.61061096191406, 9.633952140808105, -3.376721143722534, -11.09507942199707, -37.70743942260742, -0.5665685534477234, 45.92625427246094, -25.032264709472656, -19.96971321105957, 6.280146598815918, -35.3055419921875, 15.889031410217285, -39.668174743652344, 43.84886169433594, -13.983288764953613, -9.514570236206055, -1.6616218090057373, -0.9612398743629456, -30.56052017211914, 37.19171905517578, -10.014747619628906, -15.947508811950684, 0.456141859292984, -0.4666166305541992, -44.99624252319336, -19.804908752441406, -19.391483306884766, -39.635772705078125, -7.550126552581787, 22.750539779663086, 20.282485961914062, 0.554419994354248, -40.177364349365234, -8.818029403686523, -25.935537338256836, -6.821070671081543, 19.502565383911133, -6.9171881675720215, 27.858430862426758, -24.4204044342041, 13.073854446411133, -2.9087436199188232, -0.20298486948013306, -17.602127075195312, -18.536916732788086, -24.933876037597656, -19.352848052978516, -44.07961654663086, -43.73731231689453, 8.381653785705566, -33.29409408569336, 14.926734924316406, 9.752442359924316, 35.15099334716797, 18.961315155029297, 17.042783737182617, 15.70490550994873, -38.283836364746094, -39.39191818237305, -44.153533935546875, -12.516847610473633, -41.907222747802734, -36.93397903442383, 18.507841110229492, -30.375526428222656, -16.037256240844727, -40.83094024658203, 8.733038902282715, -7.3647871017456055, -31.442272186279297, -24.81520652770996, -2.0280568599700928, -34.39393997192383, -34.40077209472656, -14.568795204162598, 9.662178039550781, 11.410489082336426, 9.85910701751709, -38.72314453125, -30.259611129760742, -26.485811233520508, -40.873382568359375, -27.09905242919922, 8.58825397491455, -43.39107894897461, -2.5276565551757812, 4.945517063140869, -18.231204986572266, -34.991966247558594, 17.88913345336914, 19.566837310791016, 4.954881191253662, -3.2780721187591553, -17.277921676635742, -29.707799911499023, -9.460591316223145, -23.21752166748047, -19.09053611755371, 9.2350492477417, 20.101118087768555, 14.604788780212402, 0.7524213790893555, -11.067919731140137, -8.120772361755371, -13.565620422363281, 5.3268866539001465, 30.850723266601562, 39.952857971191406, 4.979135036468506, 19.355701446533203, -44.89900207519531, 44.91707229614258, -22.083532333374023, -15.214247703552246, -30.05832290649414, -27.482135772705078, -6.075100898742676, 17.924560546875, -25.699249267578125, -44.6847038269043, -34.8038444519043, -31.406408309936523, 17.514986038208008, 21.129150390625, 26.619112014770508, 14.503623962402344, -9.24873161315918, -23.85181999206543, -6.557422637939453, 18.463857650756836, -35.13462829589844, -40.32878112792969, 12.549560546875, -41.399539947509766, 12.920236587524414, 25.884647369384766, -5.962954998016357, 16.343050003051758, -5.9330315589904785, -29.058027267456055, 31.952991485595703, 35.2410774230957, -16.141429901123047, -8.999528884887695, -37.76791763305664, 1.1026575565338135, 17.45246696472168, -28.614883422851562, -18.627275466918945, 18.643457412719727, -33.80083465576172, -40.25326919555664, 5.480541229248047, -10.358880996704102, -8.835351943969727, -39.19216537475586, -26.533166885375977, -43.85312271118164, 18.86149787902832, 0.5960416197776794, -44.0337028503418, -19.34798240661621, -25.436655044555664, 37.219520568847656, -45.14839553833008, -25.0037784576416, -42.099449157714844, 11.127297401428223, -21.67375946044922, -18.61003875732422, -43.344322204589844, -1.6392452716827393, 18.46303367614746, 18.953941345214844, -0.3690589368343353, 17.25988006591797, -44.72088623046875, 5.259955406188965, -13.107845306396484, 1.017629623413086, -43.79344177246094, 14.29973030090332, -43.1190185546875, -21.60260772705078, -14.031416893005371, 19.300716400146484, -11.223886489868164, -13.07726001739502, -14.98763370513916, -26.64109992980957, -16.679899215698242, -43.289363861083984, 4.714383602142334, -43.51314926147461, -17.835323333740234, -43.296390533447266, -0.4759913682937622, -10.01803207397461, 13.451444625854492, 6.922624111175537, -23.579334259033203, 14.136308670043945, 18.87137794494629, -20.55121421813965, -14.502812385559082, -45.25278854370117, -38.35865020751953, -3.034721851348877, 11.319737434387207, -41.45183563232422, -8.123313903808594, -22.59519386291504, -40.28422546386719, 8.456130981445312, -5.079128742218018, -27.3698673248291, -42.245933532714844, 12.38808536529541, 50.75869369506836, -9.729178428649902, -10.665614128112793, -39.49086380004883, -43.31635665893555, 0.35917428135871887, 2.723649501800537, -25.629831314086914, -7.580564498901367, 41.36343765258789, 16.496307373046875, -41.4277458190918, 48.015296936035156, -41.92527770996094, 9.250948905944824, -19.14407730102539, -30.45186996459961, -24.925569534301758, -43.798702239990234, -22.365501403808594, -40.031517028808594, -25.82796859741211, 18.411588668823242, -13.991129875183105, 10.645520210266113, 39.39688491821289, -0.6856261491775513, 18.131406784057617, -4.550933837890625, -5.647465229034424, -26.584318161010742, -22.352375030517578, 16.46285629272461, -43.475440979003906, -26.160655975341797, 17.893966674804688, -42.02303695678711, 13.109429359436035, 13.049137115478516, 10.246249198913574, -23.594621658325195, -24.978721618652344, -24.35594367980957, -17.470458984375, 8.639577865600586, 20.57740020751953, 3.7375526428222656, 12.380424499511719, 8.642594337463379, 18.628950119018555, -43.6667366027832, -45.09989547729492, -17.74903106689453, 20.006208419799805, 17.79072380065918, 15.259407997131348, -43.90680694580078, -11.295730590820312, 15.062723159790039, -37.943260192871094, -29.902788162231445, -44.02487564086914, 12.67625617980957, -13.760019302368164, -7.6977081298828125, -13.653787612915039, -1.3129675388336182, -41.64347457885742, 19.897907257080078, 20.5159854888916, -27.17365074157715, -5.975549697875977, -13.433218955993652, 9.795516014099121, 2.7009825706481934, 18.521127700805664, 9.301518440246582, -11.045769691467285, -16.44873046875, 19.993526458740234, 6.486088752746582, 18.967432022094727, 35.5078125, -42.21294403076172, -27.109642028808594, -31.102863311767578, 15.757101058959961, 6.283496379852295, -45.10987091064453, -25.46734046936035, 20.55586051940918, 0.4210258722305298, -31.892215728759766, -11.444742202758789, -32.2800178527832, -21.02425193786621, -34.4173583984375, -7.568177700042725, 16.829132080078125, -12.628218650817871, -33.87884521484375, 17.14677619934082, -8.430230140686035, 20.939809799194336, -31.21000099182129, -27.03853988647461, 19.660594940185547, 0.2334890514612198, -40.926414489746094, 17.185754776000977, -25.038808822631836, 10.74750804901123, -21.819026947021484, -3.0391769409179688, 17.318384170532227, -44.946353912353516, -18.098283767700195, -7.119657516479492, 11.065252304077148, 10.440189361572266, -4.885158538818359, 10.476337432861328, 13.396232604980469, -16.077198028564453, 15.010226249694824, 15.85671329498291, 21.36204719543457, 7.818861484527588, 9.930163383483887, -5.630258083343506, 20.926183700561523, 5.787164211273193, 6.33730411529541, 17.625497817993164, -6.02711820602417, 9.383551597595215, 17.826574325561523, 37.88322448730469, -11.843585014343262, 5.974865436553955, 8.590583801269531, -10.420003890991211, -32.9766845703125, 13.784196853637695, -30.606101989746094, -4.77640438079834, 0.3076208829879761, 19.49988555908203, 5.912290096282959, 15.8558988571167, -24.21360206604004, -13.504444122314453, -9.7577543258667, 17.87183952331543, -44.85629653930664, -36.682308197021484, -42.77009582519531, 13.516058921813965, -19.861948013305664, -11.763492584228516, 21.207477569580078, -6.18765926361084, 1.8494104146957397, -14.030871391296387, 5.217572212219238, 10.232583999633789, -3.022538423538208, 19.95473289489746, -44.992122650146484, 1.1633319854736328, -44.229454040527344, 19.93882179260254, -42.3849983215332, 6.946078777313232, -25.13774299621582, -45.5028190612793, -26.94449234008789, 21.210962295532227, -41.3185920715332, 21.070358276367188, 18.239971160888672, -23.67340087890625, -44.210304260253906, 14.798638343811035, 17.115026473999023, -44.69206619262695, -9.153436660766602, 9.867666244506836, -27.196495056152344, -0.9134482741355896, -31.949552536010742, -29.52935218811035, 5.855056285858154, -5.287965297698975, 8.732807159423828, -23.91925621032715, -15.682117462158203, -44.163780212402344, 16.092161178588867, 21.094104766845703, 1.419771432876587, -10.714216232299805, -42.47279739379883, -43.17680740356445, -11.719832420349121, -20.897274017333984, 2.6284804344177246, 13.97832202911377, -29.706520080566406, -22.494518280029297, 8.416257858276367, -43.09101486206055, 6.558800220489502, -13.135668754577637, -44.228614807128906, -0.43657833337783813, -31.606643676757812, -25.184799194335938, -8.357340812683105, -41.91315460205078, -5.189136981964111, 14.51655387878418, -15.881216049194336, 16.49640464782715, -40.433372497558594, -11.654728889465332, -39.86754608154297, -1.4106969833374023, 9.122565269470215, 14.775187492370605, -22.551729202270508, 18.041439056396484, -44.58335494995117, 12.56164264678955, 33.962974548339844, 16.778167724609375, -43.994197845458984, 17.208209991455078, -12.811617851257324, 0.6019467711448669, -15.114398956298828, -12.589716911315918, 14.844945907592773, -44.46684646606445, 8.873506546020508, -14.87975788116455, 6.811683177947998, -36.240028381347656, -0.9210101962089539, -1.6956965923309326, -29.993541717529297, -26.50383758544922, 13.915092468261719, -13.359760284423828, 16.932090759277344, 7.530083179473877, 12.492939949035645, -9.343039512634277, -15.369117736816406, -22.91675567626953, -30.279714584350586, -26.57326316833496, -3.1442787647247314, 11.338747024536133, -29.905649185180664, -14.247111320495605, 7.494791507720947, -7.079194068908691, -25.53708267211914, 17.377765655517578, -20.499357223510742, 11.470466613769531, -29.683208465576172, 15.148791313171387, -8.896275520324707, -42.89900588989258, -28.220129013061523, 6.0814337730407715, 0.015558948740363121, -40.76897430419922, -27.499540328979492, -22.07210350036621, -4.849730491638184, -44.6647834777832, 18.54924201965332, 6.232490539550781, -16.42134666442871, 16.837013244628906, -22.89269256591797, -1.9398764371871948, -11.523530960083008, 9.3359375, -34.2556037902832, -15.596657752990723, -17.264385223388672, -0.531842827796936, -30.694843292236328, -45.10843276977539, -31.047229766845703, 4.929882526397705, -22.872859954833984, -21.043325424194336, 20.429702758789062, -7.569798946380615, -3.2827091217041016, -14.920291900634766, -25.014385223388672, -29.3778018951416, 12.972637176513672, -22.14422035217285, -22.84029769897461, 16.771440505981445, 15.746798515319824, -29.248720169067383, 0.8015104532241821, -1.3938499689102173, 22.36443328857422, 18.2891788482666, 20.45320701599121, -42.98078155517578, 9.651175498962402, -31.515405654907227, -28.491743087768555, -18.729400634765625, 17.529674530029297, -0.5508946776390076, 18.088754653930664, 19.5604305267334, -22.505537033081055, -24.504844665527344, -0.8500159978866577, 18.140655517578125, 20.109291076660156, -12.54705810546875, 15.766101837158203, -23.25269889831543, -18.026321411132812, 15.259428024291992, -4.22314453125, -28.32808494567871, -41.01702117919922, -44.76502227783203, -44.884212493896484, 3.442993640899658, -5.511295795440674, 11.537433624267578, -37.207862854003906, -20.786218643188477, 15.513361930847168, -9.983755111694336, -8.297576904296875, 11.630828857421875, 21.19379425048828, -25.868640899658203, -44.438961029052734, -16.8875789642334, -39.0728874206543, 1.590059518814087, 17.74774932861328, -45.5356330871582, -31.6832275390625, -4.764875888824463, 21.04723358154297, 18.74431610107422, 12.39432430267334, 17.12123680114746, -34.05341720581055, 17.043115615844727, 19.53626251220703, -14.448827743530273, -9.685233116149902, 19.515846252441406, 20.686681747436523, -7.133171558380127, 17.730012893676758, -12.879846572875977, 12.461548805236816, 14.645416259765625, 20.635517120361328, 14.087530136108398, -30.384340286254883, 21.5159912109375, 23.61266326904297, -41.81907272338867, -41.117313385009766, -33.74640655517578, 21.692508697509766, -4.037600994110107, 20.370655059814453, -14.544063568115234, 18.65321922302246, 11.24276351928711, 19.407333374023438, 0.10475312918424606, -13.001270294189453, -26.370258331298828, 19.52216339111328, 15.103771209716797, 15.554337501525879, -5.312028408050537, -33.51158142089844, -17.001697540283203, 6.460422515869141, -2.15840220451355, 14.298258781433105, 20.97422218322754, 14.19015121459961, -0.9732308387756348, -21.88735580444336, 21.884037017822266, 8.372593879699707, 13.080425262451172, -24.861120223999023, -20.019424438476562, -44.04291534423828, -36.00847625732422, -28.896198272705078, -7.7519049644470215, -6.540621757507324, -28.21112823486328, 20.307815551757812, 19.531719207763672, 22.943593978881836], \"y\": [-33.12831115722656, 7.869945526123047, -3.6310155391693115, 8.15921688079834, -1.8443814516067505, -35.58109664916992, 8.218822479248047, 5.187628269195557, -29.87061309814453, 8.786349296569824, 3.281350612640381, -32.68077087402344, 6.183350086212158, 7.173294544219971, -41.67083740234375, 7.253289222717285, -40.802120208740234, -40.086753845214844, -0.559442400932312, -1.3108912706375122, -33.58606719970703, -34.90346145629883, -40.8943977355957, -22.4481201171875, 41.701820373535156, -17.72667121887207, -16.743976593017578, -7.49009370803833, 8.735600471496582, 2.545872211456299, 8.694430351257324, 2.2268881797790527, -34.44069290161133, -34.9815788269043, -37.4548454284668, -34.753318786621094, 38.88670349121094, -17.952449798583984, -40.779544830322266, -30.71967887878418, -39.90399169921875, -40.464569091796875, -35.131900787353516, -31.01151466369629, 9.330466270446777, 17.371328353881836, 6.209864139556885, 7.215008735656738, -27.922882080078125, 7.982801914215088, 7.0615458488464355, 6.876572608947754, -1.9624909162521362, -39.076515197753906, 7.323670864105225, -40.14109802246094, 4.260157108306885, -8.823648452758789, -5.831896781921387, 8.426783561706543, -7.202296733856201, 7.65347146987915, -6.974741458892822, 0.9943863749504089, -3.6546719074249268, 41.79663848876953, 9.310149192810059, 3.014913320541382, 28.268457412719727, 40.258766174316406, -33.31494140625, -15.42935848236084, -35.628944396972656, 9.736355781555176, -2.432826280593872, 3.9640188217163086, 9.867901802062988, 3.1442155838012695, 4.677338123321533, -37.21966552734375, -27.903444290161133, 7.1226487159729, -5.613714218139648, 4.240262985229492, 33.088905334472656, -29.993488311767578, 4.887671947479248, -5.635669231414795, 4.8857269287109375, 29.215763092041016, 38.7056999206543, -23.62281036376953, -29.908184051513672, 5.384268283843994, -31.245807647705078, 6.325882911682129, -0.6299958229064941, -6.221399784088135, 39.87600326538086, -32.522457122802734, -8.02492618560791, -26.43345832824707, -13.919143676757812, -20.924959182739258, -20.850337982177734, -23.976266860961914, 3.3547863960266113, -10.697364807128906, -22.525287628173828, 5.125740051269531, 9.3467435836792, -29.992982864379883, 2.701010227203369, 5.864980220794678, -12.147308349609375, -2.709803819656372, -38.22437286376953, -11.60086727142334, -16.527084350585938, 7.685035705566406, 4.605922698974609, -33.16952896118164, -28.179126739501953, 8.87906265258789, -37.48404312133789, -18.566381454467773, 1.7734252214431763, 4.952264308929443, 9.30178451538086, -39.6325798034668, -6.301237106323242, -17.07342529296875, -32.2417106628418, -39.551734924316406, -30.50086212158203, -22.46996307373047, -40.24829864501953, -20.16004180908203, -32.83635711669922, 38.151939392089844, -40.33073425292969, -36.56906509399414, -32.05861282348633, -33.35483932495117, -34.494224548339844, -23.060489654541016, -4.329348564147949, -31.465246200561523, 7.596200942993164, -34.71711730957031, -30.96343994140625, -22.017658233642578, -33.37872314453125, -34.44187927246094, -14.493560791015625, -34.49007034301758, 5.869226455688477, -32.79994583129883, 1.9887737035751343, -35.66031265258789, -14.91690731048584, -25.121280670166016, 2.4586069583892822, -22.149412155151367, 31.58929443359375, 7.672552585601807, -40.79210662841797, -30.563417434692383, -14.728365898132324, 42.14814376831055, 10.494965553283691, -10.629826545715332, 4.004000663757324, 4.3162055015563965, -29.83843421936035, 35.67620849609375, -6.574198246002197, 1.753092885017395, -13.696955680847168, 3.976553201675415, 0.4516494572162628, -31.22764778137207, -0.8270215392112732, -25.756284713745117, -11.057828903198242, -29.038843154907227, 8.262136459350586, -16.424312591552734, -0.5412668585777283, 9.5182466506958, -39.005741119384766, -17.896135330200195, -25.928245544433594, 43.44056701660156, -37.536251068115234, 36.49811553955078, 6.132416725158691, -26.63119888305664, -15.88350772857666, -0.21739299595355988, -25.813480377197266, 43.608863830566406, -39.43016815185547, -3.6398472785949707, -35.34321975708008, -2.041722297668457, -27.705284118652344, -31.95197296142578, -30.1472225189209, 2.1795544624328613, -1.4355642795562744, -31.059158325195312, 4.139832973480225, -30.122892379760742, 45.0703125, 10.979798316955566, -31.506343841552734, -38.99738693237305, -0.9682136178016663, 0.9717366099357605, -40.51066589355469, -7.302575588226318, 4.771836757659912, 8.826406478881836, -9.322875022888184, -24.80145263671875, -32.15738296508789, -0.5591884255409241, 10.621259689331055, -1.2992366552352905, -4.734043121337891, 4.923435688018799, -30.58557891845703, 0.30741697549819946, 0.5106003880500793, -38.76042938232422, 6.705630779266357, -8.513113975524902, -22.808549880981445, 11.088494300842285, -3.003552198410034, 39.63254165649414, 2.1759424209594727, -29.34449005126953, -32.101898193359375, -35.08933639526367, -36.36500549316406, -4.053591728210449, -29.057741165161133, 12.144245147705078, -9.769503593444824, 9.183740615844727, -30.235816955566406, -20.766193389892578, -33.378013610839844, 44.44026184082031, -19.838655471801758, -4.8608832359313965, -2.4260146617889404, -40.388885498046875, -26.2763671875, -31.53902244567871, -31.163881301879883, 5.234180927276611, 1.0431404113769531, -31.352458953857422, 43.51112747192383, 4.691744327545166, 8.9653902053833, -14.569310188293457, -19.33724021911621, 35.52529525756836, -35.914554595947266, 39.755496978759766, -30.69721031188965, -21.24717903137207, -34.042118072509766, -26.088769912719727, -33.516746520996094, 7.791271686553955, 0.30085644125938416, -38.331031799316406, -3.4737093448638916, -22.549928665161133, -34.09450912475586, -32.40176773071289, -12.887929916381836, 11.687766075134277, -1.6872318983078003, -37.021583557128906, -30.639026641845703, -26.763113021850586, 5.439530849456787, -23.752187728881836, -28.596773147583008, 0.6151644587516785, 5.4759297370910645, -15.384320259094238, -8.655355453491211, 37.72368621826172, -13.702985763549805, -32.33882522583008, -22.067941665649414, -33.719505310058594, -40.766841888427734, 30.10606575012207, -12.792960166931152, -8.175710678100586, -1.1888850927352905, -14.708780288696289, -18.879440307617188, -40.86570358276367, -40.58536911010742, -31.441999435424805, -31.075342178344727, 4.403141498565674, 25.424758911132812, 36.37108612060547, -32.8704948425293, 11.193658828735352, 6.743927955627441, -8.264362335205078, -32.9790153503418, 9.129402160644531, -32.01045227050781, -27.13006591796875, -33.43100357055664, 0.20935307443141937, -37.76686477661133, 7.273685455322266, -28.626632690429688, 1.103835105895996, -32.75719451904297, 2.2146549224853516, -23.125492095947266, 3.6411185264587402, -5.777048587799072, -30.831605911254883, -34.126792907714844, 37.170223236083984, -31.340686798095703, 9.548480987548828, -6.752622127532959, -25.92543601989746, -3.2177693843841553, 25.396665573120117, 44.51361083984375, -41.025699615478516, -5.8383989334106445, -35.33387756347656, 3.6649303436279297, -1.6997296810150146, -29.650545120239258, -20.916114807128906, -40.69331359863281, -20.0629940032959, 44.621822357177734, -10.00875473022461, 40.95582962036133, -34.84711456298828, -25.235319137573242, 2.076993942260742, -39.99577331542969, -1.101049542427063, 9.253302574157715, -14.78013801574707, -9.915229797363281, -7.74916934967041, -26.32911491394043, 8.512578964233398, 1.2470306158065796, 24.039836883544922, -35.14580535888672, 1.8799058198928833, -0.12784552574157715, 4.530543804168701, -39.65397262573242, -41.003662109375, -23.501235961914062, 1.992154836654663, -35.217430114746094, -40.41777420043945, 0.8882838487625122, -30.549610137939453, -0.9577689170837402, -39.40608596801758, -15.363167762756348, -20.6381893157959, -39.76456069946289, -19.81739616394043, -34.31296920776367, 1.060219645500183, -27.179519653320312, 23.50956153869629, -10.59434700012207, 44.022865295410156, -30.624160766601562, -40.2369499206543, 43.602935791015625, -29.18670654296875, -29.582122802734375, -34.17597961425781, -34.87565994262695, -40.13382339477539, -23.61085319519043, -33.82904052734375, -32.77568435668945, -27.521526336669922, -8.31347942352295, -23.09333038330078, -40.64056396484375, -7.123566150665283, 38.960350036621094, -30.427753448486328, 44.885250091552734, 1.0705407857894897, -30.914661407470703, -12.398171424865723, 0.11912032216787338, 5.763051509857178, 6.287104606628418, 2.0856473445892334, -34.5766716003418, -29.858102798461914, -30.88711166381836, 13.1961088180542, -34.82210922241211, 45.203125, -38.19404220581055, -36.406978607177734, 12.116202354431152, 40.499351501464844, -1.5693691968917847, -34.41249084472656, 0.8703256845474243, -38.69404983520508, -37.16267395019531, -2.5111753940582275, -34.82204055786133, 1.66825270652771, -27.730337142944336, -10.649391174316406, 0.02899092249572277, 43.43321990966797, -39.882999420166016, 5.187976837158203, -39.353729248046875, 2.229701042175293, 14.834029197692871, 38.308231353759766, -24.09600257873535, 3.6106982231140137, 39.41963195800781, -0.6711186766624451, 6.545965194702148, -40.79173278808594, -31.592729568481445, 32.68438720703125, 6.286826133728027, 9.390873908996582, -40.583641052246094, 9.796289443969727, 8.775315284729004, 11.073633193969727, -21.83033561706543, 8.40487289428711, -31.900798797607422, 43.98192596435547, -37.228824615478516, -23.638999938964844, 6.809541702270508, 8.40611457824707, -36.287418365478516, 31.654077529907227, -30.691089630126953, -28.358049392700195, 44.9619255065918, -40.71377944946289, -39.030029296875, 28.204832077026367, 9.22449016571045, 10.76364803314209, -33.60463333129883, -13.783353805541992, -35.33332443237305, 33.007381439208984, -18.719768524169922, -15.75456428527832, 33.73612976074219, 4.687764644622803, 40.105201721191406, -21.515735626220703, -34.77550506591797, 22.538877487182617, 1.6316827535629272, -35.0218391418457, -16.7894287109375, -33.93577575683594, 8.433095932006836, 4.851951599121094, -8.999268531799316, -40.00032043457031, 9.001017570495605, 42.7149658203125, -34.699249267578125, -23.536468505859375, -31.11762046813965, 14.86684799194336, -13.766603469848633, 42.78776550292969, -34.51744842529297, 10.326637268066406, -19.134021759033203, 8.412702560424805, -21.310543060302734, -33.46507263183594, -0.3937689960002899, -30.488513946533203, -30.48023796081543, -30.549161911010742, -37.670555114746094, -16.19743537902832, -29.351228713989258, 27.13006019592285, 9.084980010986328, -23.854053497314453, 0.24385932087898254, -18.360824584960938, 3.6218526363372803, -33.9805908203125, -37.77348709106445, 21.787057876586914, -35.711700439453125, -22.49703025817871, 5.770335674285889, -40.77430725097656, -10.449002265930176, 0.6206251978874207, 19.528270721435547, 21.109954833984375, 4.089503288269043, 0.06871465593576431, -32.76943588256836, 44.44846725463867, -35.457847595214844, -0.19533531367778778, 10.416714668273926, -36.25125503540039, -29.835247039794922, -33.236446380615234, -1.0847586393356323, -5.395441055297852, 5.748064994812012, -12.276147842407227, 0.7421899437904358, 39.53960037231445, -30.584726333618164, 8.031646728515625, 23.29692268371582, -33.31060791015625, -32.30406188964844, -25.49827766418457, -32.23303985595703, -33.84843444824219, -34.54435729980469, -30.462787628173828, -32.24301528930664, 44.97755432128906, -31.215225219726562, -31.462223052978516, -35.65493392944336, 41.0281867980957, -11.433588027954102, -12.325011253356934, -30.402774810791016, -34.47761917114258, 10.876172065734863, 44.691810607910156, -20.257017135620117, -38.617740631103516, 44.09782028198242, -35.99168014526367, -39.86296463012695, -39.204586029052734, 6.342217922210693, -30.96868133544922, 11.180076599121094, 39.22784423828125, 17.785804748535156, 18.77606201171875, -1.7120145559310913, 44.87922286987305, 24.316083908081055, 30.19500160217285, 7.0841217041015625, -17.530330657958984, 7.175492286682129, -35.25674057006836, 44.46711730957031, 15.198389053344727, 0.9785419702529907, -34.65866470336914, -15.654473304748535, -21.503009796142578, 37.20069885253906, 43.736576080322266, -14.276220321655273, -40.837337493896484, -30.03166389465332, -17.482351303100586, -38.747642517089844, -14.939332008361816, 2.2972168922424316, -40.364112854003906, -39.90460205078125, 35.12470626831055, 17.740360260009766, 43.946510314941406, 0.9339357614517212, -34.50063705444336, -29.955249786376953, 29.875770568847656, -33.30046463012695, -35.610591888427734, 11.868780136108398, 4.06207799911499, -30.864944458007812, 10.17807388305664, 41.11922836303711, 13.961405754089355, 10.22104549407959, 4.641188144683838, 43.74953079223633, 0.06845276057720184, -33.933658599853516, 4.83344030380249, 15.871175765991211, -19.646055221557617, -33.99214553833008, -30.57071304321289, -34.173484802246094, 44.393829345703125, 0.9272343516349792, 37.81975173950195, -23.29833984375, -20.057865142822266, 9.165406227111816, -31.21268081665039, -28.250951766967773, -15.938272476196289, -31.007474899291992, 10.367719650268555, -34.750648498535156, -17.161874771118164, -14.509572982788086, -0.4382530152797699, -10.472684860229492, -32.935672760009766, 7.547877311706543, 20.184736251831055, -4.3891825675964355, -24.396265029907227, -36.27071762084961, 7.848743915557861, -34.586605072021484, 39.44050216674805, 41.394569396972656, 21.726158142089844, 6.3585004806518555, 7.2734055519104, 12.74968433380127, 16.869779586791992, 6.050083160400391, 39.90937423706055, -13.627299308776855, -31.84807777404785, 3.877128839492798, -7.353611469268799, 30.462629318237305, -32.47640609741211, 2.4226527214050293, -8.17978286743164, -31.0224609375, 22.179737091064453, 9.97568130493164, -30.486772537231445, 5.3139166831970215, -40.32297897338867, 2.9992148876190186, -5.073997974395752, 5.871679782867432, 36.90290832519531, 45.133724212646484, -36.706298828125, -35.6854362487793, -29.988723754882812, -38.133819580078125, 40.82149887084961, -30.157785415649414, 8.187850952148438, 16.700727462768555, 43.779685974121094, -20.050416946411133, -41.27682876586914, -40.41267395019531, -31.29070281982422, -33.04988479614258, -30.28247833251953, 4.601604461669922, 43.39491271972656, -35.76314926147461, -35.032142639160156, -20.404680252075195, -34.40256118774414, 13.7391996383667, 43.02241134643555, 10.539095878601074, 4.933994293212891, -15.918866157531738, -10.920738220214844, 9.450384140014648, -0.009077871218323708, 17.12655258178711, -29.315513610839844, 1.2275938987731934, -40.9776725769043, -31.855253219604492, 10.853124618530273, -35.308143615722656, 3.390454053878784, -32.05645751953125, -2.546712636947632, 40.630374908447266, -28.747711181640625, 2.970672607421875, -27.076745986938477, 12.776606559753418, 7.98179292678833, 6.623579025268555, -39.92905044555664, -34.84109878540039, -40.72203826904297, 3.203857183456421, -30.64319610595703, -28.048049926757812, -39.8963737487793, 2.245539903640747, 8.170044898986816, -31.44611358642578, 0.7017551064491272, -40.500736236572266, 3.888777017593384, -10.632026672363281, 43.56275939941406, -36.426998138427734, 43.155216217041016, -10.639376640319824, 13.158880233764648, -40.69133758544922, -21.652877807617188, -35.5728759765625, 23.335325241088867, -31.3570613861084, -38.942413330078125, 38.85591125488281, 4.851182460784912, 18.10222625732422, 42.835182189941406, -30.713685989379883, -34.504398345947266, 43.08218002319336, 44.677452087402344, 2.6080141067504883, 42.006797790527344, -31.889789581298828, 9.722946166992188, 44.427425384521484, -16.365068435668945, 43.226680755615234, 32.86604690551758, 29.84832000732422, 0.1698116511106491, -34.93386459350586, 27.060834884643555, 40.17095947265625, -33.444618225097656, -34.779022216796875, 40.9102897644043, 44.76377868652344, -38.206153869628906, 5.309015274047852, -38.69845962524414, 43.42827224731445, -40.629878997802734, 3.408647060394287, 6.302537441253662, 44.367515563964844, 40.714508056640625, 43.093589782714844, 3.607576370239258, -39.34055709838867, 0.5063285827636719, -34.893802642822266, 5.687730312347412, 20.151477813720703, 25.291934967041016, -15.123458862304688, -0.21619023382663727, -34.03099822998047, 23.289308547973633, -17.126441955566406, -1.8648145198822021, 37.82691955566406, -0.1731289178133011, 11.11225414276123, -0.5188626646995544, 10.278884887695312, -32.80806350708008, 10.462933540344238, -0.49726107716560364, -0.11138251423835754, -35.10027313232422, 43.361820220947266, 5.598185062408447, 6.479384899139404, -35.11697769165039, 1.6268900632858276, 17.640169143676758, 11.113688468933105, -5.703242301940918, 11.831011772155762, 19.809555053710938, 4.674076557159424, 1.0769954919815063, -16.624053955078125, 43.484806060791016, 2.9204206466674805, 44.5334358215332, -29.100740432739258, 4.8872880935668945, 10.420493125915527, -0.046293437480926514, 2.4880216121673584, 19.19827651977539, -1.4772191047668457, 1.4127038717269897, -5.947048664093018, -30.77311134338379, -34.87432098388672, 9.23347282409668, 32.87580490112305, -9.49622917175293, 1.4340765476226807, -36.28541564941406, 0.587744414806366, 45.18001174926758, 8.775160789489746, 0.875965416431427, 41.92326354980469, -1.3750003576278687, 44.10572814941406, -34.29334259033203, -21.8658504486084, -18.292770385742188, -12.804588317871094, 37.795799255371094, 35.18677520751953, 5.182344436645508, 0.9276803731918335, 10.563329696655273, 43.71207809448242, 11.033463478088379, 10.10285758972168, 9.75313949584961, -32.26200866699219, 1.5302804708480835, 36.277305603027344, 1.3889126777648926, -31.40410041809082, -17.062280654907227, -31.95269775390625, 35.993106842041016, 2.9931631088256836, -20.608964920043945, 0.5570632815361023, 37.89686584472656, -33.78829574584961, -40.19661331176758, -4.897038459777832, -25.97425651550293, -36.13474655151367, 5.407493591308594, -38.78129959106445, 36.888004302978516, -21.189565658569336, 10.631747245788574, -30.638626098632812, -34.09159851074219, 43.443084716796875, 24.53634262084961, 44.19801712036133, -39.21659851074219, -36.38126754760742, 42.2622184753418, 39.03978729248047, -21.411916732788086, 3.031578540802002, -23.226360321044922, -22.090673446655273, -33.62386703491211, -39.52299499511719, 27.71925163269043, 6.944169521331787, -9.195674896240234, 40.98883056640625, -16.58045196533203, 2.6592366695404053, -34.655609130859375, 10.124510765075684, 5.204504013061523, 2.01415753364563, 9.472160339355469, -34.926849365234375, 6.964870452880859, 4.457122325897217, -3.7530434131622314, 7.623987197875977, 6.135995864868164, 9.127702713012695, 10.418622016906738, -5.8689069747924805, 43.82410430908203, -30.7438907623291, -36.67660140991211, -21.938751220703125, -27.124584197998047, 39.26599884033203, 43.314598083496094, -28.74489402770996, -35.47492218017578, 10.66862964630127, -0.5108203291893005, 7.622090816497803, 8.94613265991211, 2.6157925128936768, -38.29966735839844, -34.57343292236328, -38.06013488769531, 41.110984802246094, 41.82746505737305, -26.26349449157715, -36.579044342041016, 28.013927459716797, 2.7638723850250244, -15.691141128540039, 44.095619201660156, 37.69118881225586, 29.103225708007812, 37.66860580444336, 0.799072265625, 37.81196975708008, 7.860804557800293, 14.800028800964355, 14.721138954162598, -0.24456091225147247, 11.304624557495117, 43.9578742980957, -11.7001371383667, -25.029212951660156, -33.54534912109375, -28.033361434936523, -34.63722229003906, 0.9330956935882568, 5.631369113922119, 23.916240692138672, -27.319347381591797, -26.815298080444336, -6.921142578125, 10.354363441467285, 11.159503936767578, 9.923518180847168, -0.7789505124092102, 43.525726318359375, -8.311349868774414, 10.853653907775879, -33.252052307128906, -33.50251388549805, -40.0710334777832, -31.071992874145508, -31.788827896118164, -11.114706993103027, -15.347272872924805, -35.9210319519043, -9.027315139770508, -24.111093521118164, -31.783863067626953, 21.28125, 29.79623031616211, 1.932051181793213, 43.040348052978516, 2.955298900604248, 40.88584518432617, 22.27977180480957, -32.659385681152344, -35.62507629394531, 9.274394035339355, -6.12864875793457, 39.85296630859375, 0.21255947649478912, 1.0012089014053345, 1.4524013996124268, -14.411785125732422, 4.262362480163574, -40.88525390625, 20.43120574951172, -33.781620025634766, 43.0239372253418, -35.43095397949219, 41.96367263793945, 24.588579177856445, 9.544937133789062, 8.857181549072266, 40.94550704956055, 3.3992161750793457, -28.273548126220703, 2.0963611602783203, -4.430069446563721, -32.712059020996094, 22.65742301940918, 39.85689163208008, 8.565155029296875, 24.713653564453125, -32.05939865112305, 8.02949333190918, 4.208088397979736, -33.818519592285156, 2.4387032985687256, -1.8587679862976074, 7.128547668457031, 43.248329162597656, -29.657859802246094, 4.112732410430908, 23.530567169189453, -0.9193270206451416, -1.3913984298706055, 10.411419868469238, 41.7162971496582, -35.740684509277344, 0.9674216508865356, -30.186311721801758, -41.02033615112305, 4.511523723602295, -20.798686981201172, 1.0975244045257568, 9.827253341674805, 41.07103729248047, 8.81396484375, -7.262190341949463, -1.9859528541564941, 9.335165023803711, 7.7665534019470215, 41.85513687133789, 7.486311435699463, -33.72877502441406, 7.462303638458252, 34.27928924560547, 5.959390640258789, -31.054262161254883, 35.919219970703125, 33.027652740478516, -33.982208251953125, -38.82954406738281, 5.782203674316406, -6.555339336395264, 3.2182223796844482, 43.412235260009766, 6.144183158874512, -33.32183837890625, -39.2863883972168, -40.867645263671875, 8.940827369689941, 0.5901756286621094, 37.13064956665039, 37.785865783691406, 3.0443482398986816, -36.43294906616211, 22.406309127807617, 32.43133544921875, 5.061739921569824, -0.5944685935974121, -31.084774017333984, -0.3166491687297821, -7.324386119842529, -38.79386520385742, 0.2635042369365692, 5.544525146484375, -10.892410278320312, 9.698770523071289, -32.37153625488281, -41.254478454589844, 43.3405876159668, 10.515369415283203, 43.583717346191406, 43.495548248291016, 10.554978370666504, 6.0626444816589355, 11.645597457885742, -8.187688827514648, 11.725113868713379, 7.017856121063232, 36.88352966308594, 1.4735698699951172, -33.385765075683594, 7.346088886260986, 43.77352523803711, -17.05097770690918, 10.695549011230469, 9.199734687805176, -32.75877380371094, 8.66759967803955, 33.25471878051758, -25.43761444091797, -20.515052795410156, -33.570247650146484, 4.186162948608398, 41.9300537109375, 0.8067572116851807, -32.67643737792969, -32.003883361816406, 3.7146592140197754, 44.72907638549805, 44.058834075927734, 41.986942291259766, -5.960935115814209, 44.149139404296875, 9.943158149719238, 4.187535762786865, 45.12186050415039, 14.975228309631348, 20.603557586669922, -30.900184631347656, -24.477310180664062, 4.613275051116943, 43.301788330078125, 44.3489990234375, 22.802453994750977, 43.9240608215332, -39.46452331542969, 9.673657417297363, 4.410528659820557, -30.641857147216797, 43.103397369384766, 44.64320755004883, 8.17988395690918, -34.51841354370117, 45.15476608276367, -14.465526580810547, 0.18160982429981232, 39.21603775024414, 10.129018783569336, 29.725257873535156, -35.499427795410156, -33.986473083496094, 11.702179908752441, 32.453857421875, 6.404319763183594, -26.451980590820312, 5.3985772132873535, -3.9110829830169678, 5.664684772491455, -22.827573776245117, -27.082904815673828, 23.95769691467285, 10.39339828491211, 7.22318172454834, -22.18163299560547, 1.3023889064788818, 43.44192886352539, 43.21511459350586, 43.97187805175781, 1.6031488180160522, -29.053993225097656, -29.651168823242188, -34.880855560302734, -35.74665832519531, -36.404937744140625, 35.99062728881836, -26.596097946166992, -32.586429595947266, -33.72909927368164, -25.157155990600586, 43.157623291015625, 0.5267012119293213, -14.619194984436035, 42.432308197021484, 1.2092794179916382, -34.790592193603516, 8.18315315246582, 23.742238998413086, 24.524192810058594, -1.2058522701263428, 1.2198141813278198, -34.42348861694336, 10.469108581542969, 45.40556716918945, -34.90065002441406, -35.15186309814453, 2.81296968460083, 14.39470100402832, 33.54283905029297, -0.17732490599155426, -32.93849182128906, 2.4389758110046387, 7.212474346160889, -0.057417821139097214, -37.70621109008789, -27.954971313476562, 41.61433410644531, 22.295106887817383, -12.444784164428711, -18.961959838867188, 10.659340858459473, -34.03470993041992, 43.3066291809082, 43.67373275756836, 2.911703586578369, 13.905437469482422, 10.250945091247559, -4.172916412353516, -29.89045524597168, -32.01114273071289, 30.59877586364746, 15.736227989196777, -39.82087326049805, 34.017581939697266, 43.17327117919922, 43.89402389526367, 2.8027660846710205, 21.41427230834961, 7.8808441162109375, -23.07133674621582, -37.49154281616211, 3.885465621948242, 34.582374572753906, -40.24678039550781, -31.334354400634766, 30.798267364501953, 44.317508697509766, 9.54261302947998, -37.1651725769043, -34.175594329833984, 9.035470008850098, 42.33184051513672, -27.05078125, -29.870059967041016, 13.181361198425293, 43.34507751464844, 43.229148864746094, 11.194314956665039, -30.324691772460938, -22.19781494140625, 40.480167388916016, 44.00894546508789, -32.432960510253906, -26.45594024658203, -34.1380500793457, -15.446172714233398, 13.442768096923828, -30.3250675201416, -11.953404426574707, 44.53459548950195, 11.950901985168457, -31.98577117919922, -3.502626895904541, 43.6891975402832, -19.001081466674805, 34.32624053955078, 45.04793930053711, 44.82270431518555, -3.247087001800537, 43.548622131347656, 26.810771942138672, 12.621891021728516, 42.7507209777832, 10.025623321533203, -13.143661499023438, -0.638878583908081, 6.67576789855957, -30.9327335357666, -14.174806594848633, -38.52277374267578, -15.351194381713867, 43.82520294189453, 45.28901290893555, -40.62965774536133, 5.709776401519775, 7.149698734283447, 45.506736755371094, 44.39179992675781, 45.163143157958984, 1.1274046897888184, -31.750064849853516, -4.697388172149658, -34.39649963378906, -20.178512573242188, -30.7707462310791, 5.899537086486816, 34.85562515258789, 36.71001434326172, 9.830671310424805, 31.55860137939453, 12.298948287963867, 10.60644817352295, 44.71753692626953, -11.739526748657227, -24.830039978027344, 41.38677215576172, -36.475318908691406, 2.729034423828125, -32.13258361816406, 11.84610652923584, 5.270270347595215, -34.28001022338867, -31.37517547607422, 43.46819305419922, -21.567222595214844, 5.990306854248047, -7.241334915161133, 42.328495025634766, 43.896480560302734, -23.263399124145508, -15.344701766967773, 43.95625686645508, -31.088485717773438, 43.749149322509766, -31.497516632080078, -25.420942306518555, -39.707584381103516, -24.294418334960938, -13.002409934997559, 1.0371216535568237, -0.25870266556739807, 8.879983901977539, -33.51250457763672, 43.84945297241211, -7.08658504486084, 11.089203834533691, 2.9430487155914307, 44.06598663330078, 22.091588973999023, 43.97321701049805, 2.583434820175171, -28.545982360839844, -0.9441036581993103, 28.74520492553711, 44.451168060302734, 42.72996520996094, 43.378055572509766, 44.608394622802734, 29.409774780273438, -2.8159704208374023, -34.684303283691406, 8.48585319519043, -21.946205139160156, 32.03241729736328, 36.24755859375, 3.495985746383667, 44.618324279785156, 12.085854530334473, -35.56576919555664, 8.444225311279297, 2.0129330158233643, 18.971906661987305, 0.140264093875885, 2.45635986328125, -33.98261260986328, 27.011789321899414, -13.212385177612305, -12.868597984313965, 43.30006408691406, 7.733821868896484, 12.232925415039062, 33.351200103759766, -1.4587305784225464, 43.61347579956055, 33.706329345703125, -26.122148513793945, -32.31208801269531, -12.195649147033691, 35.583030700683594, -34.21607971191406, 42.997650146484375, -34.629005432128906, 0.05222223699092865, 4.4298906326293945, 26.430326461791992, 12.784832000732422, 44.008033752441406, 42.33313751220703, 6.336674690246582, 0.4142763316631317, 39.94388961791992, 7.872644901275635, 35.4999885559082, 3.3393218517303467, 43.81103515625, 15.384912490844727, -0.10146117955446243, 28.824447631835938, -33.65433883666992, 0.3181512653827667, -33.82635498046875, 9.482635498046875, 31.966449737548828, 1.0402593612670898, -2.674147844314575, -35.27312469482422, 16.115942001342773, 0.6638165712356567, 9.762998580932617, 5.117784023284912, -31.305097579956055, 9.835041999816895, -30.44308853149414, 45.37726974487305, 30.73505973815918, 44.40037536621094, -29.900556564331055, 30.158321380615234, 45.04133605957031, 11.381577491760254, 43.444969177246094, 43.59313201904297, 15.642539978027344, -0.07920700311660767, -22.407455444335938, 27.974000930786133, 9.390153884887695, -36.04664993286133, 43.67211151123047, -0.6440739631652832, 12.034648895263672, -15.878884315490723, 44.86240005493164, -32.0479850769043, -35.47968673706055, 37.7783203125, 2.8564646244049072, 34.8016471862793, 1.604198694229126, -34.12983703613281, 31.24631118774414, 10.277219772338867, 13.38049602508545, 1.5447049140930176, 2.5450525283813477, 1.9995194673538208, 10.211824417114258, 38.6855583190918, 0.3288806080818176, 5.247527599334717, -31.541156768798828, 36.31634521484375, 28.003751754760742, -30.91596221923828, 45.409637451171875, -32.45102310180664, 37.625892639160156, 3.747159481048584, 9.036188125610352, 34.26152420043945, 43.521114349365234, 1.8730032444000244, 42.235252380371094, 17.488557815551758, 1.0941503047943115, 4.622050762176514, 10.358793258666992, -33.47107696533203, 43.10625457763672, 4.452328205108643, -8.749114990234375, 6.784658432006836, -19.72176170349121, 2.606203556060791, 45.18486404418945, 3.3551130294799805, 25.18328857421875, 43.72806167602539, 42.13071823120117, 43.73820877075195, 40.086524963378906, -35.67435836791992, 43.748355865478516, 26.11355972290039, -13.342933654785156, -30.82305335998535, -2.2526073455810547, 16.662771224975586, 1.9803078174591064, -33.093017578125, 43.9881706237793, -6.993872165679932, -34.50326919555664, -41.037559509277344, -20.641437530517578, 12.705281257629395, 5.9526896476745605, 44.725425720214844, -4.733796119689941, 3.746711254119873, 4.127954006195068, -3.0585103034973145, 4.168481826782227, 2.0810866355895996, 10.772525787353516, 41.45841979980469, 9.972848892211914, -32.60572052001953, -1.3966646194458008, 0.7216423153877258, 37.277992248535156, 44.520172119140625, 43.81294631958008, -6.626922130584717, 27.741680145263672, 19.99184799194336, 0.5182114839553833, 44.88422393798828, -20.113500595092773, -0.6181600093841553, 44.483253479003906, -34.997779846191406, 39.78997039794922, 6.718947410583496, 43.402645111083984, 10.268911361694336, 38.47675704956055, -1.1497702598571777, 39.048866271972656, 44.23870086669922, -0.8059696555137634, 40.97300720214844, 43.16730880737305, 10.879237174987793, 43.470123291015625, -23.836917877197266, 1.3985450267791748, -39.02779769897461, 44.705623626708984, 7.9640913009643555, 3.807053327560425, 4.3531494140625, -22.781139373779297, 41.27427291870117, 39.70502853393555, 30.236509323120117, 44.30610275268555, 22.51058578491211, -11.982684135437012, 36.23883819580078, -35.24985122680664, 6.305141448974609, -16.172094345092773, 27.02723503112793, 6.834437847137451, -0.13148115575313568, 8.472857475280762, 43.475791931152344, 31.489608764648438, -14.875535011291504, -0.6328963041305542, 43.55823516845703, 37.701297760009766, 7.657124996185303, -1.2828447818756104, 0.21223214268684387, 43.240299224853516, 44.0215950012207, 34.425296783447266, 43.971099853515625, 24.843555450439453, 38.970760345458984, 34.1335563659668, 44.04927444458008, -34.697532653808594, 43.461666107177734, 43.38884353637695, 43.66345977783203, 2.508068323135376, 0.22277233004570007, -33.074581146240234, -34.14754104614258, 0.5650771856307983, 44.03159713745117, -34.771240234375, 29.613710403442383, 9.300347328186035, 2.168569326400757, 43.155975341796875, 30.527008056640625, 42.389503479003906, -0.18437559902668, 43.53094482421875, -0.7507842183113098, 41.054718017578125, 5.320736408233643, 43.89128112792969, 9.210844993591309, -31.122928619384766, -1.9227097034454346, -40.469459533691406, 1.0963108539581299, 8.227791786193848, 32.95111083984375, 44.54106903076172, 42.45025634765625, 5.824979782104492, 38.2004280090332, 9.700601577758789, 6.790329933166504, 8.440767288208008, 40.2295036315918, 10.215520858764648, -6.760919570922852, 43.16157150268555, 40.19002914428711, 43.769439697265625, 10.431953430175781, 14.120931625366211, 44.524173736572266, 43.04639434814453, 7.811059951782227, -33.7668342590332, 43.37726593017578, 6.275879859924316, 44.610748291015625, 10.412785530090332, 29.15576934814453, 6.012105464935303, 43.39461898803711, 43.084781646728516, 42.970481872558594, 16.474870681762695, 8.216739654541016, 24.134143829345703, 0.22719433903694153, 1.9131935834884644, 43.18498992919922, 9.856181144714355, 45.40833282470703, 27.59637451171875, -0.261107861995697, 25.134767532348633, 8.879096984863281, -34.126808166503906, 11.92119026184082, 1.7158071994781494, 16.25221061706543, 19.726486206054688, 44.58101272583008, 6.4955244064331055, 43.939292907714844, 45.422027587890625, 8.846680641174316, -31.124624252319336, 43.37514877319336, -24.82843780517578, -10.950554847717285, -9.201958656311035, 40.02009963989258, 1.9417030811309814, 35.08503723144531, 6.49416446685791, 44.025360107421875, 32.33343505859375, 44.1330451965332, -31.9559383392334, 3.0997226238250732, 18.5616512298584, 10.77120304107666, -15.21908187866211, 7.675178050994873, -24.89786148071289, -30.345129013061523, 7.31566047668457, -13.80162239074707, 43.166934967041016, 1.985012412071228, 21.53501319885254, 14.984646797180176, 1.7308855056762695, 9.009671211242676, -30.435895919799805, 28.848417282104492, 27.059961318969727, 6.722805976867676, 45.31837463378906, 15.801824569702148, 10.945653915405273, 43.59476852416992, 7.560025691986084, 6.787303447723389, 35.4937629699707, 6.397675514221191, 9.437660217285156, 33.07616424560547, 10.0283784866333, 18.26250457763672, -40.780059814453125, 3.1694369316101074, 2.264169931411743, 9.153777122497559, 14.405627250671387, 42.23050308227539, 22.812292098999023, 7.943108558654785, 9.628252983093262, -0.48714661598205566, 10.190424919128418, 0.8689273595809937, 42.91630172729492, 44.05373764038086, 20.347211837768555, 29.488706588745117, 2.932035446166992, 0.31547409296035767, 8.791056632995605, 43.95124435424805, -1.0096261501312256, 43.816871643066406, 7.654519081115723, 20.015748977661133, 32.44385528564453, 42.24159240722656, 10.023467063903809, 13.407833099365234, 36.478946685791016, 33.8870964050293, 9.537409782409668, 43.37371063232422, -17.032974243164062, 8.897353172302246, -33.1066780090332, 42.81251525878906, 44.10874557495117, 43.6652717590332, 23.307804107666016, 15.118268966674805, 13.074532508850098]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('12fe3be2-d4f4-45f8-b284-91607954bbfd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial we learned how to train word2vec models on your custom data\n",
    "and also how to evaluate it. Hope that you too will find this popular tool\n",
    "useful in your Machine Learning tasks!\n",
    "\n",
    "Links\n",
    "-----\n",
    "\n",
    "- API docs: :py:mod:`gensim.models.word2vec`\n",
    "- `Original C toolkit and word2vec papers by Google <https://code.google.com/archive/p/word2vec/>`_.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
